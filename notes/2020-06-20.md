

```python
import pandas as pd
import xgboost as xgb
from xgboost import XGBClassifier
import datetime; import pytz
import matplotlib.pyplot as plt
from scipy.special import softmax
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import train_test_split # (*arrays, **options)
import numpy as np
from sklearn.metrics import log_loss
from sklearn.preprocessing import OneHotEncoder, LabelEncoder

from joblib import dump, load
import joblib
import os
from sklearn.metrics import confusion_matrix, mean_squared_error
from sklearn.model_selection import KFold, train_test_split, GridSearchCV
from sklearn.metrics import accuracy_score
import fresh.utils as fu

from importlib import reload
from collections import Counter
from tqdm.notebook import tqdm
import fresh.preproc.v1 as pv1
```


```python
datadir = '/opt/data'
localdir = '/opt/program'


tripsdf = pd.read_csv(f'{datadir}/2013-07 - Citi Bike trip data.csv'
                     )#.sample(frac=0.017, random_state=42)
stationsdf = pd.read_csv(f'{localdir}/datas/stations/stations-2018-12-04-c.csv',
                        index_col=0)

```


```python

X, y, neighborhoods = fu.prepare_data(tripsdf, stationsdf)
X_train, X_test, y_train, y_test = train_test_split(X, y)

# preproc
(X_transformed,
     one_hot_enc, le,
     y_enc) = pv1.preprocess(X_train, y_train, # X[train_index]
                         neighborhoods)
labels = le.classes_

# Test set
X_test_transformed = one_hot_enc.transform(X_test)
y_test_enc = le.transform(y_test)
```


```python
os.getpid()
```




    877




```python
%%time
workdir = fu.make_work_dir(); print(workdir)
fu.log(workdir, 'Starting')

rng = np.random.RandomState(31337)

kf = KFold(n_splits=2, shuffle=True, random_state=rng)
for (i, (train_index, test_index)) in enumerate(kf.split(X)):    
    # preproc
    (X_transformed,
         one_hot_enc, le,
         y_enc) = pv1.preprocess(X[train_index], y[train_index], 
                             neighborhoods)
    
    xgb_model = xgb.XGBClassifier(objective='multi:softprob'
                                 ).fit(X_transformed, 
                                        y_enc, verbose=True)
    fu.log(workdir, f'[{i}] Done fit.')
    
    bundle_loc = f'{workdir}/bundle_{i}.joblib'
    joblib.dump({'model': xgb_model}, bundle_loc)
    #
    X_test_transformed = one_hot_enc.transform(X[test_index])
    actuals = le.transform(y[test_index]); len(actuals)
    
    predictions = xgb_model.predict(X_test_transformed)
    confusion = confusion_matrix(actuals, predictions)
    acc = accuracy_score(actuals, predictions)
    
    y_prob_vec = fu.predict_proba(X_test_transformed, bundle_loc=bundle_loc)
    # xgb_model.predict_proba(X_test_transformed)
    fu.log(workdir, f'[{i}] Done fu.predict_proba')
    
    
    logloss = fu.big_logloss(actuals, y_prob_vec, list(range(len(labels))))
    fu.log(workdir, f'[{i}] Done big_logloss, loss={logloss}.')
                          
    # save full now though
    joblib.dump({'model': xgb_model,
                'metrics': {'confusion': confusion,
                           'validation_logloss': logloss,
                           'validation_acc': acc}}, bundle_loc)
    fu.log(workdir, f'[{i}] dumped bundle to {bundle_loc}')
                             
```

    /opt/program/artifacts/2020-06-20T215346Z
    CPU times: user 20min 19s, sys: 8.64 s, total: 20min 27s
    Wall time: 23min 30s



```python
bundle_loc = '/opt/program/artifacts/2020-06-20T215346Z/bundle_0.joblib'
bundle = joblib.load(bundle_loc)
bundle
```




    {'model': XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,
                   colsample_bynode=1, colsample_bytree=1, gamma=0,
                   learning_rate=0.1, max_delta_step=0, max_depth=3,
                   min_child_weight=1, missing=nan, n_estimators=100, n_jobs=1,
                   nthread=None, objective='multi:softprob', random_state=0,
                   reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,
                   silent=None, subsample=1, verbosity=1),
     'metrics': {'confusion': array([[   0,   49,   12, ...,    0,    0,  143],
             [   0, 1112,   13, ...,    0,    0,   39],
             [   0,    1,  283, ...,    0,    0,  305],
             ...,
             [   0,    0,    7, ...,    0,    0,   73],
             [   0,  567,   27, ...,    0,    0,   57],
             [   0,   21,  163, ...,    0,    0, 2064]]),
      'validation_logloss': 3.3088296090867195,
      'validation_acc': 0.15462832101833496}}




```python
bundle_loc = '/opt/program/artifacts/2020-06-20T215346Z/bundle_1.joblib'
bundle = joblib.load(bundle_loc)
bundle
```




    {'model': XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,
                   colsample_bynode=1, colsample_bytree=1, gamma=0,
                   learning_rate=0.1, max_delta_step=0, max_depth=3,
                   min_child_weight=1, missing=nan, n_estimators=100, n_jobs=1,
                   nthread=None, objective='multi:softprob', random_state=0,
                   reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,
                   silent=None, subsample=1, verbosity=1),
     'metrics': {'confusion': array([[ 193,   64,   14, ...,    0,    0,  150],
             [  27, 1167,   16, ...,    0,    0,   28],
             [   4,    6,  379, ...,    0,    0,  236],
             ...,
             [   0,    0,   17, ...,    0,    0,   46],
             [  67,  599,   24, ...,    0,    0,   78],
             [  19,    9,  196, ...,    0,    0, 2017]]),
      'validation_logloss': 3.306871724048802,
      'validation_acc': 0.1541161182619253}}




```python
!top
```

    [?1h=[H[2J[mtop - 22:39:42 up 4 days, 21:42,  0 users,  load average: 0.41, 0.31, 0.56[m[m[m[m[K
    Tasks:[m[m[1m   6 [m[mtotal,[m[m[1m   1 [m[mrunning,[m[m[1m   5 [m[msleeping,[m[m[1m   0 [m[mstopped,[m[m[1m   0 [m[mzombie[m[m[m[m[K
    %Cpu(s):[m[m[1m  6.0 [m[mus,[m[m[1m  0.7 [m[msy,[m[m[1m  0.0 [m[mni,[m[m[1m 93.1 [m[mid,[m[m[1m  0.2 [m[mwa,[m[m[1m  0.0 [m[mhi,[m[m[1m  0.0 [m[msi,[m[m[1m  0.0 [m[mst[m[m[m[m[K
    KiB Mem :[m[m[1m  2046844 [m[mtotal,[m[m[1m   634640 [m[mfree,[m[m[1m  1234124 [m[mused,[m[m[1m   178080 [m[mbuff/cache[m[m[m[m[K
    KiB Swap:[m[m[1m  1048572 [m[mtotal,[m[m[1m    28140 [m[mfree,[m[m[1m  1020432 [m[mused.[m[m[1m   650456 [m[mavail Mem [m[m[m[m[K
    [K
    [7m  PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND     [m[m[K
    [m  667 root      20   0 1147296  21832   5456 S   5.9  1.1   7:40.77 jupyter-no+ [m[m[K
    [m  877 root      20   0 2782904 1.076g  11120 S   5.9 55.1  21:23.56 python      [m[m[K
    [m    1 root      20   0   18236      4      0 S   0.0  0.0   0:00.11 bash        [m[m[K
    [m  897 root      20   0  243148   3360   1240 S   0.0  0.2   0:00.12 python      [m[m[K
    [m  927 root      20   0    4500    748    680 S   0.0  0.0   0:00.55 sh          [m[m[K
    [m[1m  928 root      20   0   36852   3080   2672 R   0.0  0.2   0:00.00 top         [m[m[K
    [J[H[mtop - 22:39:45 up 4 days, 21:42,  0 users,  load average: 0.38, 0.30, 0.56[m[m[m[m[K
    Tasks:[m[m[1m   6 [m[mtotal,[m[m[1m   1 [m[mrunning,[m[m[1m   5 [m[msleeping,[m[m[1m   0 [m[mstopped,[m[m[1m   0 [m[mzombie[m[m[m[m[K
    %Cpu(s):[m[m[1m  0.6 [m[mus,[m[m[1m  1.2 [m[msy,[m[m[1m  0.0 [m[mni,[m[m[1m 98.0 [m[mid,[m[m[1m  0.1 [m[mwa,[m[m[1m  0.0 [m[mhi,[m[m[1m  0.1 [m[msi,[m[m[1m  0.0 [m[mst[m[m[m[m[K
    KiB Mem :[m[m[1m  2046844 [m[mtotal,[m[m[1m   634608 [m[mfree,[m[m[1m  1234020 [m[mused,[m[m[1m   178216 [m[mbuff/cache[m[m[m[m[K
    KiB Swap:[m[m[1m  1048572 [m[mtotal,[m[m[1m    28164 [m[mfree,[m[m[1m  1020408 [m[mused.[m[m[1m   650520 [m[mavail Mem [m[m[m[m[K
    [K
    
    [m  877 root      20   0 2782904 1.076g  11120 S   6.0 55.1  21:23.74 python      [m[m[K
    [m  667 root      20   0 1147296  21832   5456 S   3.3  1.1   7:40.87 jupyter-no+ [m[m[K
    
    
    
    [m[1m  928 root      20   0   36820   3096   2672 R   0.0  0.2   0:00.00 top         [m[m[K
    [J[H[mtop - 22:39:48 up 4 days, 21:42,  0 users,  load average: 0.35, 0.30, 0.56[m[m[m[m[K
    
    %Cpu(s):[m[m[1m  0.9 [m[mus,[m[m[1m  1.4 [m[msy,[m[m[1m  0.0 [m[mni,[m[m[1m 97.6 [m[mid,[m[m[1m  0.1 [m[mwa,[m[m[1m  0.0 [m[mhi,[m[m[1m  0.1 [m[msi,[m[m[1m  0.0 [m[mst[m[m[m[m[K
    KiB Mem :[m[m[1m  2046844 [m[mtotal,[m[m[1m   634360 [m[mfree,[m[m[1m  1234252 [m[mused,[m[m[1m   178232 [m[mbuff/cache[m[m[m[m[K
    KiB Swap:[m[m[1m  1048572 [m[mtotal,[m[m[1m    28168 [m[mfree,[m[m[1m  1020404 [m[mused.[m[m[1m   650272 [m[mavail Mem [m[m[m[m[K
    [K
    
    [m  877 root      20   0 2782904 1.076g  11120 S   7.0 55.1  21:23.95 python      [m[m[K
    [m  667 root      20   0 1147296  21832   5456 S   5.7  1.1   7:41.04 jupyter-no+ [m[m[K
    
    
    
    
    [J[H[mtop - 22:39:51 up 4 days, 21:42,  0 users,  load average: 0.35, 0.30, 0.56[m[m[m[m[K
    
    %Cpu(s):[m[m[1m  0.9 [m[mus,[m[m[1m  0.6 [m[msy,[m[m[1m  0.0 [m[mni,[m[m[1m 98.4 [m[mid,[m[m[1m  0.0 [m[mwa,[m[m[1m  0.0 [m[mhi,[m[m[1m  0.2 [m[msi,[m[m[1m  0.0 [m[mst[m[m[m[m[K
    KiB Mem :[m[m[1m  2046844 [m[mtotal,[m[m[1m   634360 [m[mfree,[m[m[1m  1234292 [m[mused,[m[m[1m   178192 [m[mbuff/cache[m[m[m[m[K
    KiB Swap:[m[m[1m  1048572 [m[mtotal,[m[m[1m    28172 [m[mfree,[m[m[1m  1020400 [m[mused.[m[m[1m   650272 [m[mavail Mem [m[m[m[m[K
    [K
    
    [m  877 root      20   0 2782904 1.076g  11120 S   5.3 55.1  21:24.11 python      [m[m[K
    [m  667 root      20   0 1147296  21832   5456 S   2.7  1.1   7:41.12 jupyter-no+ [m[m[K
    [m[1m  928 root      20   0   36820   3096   2672 R   0.3  0.2   0:00.01 top         [m[m[K
    [m    1 root      20   0   18236      4      0 S   0.0  0.0   0:00.11 bash        [m[m[K
    [m  897 root      20   0  243148   3360   1240 S   0.0  0.2   0:00.12 python      [m[m[K
    [m  927 root      20   0    4500    748    680 S   0.0  0.0   0:00.55 sh          [m[m[K
    [J[?1l>[25;1H
    [K


```python
os.getpid()
```




    877



- Showing `1.076g` resident memory used by my notebook `pid=877` 
- This is anecdotally feeling better than before.
- Oh and no crashes here. May be due to single notebook running, or might be the 


```python
from shlex import join
```


    ---------------------------------------------------------------------------

    ImportError                               Traceback (most recent call last)

    <ipython-input-31-b44828d46bc6> in <module>
    ----> 1 from shlex import join
    

    ImportError: cannot import name 'join' from 'shlex' (/opt/conda/lib/python3.7/shlex.py)



```python
#import subprocess
!ps -p 877 -o pid,ppid,pmem,rss

```

      PID  PPID %MEM   RSS
      877   667 55.7 1142136



```python
out = subprocess.check_output(["ps", "-p", "877", "-o", "pid,ppid,pmem,rss"])
print(out)
pid, ppid, pmem, rss = out.decode('utf-8').split('\n')[1].strip().split()
print(f'{pid}, {pmem}, {rss}')
print(int(rss)/1024/1024) 
```

    b'  PID  PPID %MEM   RSS\n  877   667 55.8 1142288\n'
    877, 55.8, 1142288
    1.0893707275390625



```python
def get_my_memory():
    mypid = os.getpid()
    out = subprocess.check_output(["ps", "-p", f"{mypid}", "-o", "pid,ppid,pmem,rss"])

    pid, ppid, pmem, rss = out.decode('utf-8').split('\n')[1].strip().split()
    # print(f'{pid}, {pmem}, {rss}')
    gigs = int(rss)/1024/1024
    assert int(pid) == mypid
    return {'pmem': pmem, 'rss': gigs}
get_my_memory()
```




    {'pmem': '55.8', 'rss': 1.0894660949707031}


