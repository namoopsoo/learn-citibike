### TOC 
* [2020-06-12](#2020-06-12)
* [2020-06-13](#2020-06-13) Notes on dying kernel

### 2020-06-12

```python
import pandas as pd
import xgboost as xgb
from xgboost import XGBClassifier
import datetime; import pytz
import matplotlib as plt
from scipy.special import softmax
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import train_test_split # (*arrays, **options)
import numpy as np
from sklearn.metrics import log_loss
from sklearn.preprocessing import OneHotEncoder, LabelEncoder

from joblib import dump, load
import joblib
import os
from sklearn.metrics import confusion_matrix, mean_squared_error
from sklearn.model_selection import KFold, train_test_split, GridSearchCV
```


```python
datadir = '/opt/data'
localdir = '/opt/program'
tripsdf = pd.read_csv(f'{datadir}/2013-07 - Citi Bike trip data.csv')
stationsdf = pd.read_csv(f'{localdir}/datas/stations/stations-2018-12-04-c.csv',
                        index_col=0)
```


```python
os.getcwd()
```




    '/opt/program'




```python
# load model from 2020-06-10 notebook
bundle = joblib.load('/opt/program/artifacts/2020-06-11T041641Z/bundle.joblib')
```


```python
bundle
```




    {'notebook': '2020-06-10-again',
     'model': XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,
                   colsample_bynode=1, colsample_bytree=1, gamma=0,
                   learning_rate=0.1, max_delta_step=0, max_depth=3,
                   min_child_weight=1, missing=nan, n_estimators=100, n_jobs=1,
                   nthread=None, objective='multi:softprob', random_state=0,
                   reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,
                   silent=None, subsample=1, verbosity=1),
     'actuals': array([60, 60, 60, ...,  2,  2,  2]),
     'predictions': array([46, 46, 46, ...,  2,  2,  2]),
     'confusion_matrix': array([[ 193,   64,   14, ...,    0,    0,  150],
            [  27, 1167,   16, ...,    0,    0,   28],
            [   4,    6,  379, ...,    0,    0,  236],
            ...,
            [   0,    0,   17, ...,    0,    0,   46],
            [  67,  599,   24, ...,    0,    0,   78],
            [  19,    9,  196, ...,    0,    0, 2017]]),
     'walltime_train': '19min 45s',
     'preproc': {'le': LabelEncoder(),
      'one_hot_enc': OneHotEncoder(categories=[['Alphabet City', 'Battery Park City',
                                 'Bedford-Stuyvesant', 'Bloomingdale', 'Boerum Hill',
                                 'Bowery', 'Broadway Triangle', 'Brooklyn Heights',
                                 'Brooklyn Navy Yard', 'Carnegie Hill',
                                 'Carroll Gardens', 'Central Park', 'Chelsea',
                                 'Chinatown', 'Civic Center', 'Clinton Hill',
                                 'Cobble Hill', 'Columbia Street Waterfront District',
                                 'Downtown Brooklyn', 'Dumbo', 'East Harlem',
                                 'East Village', 'East Williamsburg',
                                 'Financial District', 'Flatiron District',
                                 'Fort Greene', 'Fulton Ferry District',
                                 'Garment District', 'Governors Island', 'Gowanus', ...],
                                [0, 1, 2]],
                    drop=None, dtype=<class 'numpy.float64'>, handle_unknown='error',
                    sparse=True)}}




```python
# quick manual accuracy computation
bundle['actuals'].shape, bundle['predictions'].shape
correct = len([i for i, _ in enumerate(bundle['actuals'])
              if bundle['actuals'][i] == bundle['predictions'][i]
              ])
print({'overall accuracy': correct/len(bundle['actuals']), 
       'num_correct': correct, 'total': len(bundle['actuals'])})
print(bundle['confusion_matrix'].shape)

confusion_diagonal = [bundle['confusion_matrix'][i][j]
                                  for i in range(54)
                                  for j in range(54)
                                  if i == j]
print(confusion_diagonal)
print('confusion, sum, diagonal', sum(confusion_diagonal))
```

    {'overall accuracy': 0.1541161182619253, 'num_correct': 64992, 'total': 421708}
    (54, 54)
    [193, 1167, 379, 0, 0, 1406, 0, 1039, 30505, 0, 685, 557, 67, 62, 49, 0, 4534, 0, 2583, 109, 0, 0, 2766, 2003, 0, 0, 0, 236, 0, 2722, 0, 0, 612, 6064, 581, 0, 0, 0, 0, 24, 0, 0, 0, 0, 0, 0, 4632, 0, 0, 0, 0, 0, 0, 2017]
    confusion, sum, diagonal 64992



```python
model = bundle['model']
print(len(model.feature_importances_))
print(sorted(model.feature_importances_))
```

    78
    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00057195826, 0.00096085493, 0.0019978876, 0.0028608162, 0.003014325, 0.0031509278, 0.005542396, 0.0055443724, 0.0056226645, 0.0064963517, 0.0066661313, 0.007307959, 0.007578683, 0.0077737863, 0.008284873, 0.00866166, 0.009315344, 0.010423137, 0.010517005, 0.010585468, 0.010727769, 0.012014797, 0.012143584, 0.012632706, 0.01298739, 0.013684955, 0.014033192, 0.014308239, 0.014311185, 0.016608043, 0.017402876, 0.017734889, 0.017809916, 0.017948298, 0.018543119, 0.01898507, 0.019225849, 0.02069202, 0.020770036, 0.021067692, 0.02152036, 0.022673236, 0.024081945, 0.02418218, 0.02421692, 0.026871085, 0.027934289, 0.02844202, 0.030187974, 0.032351416, 0.033994444, 0.035514593, 0.03653184, 0.036576174, 0.044999287, 0.04772858, 0.05568539]



```python
# 78 features
model.classes_
```




    array([ 0,  1,  2,  4,  5,  7,  8, 11, 12, 13, 14, 15, 17, 18, 19, 21, 23,
           24, 25, 26, 27, 30, 32, 33, 34, 36, 37, 39, 40, 42, 43, 44, 45, 46,
           47, 48, 49, 50, 51, 52, 53, 57, 58, 60, 62, 63, 64, 65, 66, 67, 68,
           71, 72, 73])




```python
import fresh.utils as fu
from importlib import reload
reload(fu)
```




    <module 'fresh.utils' from '/opt/program/fresh/utils.py'>




```python
X, y, neighborhoods = fu.prepare_data(tripsdf, stationsdf)
# = sorted(stationsdf.neighborhood.unique().tolist())


```


```python
bundle['preproc']['one_hot_enc'].categories
```




    [['Alphabet City',
      'Battery Park City',
      'Bedford-Stuyvesant',
      'Bloomingdale',
      'Boerum Hill',
      'Bowery',
      'Broadway Triangle',
      'Brooklyn Heights',
      'Brooklyn Navy Yard',
      'Carnegie Hill',
      'Carroll Gardens',
      'Central Park',
      'Chelsea',
      'Chinatown',
      'Civic Center',
      'Clinton Hill',
      'Cobble Hill',
      'Columbia Street Waterfront District',
      'Downtown Brooklyn',
      'Dumbo',
      'East Harlem',
      'East Village',
      'East Williamsburg',
      'Financial District',
      'Flatiron District',
      'Fort Greene',
      'Fulton Ferry District',
      'Garment District',
      'Governors Island',
      'Gowanus',
      'Gramercy Park',
      'Greenpoint',
      'Greenwich Village',
      "Hell's Kitchen",
      'Hudson Square',
      'Hunters Point',
      'Kips Bay',
      'Korea Town',
      'Lenox Hill',
      'Lincoln Square',
      'Little Italy',
      'Long Island City',
      'Lower East Side',
      'Lower Manhattan',
      'Meatpacking District',
      'Midtown',
      'Midtown East',
      'Midtown West',
      'Murray Hill',
      'NoHo',
      'NoMad',
      'Nolita',
      'Park Slope',
      'Peter Cooper Village',
      'Prospect Heights',
      'Prospect Park',
      'Red Hook',
      'Rose Hill',
      'SoHo',
      'Stuyvesant Heights',
      'Stuyvesant Town',
      'Sunset Park',
      'Sutton Place',
      'Theater District',
      'Tribeca',
      'Tudor City',
      'Two Bridges',
      'Ukrainian Village',
      'Union Square',
      'Upper East Side',
      'Upper West Side',
      'Vinegar Hill',
      'West Village',
      'Williamsburg',
      'Yorkville'],
     [0, 1, 2]]




```python
len(bundle['preproc']['one_hot_enc'].categories[0]), len(bundle['preproc']['one_hot_enc'].categories[1])
```




    (75, 3)




```python
features = ([f'feature_start_neighborhood={x}' for x in bundle['preproc']['one_hot_enc'].categories[0]]
           + [f'feature_gender={x}' for x in bundle['preproc']['one_hot_enc'].categories[1]])
print(features)
```

    ['feature_start_neighborhood=Alphabet City', 'feature_start_neighborhood=Battery Park City', 'feature_start_neighborhood=Bedford-Stuyvesant', 'feature_start_neighborhood=Bloomingdale', 'feature_start_neighborhood=Boerum Hill', 'feature_start_neighborhood=Bowery', 'feature_start_neighborhood=Broadway Triangle', 'feature_start_neighborhood=Brooklyn Heights', 'feature_start_neighborhood=Brooklyn Navy Yard', 'feature_start_neighborhood=Carnegie Hill', 'feature_start_neighborhood=Carroll Gardens', 'feature_start_neighborhood=Central Park', 'feature_start_neighborhood=Chelsea', 'feature_start_neighborhood=Chinatown', 'feature_start_neighborhood=Civic Center', 'feature_start_neighborhood=Clinton Hill', 'feature_start_neighborhood=Cobble Hill', 'feature_start_neighborhood=Columbia Street Waterfront District', 'feature_start_neighborhood=Downtown Brooklyn', 'feature_start_neighborhood=Dumbo', 'feature_start_neighborhood=East Harlem', 'feature_start_neighborhood=East Village', 'feature_start_neighborhood=East Williamsburg', 'feature_start_neighborhood=Financial District', 'feature_start_neighborhood=Flatiron District', 'feature_start_neighborhood=Fort Greene', 'feature_start_neighborhood=Fulton Ferry District', 'feature_start_neighborhood=Garment District', 'feature_start_neighborhood=Governors Island', 'feature_start_neighborhood=Gowanus', 'feature_start_neighborhood=Gramercy Park', 'feature_start_neighborhood=Greenpoint', 'feature_start_neighborhood=Greenwich Village', "feature_start_neighborhood=Hell's Kitchen", 'feature_start_neighborhood=Hudson Square', 'feature_start_neighborhood=Hunters Point', 'feature_start_neighborhood=Kips Bay', 'feature_start_neighborhood=Korea Town', 'feature_start_neighborhood=Lenox Hill', 'feature_start_neighborhood=Lincoln Square', 'feature_start_neighborhood=Little Italy', 'feature_start_neighborhood=Long Island City', 'feature_start_neighborhood=Lower East Side', 'feature_start_neighborhood=Lower Manhattan', 'feature_start_neighborhood=Meatpacking District', 'feature_start_neighborhood=Midtown', 'feature_start_neighborhood=Midtown East', 'feature_start_neighborhood=Midtown West', 'feature_start_neighborhood=Murray Hill', 'feature_start_neighborhood=NoHo', 'feature_start_neighborhood=NoMad', 'feature_start_neighborhood=Nolita', 'feature_start_neighborhood=Park Slope', 'feature_start_neighborhood=Peter Cooper Village', 'feature_start_neighborhood=Prospect Heights', 'feature_start_neighborhood=Prospect Park', 'feature_start_neighborhood=Red Hook', 'feature_start_neighborhood=Rose Hill', 'feature_start_neighborhood=SoHo', 'feature_start_neighborhood=Stuyvesant Heights', 'feature_start_neighborhood=Stuyvesant Town', 'feature_start_neighborhood=Sunset Park', 'feature_start_neighborhood=Sutton Place', 'feature_start_neighborhood=Theater District', 'feature_start_neighborhood=Tribeca', 'feature_start_neighborhood=Tudor City', 'feature_start_neighborhood=Two Bridges', 'feature_start_neighborhood=Ukrainian Village', 'feature_start_neighborhood=Union Square', 'feature_start_neighborhood=Upper East Side', 'feature_start_neighborhood=Upper West Side', 'feature_start_neighborhood=Vinegar Hill', 'feature_start_neighborhood=West Village', 'feature_start_neighborhood=Williamsburg', 'feature_start_neighborhood=Yorkville', 'feature_gender=0', 'feature_gender=1', 'feature_gender=2']



```python
importances = model.feature_importances_
labeled_importances = [[features[i], importances[i]] for i in range(78)]
sorted(labeled_importances, key=lambda x:x[1])
```




    [['feature_start_neighborhood=Bloomingdale', 0.0],
     ['feature_start_neighborhood=Broadway Triangle', 0.0],
     ['feature_start_neighborhood=Carnegie Hill', 0.0],
     ['feature_start_neighborhood=Carroll Gardens', 0.0],
     ['feature_start_neighborhood=Cobble Hill', 0.0],
     ['feature_start_neighborhood=East Harlem', 0.0],
     ['feature_start_neighborhood=East Williamsburg', 0.0],
     ['feature_start_neighborhood=Governors Island', 0.0],
     ['feature_start_neighborhood=Gowanus', 0.0],
     ['feature_start_neighborhood=Greenpoint', 0.0],
     ['feature_start_neighborhood=Hunters Point', 0.0],
     ['feature_start_neighborhood=Lenox Hill', 0.0],
     ['feature_start_neighborhood=Long Island City', 0.0],
     ['feature_start_neighborhood=Prospect Heights', 0.0],
     ['feature_start_neighborhood=Prospect Park', 0.0],
     ['feature_start_neighborhood=Red Hook', 0.0],
     ['feature_start_neighborhood=Stuyvesant Heights', 0.0],
     ['feature_start_neighborhood=Sunset Park', 0.0],
     ['feature_start_neighborhood=Upper East Side', 0.0],
     ['feature_start_neighborhood=Upper West Side', 0.0],
     ['feature_start_neighborhood=Yorkville', 0.0],
     ['feature_gender=2', 0.00057195826],
     ['feature_gender=1', 0.00096085493],
     ['feature_start_neighborhood=Tudor City', 0.0019978876],
     ['feature_gender=0', 0.0028608162],
     ['feature_start_neighborhood=Korea Town', 0.003014325],
     ['feature_start_neighborhood=Sutton Place', 0.0031509278],
     ['feature_start_neighborhood=Rose Hill', 0.005542396],
     ['feature_start_neighborhood=NoHo', 0.0055443724],
     ['feature_start_neighborhood=NoMad', 0.0056226645],
     ['feature_start_neighborhood=Union Square', 0.0064963517],
     ['feature_start_neighborhood=Little Italy', 0.0066661313],
     ['feature_start_neighborhood=Gramercy Park', 0.007307959],
     ['feature_start_neighborhood=Peter Cooper Village', 0.007578683],
     ['feature_start_neighborhood=Flatiron District', 0.0077737863],
     ['feature_start_neighborhood=Nolita', 0.008284873],
     ['feature_start_neighborhood=Lower Manhattan', 0.00866166],
     ['feature_start_neighborhood=SoHo', 0.009315344],
     ['feature_start_neighborhood=Stuyvesant Town', 0.010423137],
     ['feature_start_neighborhood=Garment District', 0.010517005],
     ['feature_start_neighborhood=Meatpacking District', 0.010585468],
     ['feature_start_neighborhood=Murray Hill', 0.010727769],
     ['feature_start_neighborhood=Kips Bay', 0.012014797],
     ['feature_start_neighborhood=Hudson Square', 0.012143584],
     ['feature_start_neighborhood=Ukrainian Village', 0.012632706],
     ['feature_start_neighborhood=Midtown', 0.01298739],
     ['feature_start_neighborhood=East Village', 0.013684955],
     ['feature_start_neighborhood=Park Slope', 0.014033192],
     ['feature_start_neighborhood=Vinegar Hill', 0.014308239],
     ['feature_start_neighborhood=Bowery', 0.014311185],
     ['feature_start_neighborhood=Chinatown', 0.016608043],
     ['feature_start_neighborhood=Alphabet City', 0.017402876],
     ['feature_start_neighborhood=Lincoln Square', 0.017734889],
     ['feature_start_neighborhood=Dumbo', 0.017809916],
     ['feature_start_neighborhood=Brooklyn Navy Yard', 0.017948298],
     ['feature_start_neighborhood=Civic Center', 0.018543119],
     ['feature_start_neighborhood=Theater District', 0.01898507],
     ['feature_start_neighborhood=Fulton Ferry District', 0.019225849],
     ['feature_start_neighborhood=West Village', 0.02069202],
     ['feature_start_neighborhood=Midtown West', 0.020770036],
     ['feature_start_neighborhood=Midtown East', 0.021067692],
     ['feature_start_neighborhood=Boerum Hill', 0.02152036],
     ['feature_start_neighborhood=Two Bridges', 0.022673236],
     ["feature_start_neighborhood=Hell's Kitchen", 0.024081945],
     ['feature_start_neighborhood=Greenwich Village', 0.02418218],
     ['feature_start_neighborhood=Columbia Street Waterfront District',
      0.02421692],
     ['feature_start_neighborhood=Battery Park City', 0.026871085],
     ['feature_start_neighborhood=Chelsea', 0.027934289],
     ['feature_start_neighborhood=Lower East Side', 0.02844202],
     ['feature_start_neighborhood=Downtown Brooklyn', 0.030187974],
     ['feature_start_neighborhood=Tribeca', 0.032351416],
     ['feature_start_neighborhood=Clinton Hill', 0.033994444],
     ['feature_start_neighborhood=Brooklyn Heights', 0.035514593],
     ['feature_start_neighborhood=Bedford-Stuyvesant', 0.03653184],
     ['feature_start_neighborhood=Financial District', 0.036576174],
     ['feature_start_neighborhood=Fort Greene', 0.044999287],
     ['feature_start_neighborhood=Williamsburg', 0.04772858],
     ['feature_start_neighborhood=Central Park', 0.05568539]]




```python
# Perhaps indeed the starting locations which are so un-important, basically have just way too many
# destinations, or maybe there are just not enough trips involving those stations.
# But anyway, I think ultimately the importances which are there 
#    across different cross validation folds are the ones to focus on
```


```python
# retry that multi-logloss ...
rng = np.random.RandomState(31337)
indices1 = []
kf = KFold(n_splits=2, shuffle=True, random_state=rng)
for train_index, test_index in kf.split(X):
    indices1.append([train_index, test_index])

indices2 = []
kf = KFold(n_splits=2, shuffle=True, random_state=rng)
for train_index, test_index in kf.split(X):
    indices2.append([train_index, test_index])
    

```


```python
# hmm doesnt look the same though, guess that random seed doesnt work deterministically?
indices1[0][:5] , indices2[0][:5]

```




    ([array([     0,      2,      3, ..., 843411, 843412, 843415]),
      array([     1,      7,      8, ..., 843410, 843413, 843414])],
     [array([     5,      7,      9, ..., 843412, 843413, 843414]),
      array([     0,      1,      2, ..., 843408, 843411, 843415])])




```python
#log_loss(y_true_enc, y_prob, labels=self.labels)
#help(log_loss)
bundle['preproc']['le'].classes_.shape
```




    (75,)




```python
X_transformed = bundle['preproc']['one_hot_enc'].transform(X[:1000])
y_prob = model.predict_proba(X_transformed)
```


```python
y_prob[0].shape
```




    (54,)




```python
# ok got to clear up this inconsistency.. so, len(bundle['preproc']['one_hot_enc'].categories[0]) => 75
# but there are I believe only 54 neighborhoods actually represented in the data itself,

from collections import Counter
print(len(bundle['preproc']['one_hot_enc'].categories[0]))
print(len(dict(Counter([x[0] for x in X]))))
```

    75
    54



```python
sorted(list(dict(Counter(y)).keys()))
```




    ['Alphabet City',
     'Battery Park City',
     'Bedford-Stuyvesant',
     'Boerum Hill',
     'Bowery',
     'Brooklyn Heights',
     'Brooklyn Navy Yard',
     'Central Park',
     'Chelsea',
     'Chinatown',
     'Civic Center',
     'Clinton Hill',
     'Columbia Street Waterfront District',
     'Downtown Brooklyn',
     'Dumbo',
     'East Village',
     'Financial District',
     'Flatiron District',
     'Fort Greene',
     'Fulton Ferry District',
     'Garment District',
     'Gramercy Park',
     'Greenwich Village',
     "Hell's Kitchen",
     'Hudson Square',
     'Kips Bay',
     'Korea Town',
     'Lincoln Square',
     'Little Italy',
     'Lower East Side',
     'Lower Manhattan',
     'Meatpacking District',
     'Midtown',
     'Midtown East',
     'Midtown West',
     'Murray Hill',
     'NoHo',
     'NoMad',
     'Nolita',
     'Park Slope',
     'Peter Cooper Village',
     'Rose Hill',
     'SoHo',
     'Stuyvesant Town',
     'Sutton Place',
     'Theater District',
     'Tribeca',
     'Tudor City',
     'Two Bridges',
     'Ukrainian Village',
     'Union Square',
     'Vinegar Hill',
     'West Village',
     'Williamsburg']




```python
# yea so 54 in X and y... but i used stationsdf w/ 75 neighborhoods, 
# so at the very least I should not be using that if it ends up indeed , 
# blowing up the one hot encoder to 75 , ... this might be why we have those start neighborhoods, 
# with  0 importance, since there was just no data for them 

# Anyhow since the predict_proba output is indeed only length 54, that tells me the classifier
# ended up doing the rigiht thing anway. So I will keep this in mind for the next dataset but 
# in this case it is okay anyway.
```

### 2020-06-13

#### quick update, also just calculate a multiclass logloss as well
- Hmm don't have the indices I used in notebook "2020-06-10-again" so I have to do that again
- Also kernel died while trying to do this so numbers starting over 
- And wow happened twice. Turns out running log_loss() with 843416 rows did the trick!


```python
import pandas as pd
import xgboost as xgb
from xgboost import XGBClassifier
import datetime; import pytz
import matplotlib as plt
from scipy.special import softmax
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import train_test_split # (*arrays, **options)
import numpy as np
from sklearn.metrics import log_loss
from sklearn.preprocessing import OneHotEncoder, LabelEncoder

from joblib import dump, load
import joblib
import os
from sklearn.metrics import confusion_matrix, mean_squared_error
from sklearn.model_selection import KFold, train_test_split, GridSearchCV
import fresh.utils as fu

from importlib import reload
from collections import Counter
from tqdm.notebook import tqdm
import fresh.preproc.v1 as pv1
```


```python
datadir = '/opt/data'
localdir = '/opt/program'
tripsdf = pd.read_csv(f'{datadir}/2013-07 - Citi Bike trip data.csv')
stationsdf = pd.read_csv(f'{localdir}/datas/stations/stations-2018-12-04-c.csv',
                        index_col=0)

```


```python
# load model from 2020-06-10 notebook
# bundle = joblib.load('/opt/program/artifacts/2020-06-11T041641Z/bundle.joblib')
```

```
example
log_loss(y[:100], y_prob_vec[:100], labels=sorted(list(dict(Counter(y)).keys())))
=> 4.133

losses_vec = []
for part in fu.get_partitions(list(range(len(y_prob_vec))), slice_size=1000):
    i, j = part[0], part[-1]   
    losses_vec.append(log_loss(y[i:j], y_prob_vec[i:j], labels=labels))

fu.big_logloss(y, y_prob=y_prob_vec, labels=labels)
```

#### kernel keeps dying when I'm trying to do this
* I finally started to log some breadcrumbs and I am seeing now where it is dying.. 
* I see that it is dying right before the second `xgb.XGBClassifier()` 
```
2020-06-14 17:49:40Z, Starting
2020-06-14 17:49:44Z, [0] Done preprocessing
2020-06-14 18:01:09Z, [0] Done fit
2020-06-14 18:01:09Z, [0] Done transforming test data
2020-06-14 18:02:27Z, [0] Done predict()
2020-06-14 18:03:48Z, [0] Done  predict_proba()
2020-06-14 18:03:48Z, [0] Done  done fu.big_logloss()
2020-06-14 18:03:48Z, [0] wrote bundle /opt/program/artifacts/2020-06-14T174940Z/bundle_0.joblib
2020-06-14 18:03:50Z, [1] Done preprocessing
```
* The `xgb.XGBClassifier()` is indeed here the longest segment. I am now wondering about borrowing a technique from another project where I would just call a subprocess 
* Reading about using [external memory](https://xgboost.readthedocs.io/en/latest/tutorials/external_memory.html)
* Maybe I can contribute to [this stackoverflow question](https://stackoverflow.com/questions/43972009/how-to-load-a-big-train-csv-for-xgboost) . And indeed [this np.memmap](https://stackoverflow.com/questions/16149803/working-with-big-data-in-python-and-numpy-not-enough-ram-how-to-save-partial-r/16633274#16633274) answer is interesting too.
* 


```python

param = {'max_depth':2, 'eta':1, 'objective':'multi:softprob'}

# performance notice: set nthread to be the number of your real cpu
# some cpu offer two threads per core, for example, a 4 core cpu with 8 threads, in such case set nthread=4
#param['nthread']=num_real_cpu

watchlist = [(dtest, 'eval'), (dtrain, 'train')]
num_round = 2
bst = xgb.train(param, dtrain, num_round, watchlist)
```




    numpy.memmap



#### Another go
But store the intermediary results this time unlike inthe 2020-06-10 notebook





```python
%%time

# New workdir
workdir = fu.make_work_dir(); print('workdir: ', workdir)
fu.log(workdir, 'Starting')

rng = np.random.RandomState(31337)
X, y, neighborhoods = fu.prepare_data(tripsdf, stationsdf)
neighborhoods = sorted(stationsdf.neighborhood.unique().tolist())
labels = sorted(list(dict(Counter(y)).keys()))

X, y = X[:10000], y[:10000]

kf = KFold(n_splits=5, shuffle=True, random_state=rng)
for i, (train_index, test_index) in enumerate(tqdm(kf.split(X), desc='outer', leave=True)):
    
    # preprocess
    (X_transformed, one_hot_enc, le,
         y_enc) = pv1.preprocess(X[train_index], y[train_index], 
                             neighborhoods)
    fu.log(workdir, f'[{i}] Done preprocessing')
    labels = le.classes_
    
    #
    outpath = f'{workdir}/dtrain.{i}.train'
    fu.save_libsvm(X_transformed.toarray(), y_enc, outpath)
    fu.log(workdir, f'[{i}] Saved train data: {outpath}')
    dtrain = xgb.DMatrix(f'{outpath}#dtrain.cache')
    xgb_model = xgb.XGBClassifier().fit(dtrain) #X_transformed, y_enc
    fu.log(workdir, f'[{i}] Done fit')
    
    X_test_transformed = one_hot_enc.transform(X[test_index]).toarray()
    actuals = le.transform(y[test_index])
    fu.log(workdir, f'[{i}] Done transforming test data')
    
    predictions = xgb_model.predict(X_test_transformed)
    fu.log(workdir, f'[{i}] Done predict()')
    correct = len([i for i, _ in enumerate(actuals)
              if actuals[i] == predictions[i]])

    y_prob_vec = []
    X_parts = fu.get_partitions(X_test_transformed, slice_size=1000)
    for X_part in tqdm(X_parts, desc='inner', leave=False):
        # X_transformed = one_hot_enc.transform(X_part)
        y_prob = xgb_model.predict_proba(X_part)
        y_prob_vec.extend(y_prob)
    fu.log(workdir, f'[{i}] Done  predict_proba()')
    # y_prob_vec = xgb_model.predict_proba(X_test_transformed)
    
    bundle_file = f'{workdir}/bundle_{i}.joblib'
    loss = fu.big_logloss(actuals, y_prob=y_prob_vec, labels=labels)
    fu.log(workdir, f'[{i}] Done  done fu.big_logloss()')
    
    joblib.dump({'loss': loss,
     'confusion_matrix': confusion_matrix(actuals, predictions),
     'model': xgb_model,
     'notebook': '2020-06-12.ipynb',
     'accuracy': correct/len(actuals),
     'timestamp': fu.utc_ts(),
    }, bundle_file)
    fu.log(workdir, f'[{i}] wrote bundle {bundle_file}')
```

    workdir:  /opt/program/artifacts/2020-06-14T225321Z



    HBox(children=(FloatProgress(value=1.0, bar_style='info', description='outer', max=1.0, style=ProgressStyle(deâ€¦


    [22:53:23] SparsePageSource::CreateRowPage Finished writing to dtrain.cache
    [22:53:23] 1x78 matrix with 16000 entries loaded from /opt/program/artifacts/2020-06-14T225321Z/dtrain.0.train#dtrain.cache
    



    ---------------------------------------------------------------------------

    TypeError                                 Traceback (most recent call last)

    <timed exec> in <module>


    TypeError: fit() missing 1 required positional argument: 'y'



```python
# 0:45 , starting 
# 1:00 ,  still going, but dang no sign of the inner tqdm yet (the predict proba)
# 1:01 => TypeError, sparse matrix length is ambiguous; use getnnz() or shape[0]
#          
#/opt/program/fresh/utils.py in get_partitions(vec, slice_size, keep_remainder)
#      39 def get_partitions(vec, slice_size, keep_remainder=True):
#      40     assert slice_size > 0
# ---> 41     num_slices = int(math.floor(len(vec)/slice_size))
```


```python
# fu.save_libsvm(X_transformed, y_enc, outpath)
X_transformed.toarray()[0][0]
```




    0.0


#### averaging log losses..


```python
# pretty sure since I had had to partition the logloss , I can still average it to get a full score.
i, j = 0, 1000
a = log_loss(y[i:j], y_prob_vec[i:j], labels=labels)

i, j = 1000, 2000
b = log_loss(y[i:j], y_prob_vec[i:j], labels=labels)

i, j = 0, 2000
c = log_loss(y[i:j], y_prob_vec[i:j], labels=labels)

(a+b)/2, c

```




    (3.993434763431549, 3.9934347634315492)


