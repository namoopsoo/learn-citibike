

#### making the tarball from the joblib..

```
cd artifacts/2020-08-19T144654Z

ls
# => all_bundle_with_stationsdf.joblib

mkdir model

mv all_bundle_with_stationsdf.joblib model

tar -czf model.tar.gz model
# => creates model.tar.gz , which I can throw into a SageMaker model.

```

#### troubleshoot docker does not run serve command...
- is it not executable? Wrong work dir?

```
$ docker run -p 8889:8889 -p 8080:8080 -i -t -v $(pwd):/opt/program       \
      -v ${my_local_data_directory}:/opt/data        \
      -v   ~/Downloads:/opt/downloads         \
      -v  $(pwd)/artifacts/2020-08-19T144654Z:/opt/ml   citibike-learn:latest  serve

docker: Error response from daemon: OCI runtime create failed: container_linux.go:349: starting container process caused "exec: \"serve\": executable file not found in $PATH": unknown.



```

* Maybe some help [here](https://stackoverflow.com/questions/27158840/docker-executable-file-not-found-in-path) , or [here](https://docs.docker.com/engine/reference/builder/#/cmd)  , with the use of a `CMD` word in the `Dockerfile` .


### 2020-08-26

#### dockerfile
* ok i had just needed to add `/opt/server` to the `PATH` and that fixed it


#### for the probabily outputs from xgboost, got to map those to neighborhoods
* this is the next thing
* and put that mapping into `fresh/lambda.py`
* This information should be in the bundle too. along with the input header too.

#### 54
* `54` output probabilities.


### 2020-08-29

#### test entry code

```python
import fresh.lambda_entry as fl

fl.entry(None, None)

bundle = fl.fetch_bundle()
```

* hmm the bundle requires xgboost, which locally (except for Docker) I dont have and lambda also will not have
* making a slimmed bundle w/o the model...

```python
import fresh.predict_utils as fpu
import joblib
bundle = fpu.load_bundle_in_docker()
del bundle['model_bundle']['bundle']['xgb_model']

blahdir = '/opt/program/artifacts/2020-08-19T144654Z'

joblib.dump(bundle, f'{blahdir}/all_bundle_with_stationsdf_except_xgb.joblib')

```
* And then I saved that to my s3 location
* Try main entry func again w/ the no-xgb bundle

```python
import fresh.lambda_entry as fl
bundle = fl.fetch_bundle()
# fl.map_probabilities(bundle, prob_vec, k=5)
```

* hmm got a scikit learn error now

```
ModuleNotFoundError: No module named 'sklearn.preprocessing._label'
```
* not sure if it helps, but going to align my version ..


```
In [92]: sklearn.__version__                                                                                          
Out[92]: '0.20.2'

In [93]: !pip install -U scikit-learn==0.22.1
```
* oh wow... I tried `fetch_bundle` again after that and bingo!

* ok try also w/ map probabilities...

```python
import fresh.lambda_entry as fl
bundle = fl.fetch_bundle()
out = fl.entry(None, None)

fl.map_probabilities(bundle, prob_vec=out['result'][0], k=5)
```
* ok yay... very cool.

```python
In [8]: fl.map_probabilities(bundle, prob_vec=out['result'][0], k=5)                                                      
Out[8]:
[('Bedford-Stuyvesant', 0.18238812685012817),
 ('Vinegar Hill', 0.0740085020661354),
 ('Columbia Street Waterfront District', 0.07334273308515549),
 ('Downtown Brooklyn', 0.07258936762809753),
 ('Fulton Ferry District', 0.0493587926030159)]
```
* Now just need to add the Google Static Map API call in there. And complete.
* Ah I forgot got a few choices w/ what latlng to chose
```python
stationsdf = bundle['stations_bundle']['stationsdf']
df = fl.map_probabilities(bundle, prob_vec=out['result'][0], k=5)                                                      

In [24]: df.merge(stationsdf, on='neighborhood').iloc[:5][['station_name', 'latlng', 'neighborhood']]                     
Out[24]:
                  station_name                        latlng        neighborhood
0  Lexington Ave & Classon Ave      40.68676793,-73.95928168  Bedford-Stuyvesant
1    Franklin Ave & Myrtle Ave          40.694528,-73.958089  Bedford-Stuyvesant
2   Lefferts Pl & Franklin Ave   40.680342423,-73.9557689392  Bedford-Stuyvesant
3     Hancock St & Bedford Ave      40.68216564,-73.95399026  Bedford-Stuyvesant
4      Macon St & Nostrand Ave  40.6809833854,-73.9500479759  Bedford-Stuyvesant


```
* ..
```python
import fresh.lambda_entry as fl
out = fl.entry(None, None)

```

#### Summary
* Ok cool. i have a full end to end glue now, complete with locations on a static map img tag.

#### Next ...
* I want to just add the 'start' location too. Probably different color label too
* Then place the thing into a lambda
* And then the html side needs to TLC .


### 2020-08-30

#### quick lambda test
* can i even access file system on lambda?

```python
import os
def sage_entry(event, context):
    print(os.getcwd())
    print(os.listdir('.'))

```
* heres what i get

```
/var/task
['lambda_function.py']
```

* ok but when i tried to write ... Damn does not allow.
```python
with open('/var/task/temp.blah', 'w') as fd:
    fd.write('cool beans')
```

```
Response:
{
  "errorMessage": "[Errno 30] Read-only file system: '/var/task/temp.blah'",
  "errorType": "OSError",
  "stackTrace": [
    "  File \"/var/task/lambda_function.py\", line 14, in sage_entry\n    with open('/var/task/temp.blah', 'w') as fd:\n"
  ]
}
```
* So going to have to just embed the information I need in the code itself. Not s3. thats fine.

#### the html side...
* My original demo is [here](https://bike-hop-predict.s3.amazonaws.com/index.html)


### 2020-08-31

#### note
*  ok so since cannot write to file system, must change the entry function since cannot use joblib because it requires disk.
* I can still keep the extra info on s3, just use json or pickle instead since those dont need disk.


```python
In [1]: import joblib                                                           

In [2]: import fresh.lambda_entry as fle                                        

In [3]: bundle = fle.fetch_bundle()

In [6]: import pickle                                                           

In [7]: pkl = pickle.dumps(bundle)                                              

In [8]: import fresh.s3utils as fs3                                             


In [12]: loc = 'bikelearn/artifacts/2020-08-19T144654Z/all_bundle_with_stationsdf_except_xgb.pkl'                                                      

In [13]: fs3.write_s3_file(bucket_name, loc, pkl)                               

```

### 2020-09-02

#### update w that pkl..
* ok cool updated code w/ pkl instead of joblib/disk dependence and all good.

### 2020-09-03

#### Next
* test this code on lambda, along w/ docker update on sagemaker
* the lambda entry must also return the img html to the browser ajax call
* fast follow: the "Source station" should also be a special label in the static map diagram too!
* the API Gateway authentication : how to authenticate now?

#### api gateway authentication
* previously I was using the access keys/secrets as inputs to the actual html form. I guess I can still see if that works?
* that's a super bare bones mvp haha. But might as well see if it works.


#### zip
* uploaded the `foo.zip` created like this to lambda..
```
zip   -r foo fresh -i \*.py
```
* but ran into this on lambda darn..

```
Response:
{
  "errorMessage": "Unable to import module 'fresh.lambda_entry': No module named 'pandas'",
  "errorType": "Runtime.ImportModuleError"
}
```

#### tried another sagemaker model endpoint
* hmm but failed with this ..

```
Traceback (most recent call last):
  File "/opt/conda/lib/python3.7/site-packages/flask/app.py", line 2447, in wsgi_app
    response = self.full_dispatch_request()
  File "/opt/conda/lib/python3.7/site-packages/flask/app.py", line 1952, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/opt/conda/lib/python3.7/site-packages/flask/app.py", line 1821, in handle_user_exception
    reraise(exc_type, exc_value, tb)
  File "/opt/conda/lib/python3.7/site-packages/flask/_compat.py", line 39, in reraise
    raise value
  File "/opt/conda/lib/python3.7/site-packages/flask/app.py", line 1950, in full_dispatch_request
    rv = self.dispatch_request()
  File "/opt/conda/lib/python3.7/site-packages/flask/app.py", line 1936, in dispatch_request
    return self.view_functions[rule.endpoint](**req.view_args)
  File "/opt/server/predictor.py", line 82, in ping
    record = make_canned_record()

NameError: name 'make_canned_record' is not defined
```

#### Summary
* updated lambda entry code to return the map html
* tried another sagemaker docker go.
* zip + a lambda build go.

#### Next
* got to fix that sagemaker `make_canned_record` missing dependency
* pandas into lambda layer + retry
* try pipeline again.


### 2020-09-04

#### pandas layer
* Just out of convenience, I ran this in my running docker. ( Thanks to convenient refresher notes [here](https://medium.com/swlh/how-to-add-python-pandas-layer-to-aws-lambda-bab5ea7ced4f) )
```
mkdir python
pip install -t python pandas pytz
rm -r python/numpy*
```
* Not having `zip` in my docker, i ran the zip part on the mac host
```
zip -r python.zip python
```
* And I uploaded this to s3, and built a lambdas layer
* And the dependency was now good. but failed for joblib!.
* I commented out the joblib but then sklearn. Right also forgot about that.


#### summary
* Ok built pandas layer
* uncommented joblib dependency, but found sklearn dependency also needs to be met


#### NExt
* sklearn dependency needs to be layered up too!.
* And as from earlier, got to re-build the docker image w/ the `make_canned_record` fix. 
