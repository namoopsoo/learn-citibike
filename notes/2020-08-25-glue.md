

#### making the tarball from the joblib..

```
cd artifacts/2020-08-19T144654Z

ls
# => all_bundle_with_stationsdf.joblib

mkdir model

mv all_bundle_with_stationsdf.joblib model

tar -czf model.tar.gz model
# => creates model.tar.gz , which I can throw into a SageMaker model.

```

#### troubleshoot docker does not run serve command...
- is it not executable? Wrong work dir?

```
$ docker run -p 8889:8889 -p 8080:8080 -i -t -v $(pwd):/opt/program       \
      -v ${my_local_data_directory}:/opt/data        \
      -v   ~/Downloads:/opt/downloads         \
      -v  $(pwd)/artifacts/2020-08-19T144654Z:/opt/ml   citibike-learn:latest  serve

docker: Error response from daemon: OCI runtime create failed: container_linux.go:349: starting container process caused "exec: \"serve\": executable file not found in $PATH": unknown.



```

* Maybe some help [here](https://stackoverflow.com/questions/27158840/docker-executable-file-not-found-in-path) , or [here](https://docs.docker.com/engine/reference/builder/#/cmd)  , with the use of a `CMD` word in the `Dockerfile` .


### 2020-08-26

#### dockerfile
* ok i had just needed to add `/opt/server` to the `PATH` and that fixed it


#### for the probabily outputs from xgboost, got to map those to neighborhoods
* this is the next thing
* and put that mapping into `fresh/lambda.py`
* This information should be in the bundle too. along with the input header too.

#### 54
* `54` output probabilities.


### 2020-08-29

#### test entry code

```python
import fresh.lambda_entry as fl

fl.entry(None, None)

bundle = fl.fetch_bundle()
```

* hmm the bundle requires xgboost, which locally (except for Docker) I dont have and lambda also will not have
* making a slimmed bundle w/o the model...

```python
import fresh.predict_utils as fpu
import joblib
bundle = fpu.load_bundle_in_docker()
del bundle['model_bundle']['bundle']['xgb_model']

blahdir = '/opt/program/artifacts/2020-08-19T144654Z'

joblib.dump(bundle, f'{blahdir}/all_bundle_with_stationsdf_except_xgb.joblib')

```
* And then I saved that to my s3 location
* Try main entry func again w/ the no-xgb bundle

```python
import fresh.lambda_entry as fl
bundle = fl.fetch_bundle()
# fl.map_probabilities(bundle, prob_vec, k=5)
```

* hmm got a scikit learn error now

```
ModuleNotFoundError: No module named 'sklearn.preprocessing._label'
```
* not sure if it helps, but going to align my version ..


```
In [92]: sklearn.__version__                                                                                          
Out[92]: '0.20.2'

In [93]: !pip install -U scikit-learn==0.22.1
```
* oh wow... I tried `fetch_bundle` again after that and bingo!

* ok try also w/ map probabilities...

```python
import fresh.lambda_entry as fl
bundle = fl.fetch_bundle()
out = fl.entry(None, None)

fl.map_probabilities(bundle, prob_vec=out['result'][0], k=5)
```
* ok yay... very cool.

```python
In [8]: fl.map_probabilities(bundle, prob_vec=out['result'][0], k=5)                                                      
Out[8]:
[('Bedford-Stuyvesant', 0.18238812685012817),
 ('Vinegar Hill', 0.0740085020661354),
 ('Columbia Street Waterfront District', 0.07334273308515549),
 ('Downtown Brooklyn', 0.07258936762809753),
 ('Fulton Ferry District', 0.0493587926030159)]
```
* Now just need to add the Google Static Map API call in there. And complete.
* Ah I forgot got a few choices w/ what latlng to chose
```python
stationsdf = bundle['stations_bundle']['stationsdf']
df = fl.map_probabilities(bundle, prob_vec=out['result'][0], k=5)                                                      

In [24]: df.merge(stationsdf, on='neighborhood').iloc[:5][['station_name', 'latlng', 'neighborhood']]                     
Out[24]:
                  station_name                        latlng        neighborhood
0  Lexington Ave & Classon Ave      40.68676793,-73.95928168  Bedford-Stuyvesant
1    Franklin Ave & Myrtle Ave          40.694528,-73.958089  Bedford-Stuyvesant
2   Lefferts Pl & Franklin Ave   40.680342423,-73.9557689392  Bedford-Stuyvesant
3     Hancock St & Bedford Ave      40.68216564,-73.95399026  Bedford-Stuyvesant
4      Macon St & Nostrand Ave  40.6809833854,-73.9500479759  Bedford-Stuyvesant


```
* ..
```python
import fresh.lambda_entry as fl
out = fl.entry(None, None)

```

#### Summary
* Ok cool. i have a full end to end glue now, complete with locations on a static map img tag.

#### Next ...
* I want to just add the 'start' location too. Probably different color label too
* Then place the thing into a lambda
* And then the html side needs to TLC .


### 2020-08-30

#### quick lambda test
* can i even access file system on lambda?

```python
import os
def sage_entry(event, context):
    print(os.getcwd())
    print(os.listdir('.'))

```
* heres what i get

```
/var/task
['lambda_function.py']
```

* ok but when i tried to write ... Damn does not allow.
```python
with open('/var/task/temp.blah', 'w') as fd:
    fd.write('cool beans')
```

```
Response:
{
  "errorMessage": "[Errno 30] Read-only file system: '/var/task/temp.blah'",
  "errorType": "OSError",
  "stackTrace": [
    "  File \"/var/task/lambda_function.py\", line 14, in sage_entry\n    with open('/var/task/temp.blah', 'w') as fd:\n"
  ]
}
```
* So going to have to just embed the information I need in the code itself. Not s3. thats fine.

#### the html side...
* My original demo is [here](https://bike-hop-predict.s3.amazonaws.com/index.html)


### 2020-08-31

#### note
*  ok so since cannot write to file system, must change the entry function since cannot use joblib because it requires disk.
* I can still keep the extra info on s3, just use json or pickle instead since those dont need disk.


```python
In [1]: import joblib                                                           

In [2]: import fresh.lambda_entry as fle                                        

In [3]: bundle = fle.fetch_bundle()

In [6]: import pickle                                                           

In [7]: pkl = pickle.dumps(bundle)                                              

In [8]: import fresh.s3utils as fs3                                             


In [12]: loc = 'bikelearn/artifacts/2020-08-19T144654Z/all_bundle_with_stationsdf_except_xgb.pkl'                                                      

In [13]: fs3.write_s3_file(bucket_name, loc, pkl)                               

```

### 2020-09-02

#### update w that pkl..
* ok cool updated code w/ pkl instead of joblib/disk dependence and all good.

### 2020-09-03

#### Next
* test this code on lambda, along w/ docker update on sagemaker
* the lambda entry must also return the img html to the browser ajax call
* fast follow: the "Source station" should also be a special label in the static map diagram too!
* the API Gateway authentication : how to authenticate now?

#### api gateway authentication
* previously I was using the access keys/secrets as inputs to the actual html form. I guess I can still see if that works?
* that's a super bare bones mvp haha. But might as well see if it works.


#### zip
* uploaded the `foo.zip` created like this to lambda..
```
zip   -r foo fresh -i \*.py
```
* but ran into this on lambda darn..

```
Response:
{
  "errorMessage": "Unable to import module 'fresh.lambda_entry': No module named 'pandas'",
  "errorType": "Runtime.ImportModuleError"
}
```

#### tried another sagemaker model endpoint
* hmm but failed with this ..

```
Traceback (most recent call last):
  File "/opt/conda/lib/python3.7/site-packages/flask/app.py", line 2447, in wsgi_app
    response = self.full_dispatch_request()
  File "/opt/conda/lib/python3.7/site-packages/flask/app.py", line 1952, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/opt/conda/lib/python3.7/site-packages/flask/app.py", line 1821, in handle_user_exception
    reraise(exc_type, exc_value, tb)
  File "/opt/conda/lib/python3.7/site-packages/flask/_compat.py", line 39, in reraise
    raise value
  File "/opt/conda/lib/python3.7/site-packages/flask/app.py", line 1950, in full_dispatch_request
    rv = self.dispatch_request()
  File "/opt/conda/lib/python3.7/site-packages/flask/app.py", line 1936, in dispatch_request
    return self.view_functions[rule.endpoint](**req.view_args)
  File "/opt/server/predictor.py", line 82, in ping
    record = make_canned_record()

NameError: name 'make_canned_record' is not defined
```

#### Summary
* updated lambda entry code to return the map html
* tried another sagemaker docker go.
* zip + a lambda build go.

#### Next
* got to fix that sagemaker `make_canned_record` missing dependency
* pandas into lambda layer + retry
* try pipeline again.


### 2020-09-04

#### pandas layer
* Just out of convenience, I ran this in my running docker. ( Thanks to convenient refresher notes [here](https://medium.com/swlh/how-to-add-python-pandas-layer-to-aws-lambda-bab5ea7ced4f) )
```
mkdir python
pip install -t python pandas pytz
rm -r python/numpy*
```
* Not having `zip` in my docker, i ran the zip part on the mac host
```
zip -r python.zip python

# $ ls -lh python.zip
# 16M
```
* And I uploaded this to s3, and built a lambdas layer
* And the dependency was now good. but failed for joblib!.
* I commented out the joblib but then sklearn. Right also forgot about that.


#### summary
* Ok built pandas layer
* uncommented joblib dependency, but found sklearn dependency also needs to be met


#### NExt
* sklearn dependency needs to be layered up too!.
* And as from earlier, got to re-build the docker image w/ the `make_canned_record` fix.

### 2020-09-05

#### add other dependencies to layers...

```
mkdir python
pip install -t python pandas pytz
rm -r python/numpy*

# adding some more...
pip install -t python scikit-learn==0.22.1

```
*  ok ... made another layer for sklearn

```
zip -r python.zip python

# $ ls -lh python.zip
# 70M

rm -r python/scipy* python/numpy* python/pandas* python/pytz* python/dateutil*
rm -r python/six* python/python_dateutil*

# $ ls -lh python.zip
# 9.8M
```


#### zip lambda code again ...
* (because try except around a tqdm import)
* uploaded the `foo.zip` created like this to lambda..
```
zip   -r foo fresh -i \*.py
```

##### Dang also requests...
* separate layer for that ...

```
mkdir python
pip install -t python requests
```
*
```
zip -r python.zip python
# 904K
```

##### Access denied
* hmm need fix permission for s3...
```
"errorMessage": "An error occurred (AccessDenied) when calling the GetObject operation: Access Denied",
```

* Ah ok ... the reason was that (1) I was missing the GetObject IAM policy from my Lambda Role,
* (2) But then also I had an environmental variable ACCESS KEY I was defining in my `fresh/s3utils.py` code , which also did not have the permission
* So Removing the ACCESS KEY from my Lambda environmental variables and adding the permission to the Lambda Role freed up the lambda to use the permission through the IAM Role itself!

##### ok and rebuild the sagemaker docker ...
* ...  and got to repackage the model again think got to do that differently ..

```
cd artifacts/2020-08-19T144654Z

```

* Ok had to repackage the `model.tar.gz` without the `model` dir.
* and now `purple-bottleneck-epsilon` is In Service

#### Next
* Ok so try to hit sagemaker endpoint from the lambda then.


### 2020-09-07

#### Summary
* ok was able to hit sagemaker endpoint from the lambda after some tweaks.
* Also tested the `index.html` form i have on my s3 bucket, with some random data

#### next
* update the client javascript to embed the image from the response .

### 2020-09-08

#### to be easier, just perhaps a script that pushes my client code to s3
* hmm ok i have a deploys script thats deploying,
* but now the static website no longer serves instead now it is just making me download the index.html for some reason .
* weird.

#### Now deplpoy like this
* Deploys my local files to my public s3 bucket which serves my static public website
```python
import fresh.deploy_static as fds
os.environ['S3_DEPLOY_BUCKET'] = 'bike-hop-predict'   
fds.deploy()                                                                                         
# ==>
# copying predict_demo/index.html to bike-hop-predict:::index.html
# copying predict_demo/js/fetch_data.js to bike-hop-predict:::js/fetch_data.js
```

#### Summary
* got a deploy script to s3 static (but needs tweaking)

#### Next
* Got to make the s3 deploy script not cause the s3 static hosting to break .


### 2020-09-09

#### two domain names..?
* This is the one that worked before I uploaded again  https://bike-hop-predict.s3.amazonaws.com/index.html
* And when I went into "Static website hosting" properties of my S3 bucket, I saw this new url I dont recall http://bike-hop-predict.s3-website-us-east-1.amazonaws.com
* But both prompt to just download the `index.html` file now
* and wow [this doc](https://docs.aws.amazon.com/AmazonS3/latest/dev/IndexDocumentSupport.html) has one more..
http://bike-hop-predict.s3-website.us-east-1.amazonaws.com/
* Hmm I also tried again manually uploading through the console, still not working.
* Per [here](https://stackoverflow.com/questions/25734480/website-hosted-on-s3-just-downloads-a-blank-file#25739950) I did check the `Content-type` and it was already `text/html` but I did just edit and save again. Still nothing.

##### ah uploading again
*  scrolling down, content-type must be selected in the beginning and cannot be changed after uploading
* so this time worked!

#### ok now trying to properly edit the html to insert the img
* so far just displaying the raw <img> html as a string literal
* tried `$('#' + output_id).text(JSON.stringify(response));`  that initially was bad because the `JSON.stringify` was escaping the quotation marks weird
* Then I tried without the `JSON.stringify` but still just raw string. except not escaped
* Then tried `document.getElementById(output_id_2).innerHTML=response['map_html'];`  . that worked except for the first try when I left the `"#"` prepended in the `getElementById`

```
Uncaught TypeError: Cannot set property 'innerHTML' of null
    at Object.success (fetch_data.js:408)
    at i (jquery-3.2.0.min.js:2)
    at Object.fireWith [as resolveWith] (jquery-3.2.0.min.js:2)
    at A (jquery-3.2.0.min.js:4)
    at XMLHttpRequest.<anonymous> (jquery-3.2.0.min.js:4)

```
* So yea now works!


#### Summary
* Yay figured out the weirdness around the content type .
* and updated the javascript to properly edit the inner html to insert the meticulously produced `<img>` tag!.


#### Next
* Should update that s3 deploy to actually use the `content-type` as `text/html` if I want to use that again.
* easier authentication for a true easy to use demo.
* and eventually just drop downs much easier to use


### 2020-09-10

#### hmm cognito?
* Ok cool per [docs](https://docs.aws.amazon.com/cognito/latest/developerguide/identity-pools.html#authenticated-and-unauthenticated-identities) I was able to create an "Unautenticated Identity Pool" for "Guests" who do not have to autenticate by definition.
* Wow that's exactly what I need. And this connects to an IAM role too. Quite nifty.
* Also this [starter javascript guide](https://docs.aws.amazon.com/sdk-for-javascript/v2/developer-guide/getting-started-browser.html) first helps with talking to cognito and then connects to Amazon Polly which converts text to speech . Haha.
* So per the steps, I attached `AmazonPollyFullAccess` to my new Unauthenticated Role.
* Ok wow the demo html worked right out of the box.

#### Summary
* Got an unauthenticated cognito identity pool created
* And tried out the identity pool with the Amazon Polly demo. Worked out of the box.

#### Next
* Use this unauthenticated identity pool with my API gateway.

### 2020-09-11

#### javascript plus cognito
* trying to decipher some of the docs like [this one](https://docs.aws.amazon.com/apigateway/latest/developerguide/how-to-generate-sdk-javascript.html)  .. There is something like `"lib/apiGatewayCore/apiGatewayClient.js"`
* The [sdk doc here](https://docs.aws.amazon.com/AWSJavaScriptSDK/latest/AWS/ApiGatewayV2.html) seems to describe managing the APIGateway not actually executing API . Umm ok.
* But reading [here](https://stackoverflow.com/questions/57680057/how-to-use-aws-cognito-to-authenticate-api-gateway) and [here](https://www.codeproject.com/Articles/5255224/Calling-API-Gateway-Cognito-from-JavaScript)  , I think the client makes a call first to get back a "Cognito-signed JWT (JSON Web Token)" and that can be used perhaps in the typical aws signing process, like what I currently use with `aws-sign-web.js`  
* Oh actually [this guide](https://github.com/mcasperson/AWSCognitoJavaScript) looks pretty detailed.
* But according to [here](https://aws-amplify.github.io/docs/) Amplify requires `$ npm install -g @aws-amplify/cli` which is a next level of intensity for sure.

#### Summary
* Created an Authorizer using Cognito.
* Researched how to actually use cognito on javascript. Found some bits and pieces of examples.

#### next
* maybe as a proof of concept, I should figure out how to make the Polly example I have spit out an Authorization token, and try using that  in a vanilla request to the API. Maybe that actually works? Maybe Cognito lets you avoid the whole AWS Signature v4 thing?
* Also interestingly enough maybe since the `AWS.config.credentials` javascript thing seems to have `accessKeyId` and `secretAccessKey` ... maybe that means something?

### 2020-09-12

#### I tried just defining the credentials, but still empty
* Using just this below, did not work

```
AWS.config.region = 'MY_REGION';
AWS.config.credentials = new AWS.CognitoIdentityCredentials({
  IdentityPoolId: 'MY_IDENTITY_POOL'
});
```
* The credentials were blank, as if like uninitialized. Probably they get filled in during the `AWS.Polly()`  service call itself?

#### hmm maybe getGatewayResponse ?
* Perhaps this? https://docs.aws.amazon.com/AWSJavaScriptSDK/latest/AWS/APIGateway.html#getGatewayResponse-property
* Maybe `getGatewayResponse` . will try.
* `getSdkType` , https://docs.aws.amazon.com/AWSJavaScriptSDK/latest/AWS/APIGateway.html#getSdkType-property  , "Calls the GetSdkType API operation. "
* Also [this AWS documentation](https://docs.aws.amazon.com/apigateway/latest/developerguide/how-to-generate-sdk-javascript.html) that says to use something like `var apigClient = apigClientFactory.newClient();` feels outdated.
* There are EC2, S3, Kinesis, and other examples [here](https://docs.aws.amazon.com/sdk-for-javascript/v2/developer-guide/sdk-code-samples.html) but not APIGateway. I would think API Gateway should be a popular request.

#### config example
* Hmm [this doc](https://docs.aws.amazon.com/sdk-for-javascript/v2/developer-guide/global-config-object.html) has this example..

```
var myCredentials = new AWS.CognitoIdentityCredentials({IdentityPoolId:'IDENTITY_POOL_ID'});
var myConfig = new AWS.Config({
  credentials: myCredentials, region: 'us-east-1'
});

// maybe i can then add...
var apigateway = new AWS.APIGateway (myConfig);
var apigateway = new AWS.APIGateway({apiVersion: '2015-07-09',
                   params: {restApiId: 'xxxx',
                       stageName: 'default'}});


apigateway.getGatewayResponse({responseType: "DEFAULT_4XX",
                               restApiId: 'MY_REST_API_ID'}, function(err, data) {
  if (err) console.log(err, err.stack); // an error occurred
  else     console.log(data);           // successful response
});
```
* tried that ^^^ , and got ..

```
GET https://apigateway.us-east-1.amazonaws.com/restapis/xxxx/gatewayresponses/DEFAULT_4XX 403
AccessDeniedException: ....

AccessDeniedException: User: arn:aws:sts::xxxxx:assumed-role/Cognito_BikeLearnUnauth_Role/CognitoIdentityCredentials is not authorized to perform: apigateway:GET on resource: arn:aws:apigateway:us-east-1::/restapis/xxxx/gatewayresponses/DEFAULT_4XX
```
* Actually a pretty informative error. Wish I knew what the right method was though haha. This is definitely not the one.

```
https://{restapi_id}.execute-api.{region}.amazonaws.com/{stage_name}/
```

##### Oh wow I think I found a really good example
* First, I think the answer to the question of how do you invoke APIs is still to use vanilla HTTP GET/POST. That's why I couldnt find anything for that in the javascript sdk.
* and the javascript sdk , as per this [awesome stack overflow question](https://stackoverflow.com/questions/36929336/how-to-call-aws-api-gateway-endpoint-with-cognito-id-configuration#36941672) , is useful for actually getting the Cognito service to spit back out the tokens I need for filling the HTTP Authorization header...

```javascript
AWS.config.region = 'us-east-1'; // Region
AWS.config.credentials = new AWS.CognitoIdentityCredentials({
  IdentityPoolId: 'us-east-1:XXXXXXXXXXXXXXXXXXXXXXXX' // your identity pool id here
});

AWSCognito.config.region = 'us-east-1';
AWSCognito.config.credentials = new AWS.CognitoIdentityCredentials({
  IdentityPoolId: 'us-east-1:XXXXXXXXXXXXXXXXXXXXXXXX' // your identity pool id here
});

var poolData = {
  UserPoolId: 'us-east-1_XXXXXXXX',
  ClientId: 'XXXXXXXXXXXXXXXXXXXXXXXX'
};
var userPool = new AWSCognito.CognitoIdentityServiceProvider.CognitoUserPool(poolData);


var authenticationData = {
  Username: 'user',
  Password: '12345678',
};
var authenticationDetails = new AWSCognito.CognitoIdentityServiceProvider.AuthenticationDetails(authenticationData);
var userData = {
  Username: 'user',
  Pool: userPool
};
var cognitoUser = new AWSCognito.CognitoIdentityServiceProvider.CognitoUser(userData);
cognitoUser.authenticateUser(authenticationDetails, {
  onSuccess: function (result) {
  console.log('access token + ' + result.getAccessToken().getJwtToken());

  AWS.config.credentials = new AWS.CognitoIdentityCredentials({
    IdentityPoolId: 'us-east-1:XXXXXXXXXXXXXXXXXXXX',
    IdentityId: AWS.config.credentials.identityId,
    Logins: {
      'cognito-idp.us-east-1.amazonaws.com/us-east-1_XXXXXX': result.idToken.jwtToken
    }
  });

  AWS.config.credentials.get(function (err) {
    // now I'm using authenticated credentials
    if(err)
    {
      console.log('error in autheticatig AWS'+err);
    }
    else
    {
      console.log(AWS.config.credentials.identityId);

    }
  });
  },

  onFailure: function (err) {
    alert(err);
  }

});

```
* Also [this aws blog post](https://aws.amazon.com/blogs/mobile/use-amazon-cognito-in-your-website-for-simple-aws-authentication/) looks pretty good too.
* kept original above ^^^ from question.. And tweaking below for my case, which is anonymous as opposed to specific user/pass


##### the cognito post kept getting cancelled.
* I just kept seeing `XHR failed loading: POST` . but per [stackoverflow](https://stackoverflow.com/questions/38374549/xhr-failed-loading-post)  , I needed to prevent my form from reloadingthe page because it was killing the XHR !! right. right.
* So I added `action="#0"` into the `<form>` tag. That fixed that problem

* ANOTHER problem was my cognito call I think was running async, finishing after I was actually calling my API Gateway endpoint.
* So I made the function that calls my endpoint as a parameter to the cognito function ...
* That made the code messy but it started to appear to call in sequence.
```javascript
authParametersFromCognito = function(callback, callback_params) {

  AWS.config.region = 'us-east-1';
  AWS.config.credentials = new AWS.CognitoIdentityCredentials({
        IdentityPoolId: 'MY_IDENTITY_POOL'
      });

  AWS.config.credentials.get(function(err) {
    if (err) {
      console.log("Error: "+err);
      return;
    }
    console.log("Cognito Identity Id: " + AWS.config.credentials.identityId);

    authparameters = {
      'accessKeyId': AWS.config.credentials.accessKeyId,
      'secretAccessKey': AWS.config.credentials.secretAccessKey,
      // save for later...?
      // 'sessionToken': AWS.config.credentials.sessionToken
    }
    //
    console.log('parameters from form: ' + JSON.stringify(callback_params));
    callback(callback_params, authparameters, 'out-div', 'out-div-2');
    });
}

```

#### but now a new problem, now my api gateway call is showing CORS weirdness
* not sure why this is happening now or why not before. I thought I already enabled CORS.
```
Access to XMLHttpRequest at 'https://xxxx.execute-api.us-east-1.amazonaws.com/default/myBikelearnSageLambda?birth_year=&rider_gender=&rider_type=&start_station=&start_time=' from origin 'https://bike-hop-predict.s3.amazonaws.com' has been blocked by CORS policy: No 'Access-Control-Allow-Origin' header is present on the requested resource.
```
* Did my resource change?
* This is especially weird, because on the API Gateway, I have this in my "Enable CORS" setting:

```
Access-Control-Allow-Origin*: '*'
```
* And the `'*'` means every origin is allowed.

```
'Content-Type,X-Amz-Date,Authorization,X-Api-Key,X-Amz-Security-Token'
```

##### changing back to original code
* Hmm now I also dont know what happened but now the original code is getting a `401` now. (not a CORS error?)
* But i did switch over to the new authorizer however. so perhaps this is related to new authorization ..
* Ok, and when I switched back to original authorizer, code now works again .


### 2020-09-15

#### try cors  again
* also interesting [stack here](https://stackoverflow.com/questions/48140465/aws-cognito-and-cors-security-concern)
* So trying again now w/ the Cognito approach , and getting back a `401` and a console error again says

```
Access to XMLHttpRequest at https://xxxx.execute-api.us-east-1.amazonaws.com/default/myBikelearnSageLambda?birth_year=&rider_gender=&rider_type=&start_station=&start_time= from origin https://bike-hop-predict.s3.amazonaws.com has been blocked by CORS policy: No 'Access-Control-Allow-Origin' header is present on the requested resource.
```

* and the response from the error is also kind of interesting... maybe I can look that up. Not sure where the console log 'CORS' error is coming from. guess thats the browser itself generating that error?

```
{"readyState":0,"status":0,"statusText":"error"}
```
* But the Cognito call which happens first did not fail and when I look at the credentials in `AWS.config.credentials` , they were filled in .
```
{
			'accessKeyId': AWS.config.credentials.accessKeyId,
			'secretAccessKey': AWS.config.credentials.secretAccessKey,
			// save for later...
			// 'sessionToken': AWS.config.credentials.sessionToken
		}
```

### 2020-09-16

#### That error..
* that `{"readyState":0,"status":0,"statusText":"error"}` response... looks same as [here](https://salesforce.stackexchange.com/questions/158448/response-status-is-0-in-jquery-ajax)  
* And one person notes interestingly, _"A Status Code of 0 means "the browser refused to honor the request." "_ . Good to know haha.
* So that makes me think indeed CORS related still.
* hmm... something tells me I got to use the session token `AWS.config.credentials.sessionToken` in the V4 signature as well. I had been reading about this before as an optional component...
* [v4 troubleshooting](https://docs.aws.amazon.com/general/latest/gr/signature-v4-troubleshooting.html) may be useful later.

#### Security Token Service
* Hmm according to this Note ... [here](https://docs.aws.amazon.com/general/latest/gr/sigv4-create-canonical-request.html)

> You can use temporary security credentials provided by the AWS Security Token Service (AWS STS) to sign a request. The process is the same as using long-term credentials, but when you add signing information to the query string you must add an additional query parameter for the security token. The parameter name is X-Amz-Security-Token, and the parameter's value is the URI-encoded session token (the string you received from AWS STS when you obtained temporary security credentials).
> For some services, you must include the X-Amz-Security-Token query parameter in the canonical (signed) query string. For other services, you add the X-Amz-Security-Token parameter at the end, after you calculate the signature. For details, see the API reference documentation for that service.

* It looks like the `AWS.config.credentials.sessionToken` is the STS token which per above, depends on the service as to where it should go in the request as the `X-Amz-Security-Token` header.
* I dont see the Security Token mentioned [here](https://docs.aws.amazon.com/apigateway/api-reference/signing-requests/) hmm.
* Per [this](https://docs.aws.amazon.com/general/latest/gr/sigv4-add-signature-to-request.html) ...

> You can use temporary security credentials provided by the AWS Security Token Service (AWS STS) to sign a request. The process is the same as using long-term credentials.

* Maybe using `X-Amz-Security-Token` is optional ?  
* this [blog post](https://jun711.github.io/aws/how-to-sign-api-gateway-requests-with-signature-version-4-using-aws-amplify/) although it uses Amplify , but it shows at least the use of the `X-Amz-Security-Token` header following the `x-amz-date` header in the `execute-api` HTTP request. So maybe that's a path to try next?

#### Next
* So per above perhaps I can try use of `X-Amz-Security-Token` as per this blog post.
* Actually haha I am looking at the `aws-sign-web.js` which I have been using all this time... and the `sessionToken` may be provided actually.

### 2020-09-17

#### ok try that bonus sessionToken
* ... I just added that into the `var signer = new awsSignWeb.AwsSigner(config);`
* hmm per [this example](https://jun711.github.io/aws/how-to-sign-api-gateway-requests-with-signature-version-4-using-aws-amplify/) , the `x-amz-security-token` should be part of the headers and part of the "SignedHeaders" section of the "Authorization" header.
* But when I look at `aws-sign-web.js` it includes in the `AWsSigner.prototype.sign` func, but I don't see it in the `headers` which are actually being prepared to be sent.
* So yea perhaps `aws-sign-web.js` doesnt work for using sessionToken out of the box.

#### Also looked at the Cloudwatch API Gateway logs
* Seeing flat out the cognito Authorizer I have set up `hht41e` is being called out in the log and it is simply saying it is unauthorized.

```
(d07215c7-d495-4ecf-9274-e78b4b17e9d5) Starting authorizer: hht41e for request: d07215c7-d495-4ecf-9274-e78b4b17e9d5
(d07215c7-d495-4ecf-9274-e78b4b17e9d5) Unauthorized request: d07215c7-d495-4ecf-9274-e78b4b17e9d5
```

* Also kind of nice the API gateway cloudwatch log also loging the `OPTIONS` request ... and I can see the response headers..
```
(211ac0bb-7227-4a49-836c-f33cd9f3eeea) Method response headers: {Access-Control-Allow-Headers=Content-Type,X-Amz-Date,Authorization,X-Api-Key,X-Amz-Security-Token, Access-Control-Allow-Methods=GET,OPTIONS,POST, Access-Control-Allow-Origin=*, Content-Type=application/json}
```
* So yea most likely the response that is being generated is not allowed in the CORS somehow , so a `401` is masquerading as a `CORS` error. I feel like I've seen this before.

#### Summary
* For sure I now know that Cognito Auth issues are masquerading as CORS issues.

#### Next
* the CORS is for sure obscuring the Authorization error I'm seeing. I think I need to try to use `curl` to troubleshoot the Authorization/ signature itself, possibly just doing the Signature from scratch, maybe I can use python to create the request material since that is a bit easier.
* Then once the using `curl` I get the Cognito Auth straightened out, I can try in a browser again.


### 2020-09-18

#### make a raw python request
* I will use my existing javascript to generate the signature
```python
import requests

API_ID = os.getenv('API_ID')


curl \
Request URL:

x-amz-date: 20200917T143905Z
authorization: AWS4-HMAC-SHA256 Credential=xxxxxxO3UIME/20200917/us-east-1/execute-api/aws4_request, SignedHeaders=accept;host;x-amz-date, Signature=a7626a275f49ac57a5671bfbc81a3ba92a1b9bf772b682a2cece125ce4438625
accept: application/json


headers = {
    'Accept': "application/json",
    'Authorization': "AWS4-HMAC-SHA256 Credential=xxxxxxxGQOIOR/20200918/us-east-1/execute-api/aws4_request, SignedHeaders=accept;host;x-amz-date, Signature=c1f54f3bab31cd958e80293995db1551a4053a6a65abcce1bfd3b204f59a86e6",
    'x-amz-date': "20200918T143405Z"
    }

API_ID = 'xxx'
r = requests.get(url=f'https://{API_ID}.execute-api.us-east-1.amazonaws.com/default/myBikelearnSageLambda?birth_year=&rider_gender=&rider_type=&start_station=&start_time=',
    headers=headers)

```
* Dang. So I dumped the javascript output and called with python requests, but the response was not informative.. just

```python

In [35]: r                                                                                        
Out[35]: <Response [401]>

In [36]: r.json()                                                                                 
Out[36]: {'message': 'Unauthorized'}
```

#### SDK generation
* I was able to download an sdk from api gateway.
* no Cognito there though .

#### Summary
* hmm so it's intriguing that w/ the raw python request, indeed i see the `401` and the CORS issue indeed hides the authentication issue.
* The API Gateway + Incognito + javascript is poorly documented.
* The error message was simply 'Unauthorized' whereas I know in earlier attempts to authenticate against API Gateway using python, I've seen messages like `{'message': 'The request signature we calculated does not match the signature you provided. Check your AWS Secret Access Key and signing method. Consult the service documentation for details.\n\nThe Canonical String for this request should have been...'}`
where the error literally said the `Canonical String` etc..

### 2020-09-19

#### let me see if i can increase the level of error messaging from API Gateway hmm
* Maybe then with more feedback I can get better intel whats going on.
* hmm according to [docs](https://docs.aws.amazon.com/apigateway/latest/developerguide/api-gateway-gatewayResponse-definition.html) , I can control the _Response template_ of errors, and I can add additional information around three areas,
  * `$context`
  * `$stageVariables`
  * ` method.request.param-position.param-name`
* Checking out the [context](https://docs.aws.amazon.com/apigateway/latest/developerguide/api-gateway-mapping-template-reference.html#context-variable-reference) section ... hmm

#### ok i added a new piece of context. going to retest
* I changed the response template to
```
{"message":$context.error.messageString, "validation": $context.error.validationErrorString}
```
```python
def js_to_python(url, raw):
    m = re.search(
            (r'\sAccept: "(?P<accept>[^"]*)"\s'
            r'Authorization: "(?P<auth>[^"]*)"\sx-amz-date: "(?P<date>[^"]*)"'), raw); m.groupdict()
    headers = {}

    headers = {
    'Accept': m['accept'],
    'Authorization': m['auth'],
    'x-amz-date': m['date']
    }

    r = requests.get(url=url,
    headers=headers)
    return r
    # return r.status_code, r.json()
url = f'https://{API_ID}.execute-api.us-east-1.amazonaws.com/default/myBikelearnSageLambda?birth_year=&rider_gender=&rider_type=&start_station=&start_time='

raw = '''
....
'''
r = js_to_python(url, raw)

```
* Damn now `r.json()` failed because response isn't even json...
```
# JSONDecodeError: Expecting value: line 1 column 42 (char 41)
In [75]: r.text                                                                                   
Out[75]: '{"message":"Unauthorized", "validation": }'
```
* Somehow that context was null.

##### I also tried ..
```
{"message":$context.error.messageString, "validation": "$context.error.validationErrorString", "response_type" : "$context.error.responseType", "cognitoAuthenticationType": "$context.identity.cognitoAuthenticationType"}
```
* But got back..
```
Out[78]: '{"message":"Unauthorized", "validation": "", "response_type" : "UNAUTHORIZED", "cognitoAuthenticationType": ""}'
```
* So is that saying that the gateway doesnt see any evidence the request was signed by a Cognito identity. I wonder if thats the case for both Authenticated and Unauthenticated.

* Hmm one positive note, I was able to select the "Enable Access Logging" option on my APIGateway stage, and in CloudWatch I created a new log group. I added that log group's arn to this "Enable Access Logging" area and now requests are getting logged.
* So far the default information is not interesting. But going to look at the [docs](https://docs.aws.amazon.com/apigateway/latest/developerguide/set-up-logging.html) , hopefully some interesting log variables can be added !

### 2020-09-20

#### other logs
* Hmm wondering Authorizer logs? Not seeing those in cloudwatch though
* Maybe there's a Cognito log? hmm cant find

#### trying out python approach for now ...

```python
import aws_v4

# url = f'https://{API_ID}.execute-api.us-east-1.amazonaws.com/default/myBikelearnSageLambda?birth_year=&rider_gender=&rider_type=&start_station=&start_time='
API_ID = 'xxx'
url = f'https://{API_ID}.execute-api.us-east-1.amazonaws.com/default/myBikelearnSageLambda'
request_dict = {
    'birth_year': '', 'rider_gender': '',
    'rider_type': '', 'start_station': '', 'start_time': ''}

raw = '''
....
'''
headers = aws_v4.js_to_python(url, raw)

# from an earlier chrome session
access_key, secret_key = "xxxxxxxX45", "xxxxxxxxx"
region = 'us-east-1'
auth = aws_v4.GET_create_api_gateway_auth(url, request_dict, region, access_key, secret_key)
auth
r = requests.get(url, json=request_dict, headers=auth)
r

```
* Interesting, now I got a response, different from `Unauthorized` finally...
```python
In [35]: r                                                                                                    
Out[35]: <Response [403]>

In [36]: r.text                                                                                               
Out[36]: '{"message":"The security token included in the request is invalid."}'
```
* But I had used access key from yesterday so maybe they were expired by now , maybe a fulle day later.
* Going to try again with a fresh access key...
* ...
```python
url = f'https://{API_ID}.execute-api.us-east-1.amazonaws.com/default/myBikelearnSageLambda'
request_dict = {
    'birth_year': '', 'rider_gender': '',
    'rider_type': '', 'start_station': '', 'start_time': ''}
#
access_key, secret_key = "xxxxxxxT3SS", "xxxxxxxCxH/gP"
region = 'us-east-1'
auth = aws_v4.GET_create_api_gateway_auth(url, request_dict, region, access_key, secret_key)
auth
full_url = f'{url}?{qs}'
r = requests.get(full_url, json=request_dict, headers=auth)
r
```
* Ok, refreshed the access key and yet against getting that `401`
```python
Out[41]: <Response [401]>

In [42]: r.json()                                                                                             
Out[42]:
{'message': 'Unauthorized',
 'validation': '',
 'response_type': 'UNAUTHORIZED',
 'cognitoAuthenticationType': '',
 'path': '/default/myBikelearnSageLambda',
 'user-agent': 'python-requests/2.22.0',
 'caller': ''}
```

##### wow i noticed I did not have the execute api policy on the cognito role
* Ok but I added the `bikeLearnAPIexecute` policy, but still getting the `401` `Unauthorized`
* Going to manufactor another access key and retry ...
* Hmm still no good

##### I switched to the AWS IAM Authorization type briefly
* So that I can test drive that the python signing is good.
* Oddly enough the response in the request was indeed getting backa bout the detail of the Canonical Signature , ( complaining about the recommendation in [this example](https://docs.aws.amazon.com/code-samples/latest/catalog/python-signv4-v4-signing-get-querystring.py.html) to put the X amazon heaaders into the QueryString )
* ...

```python
Out[61]:
(403,
 {'message': "The request signature we calculated does not match the signature you provided. Check your AWS Secret Access Key and signing method. Consult the service documentation for details.\n\nThe Canonical String for this request should have been\n'GET\n/default/myBikelearnSageLambda\nbirth_year=&rider_gender=&rider_type=&start_station=&start_time=\ncontent-type:application/x-amz-json-1.0\nhost:rmuxqpksz2.execute-api.us-east-1.amazonaws.com\nx-amz-date:20200920T211730Z\n\ncontent-type;host;x-amz-date\ne3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855'\n\nThe String-to-Sign should have been\n'AWS4-HMAC-SHA256\n20200920T211730Z\n20200920/us-east-1/execute-api/aws4_request\n2727b324b1a2810f723f1865bb33575dd1944f33b0b9cb7fcb86f975d4aa26fd'\n"})

In [62]: print(r.json()['message'])                                                                            
The request signature we calculated does not match the signature you provided. Check your AWS Secret Access Key and signing method. Consult the service documentation for details.

The Canonical String for this request should have been
'GET
/default/myBikelearnSageLambda
birth_year=&rider_gender=&rider_type=&start_station=&start_time=
content-type:application/x-amz-json-1.0
host:rmuxqpksz2.execute-api.us-east-1.amazonaws.com
x-amz-date:20200920T211730Z

content-type;host;x-amz-date
e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855'

The String-to-Sign should have been
'AWS4-HMAC-SHA256
20200920T211730Z
20200920/us-east-1/execute-api/aws4_request
2727b324b1a2810f723f1865bb33575dd1944f33b0b9cb7fcb86f975d4aa26fd'

```
* I fixed this ^^ and now I'm getting a brand new error, a `415` ...
```python
Out[69]: (415, {'message': 'Unsupported Media Type'})
```
* According to [here](https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/415) the `Content-type` I'm passing, `content_type = 'application/x-amz-json-1.0'` is not good. But it is a recommendation from [here](https://docs.aws.amazon.com/code-samples/latest/catalog/python-signv4-v4-signing-get-post.py.html)  
* Hmm but per [the Querystringt doc](https://docs.aws.amazon.com/code-samples/latest/catalog/python-signv4-v4-signing-get-querystring.py.html) there is actually no mention of `Content-type`
* Hmm, maybe that is only a `POST` thing then?

##### took out that content type now its good
* Cool, so now have working GET as well. just w/o the query string

#### Summary
* I malformed the cognito access keys and the message changed from `Unauthorized` to `"The security token included in the request is invalid."`
* OOps I ended up the `UnauthCognitoRole` I had actually didnt have the required permission to 'execute' the API gateway. I added that. although I still was getting the `401 Unauthorized` so may be some other problems...

#### Next
* Can try the vetted GET code against a token I got from cognito
* maybe maybe longshot is to use the STS token too.
* But if it doesnt work now then a Role misconfiguration or authorizer misconfiguration hmm..

### 2020-09-21

#### try yesterdays `aws_v4.GET_create_api_gateway_auth` func w yesterdays cognito access key

```python

# access key from the cognito... try one from yesterday first...
access_key, secret_key = "xxxxxxx3SS", "xxxxxxxxxmYZ1CxH/gP"
# access_key, secret_key =
region = 'us-east-1'
print(url)
auth = aws_v4.GET_create_api_gateway_auth(url, request_dict, region, access_key, secret_key)
print('full_url', full_url)
print('auth', auth)
r = requests.get(full_url, headers=auth)
r.status_code, r.json()

```
* ok getting
```
Out[79]: (403, {'message': 'The security token included in the request is invalid.'})
```
* Perhaps the token does indeed expire..

#### try `aws_v4.GET_create_api_gateway_auth` with a fresh cognito access key ..

```python
access_key, secret_key = 'xxxxxx3HB', "xxxxxxxxx"
region = 'us-east-1'
print(url)
auth = aws_v4.GET_create_api_gateway_auth(url, request_dict, region, access_key, secret_key)
print('full_url', full_url)
print('auth', auth)
r = requests.get(full_url, headers=auth)
r.status_code, r.json()

```
* hmm same thing
```
Out[80]: (403, {'message': 'The security token included in the request is invalid.'})
```
* wait a second... security token...!! not access key
* Hmm, but [this stackoverflow q](https://stackoverflow.com/questions/56835781/unrecognizedclientexception-the-security-token-included-in-the-request-is-inval)  has an answer that suggests _" Either the accessKeyId or secretAccessKey (or both) are wrong."_
* ( This uses [this ](https://docs.aws.amazon.com/STS/latest/APIReference/API_GetCallerIdentity.html) )
```
aws sts get-caller-identity --cli-input-json
aws sts get-caller-identity --generate-cli-skeleton

aws sts get-caller-identity --cli-input-json '{"AccessKeyId": "xxxxx3HB", "SecretAccessKey": "xxxxxxx"}'

Parameter validation failed:
Unknown parameter in input: "accessKey", must be one of:
Unknown parameter in input: "secretKey", must be one of:
```
* But when I inquire about this cognito generated key like this. .. my account pops back...
```
(pandars3) $ aws --profile adminuser sts get-access-key-info --access-key-id xxxxxxx3HB
{
    "Account": "xxxxxxx"
}
```

* Ok I put the information into my `.aws/credentials` and getting this

```
(pandars3) $ aws --profile tempcognito sts get-caller-identity

An error occurred (InvalidClientTokenId) when calling the GetCallerIdentity operation: The security token included in the request is invalid.
(pandars3) $
```
* SO honestly, this isn't a permission thing... but I think it's something like this token is messed up somehow.

### 2020-09-28

#### hmm
* So to digest previous efforts, the cognito generated keys are real identities, but either they have wrong permissions or I need to use them only with a token? But Per stack overflow
* Per that [that stackoverflow response](https://stackoverflow.com/questions/56835781/unrecognizedclientexception-the-security-token-included-in-the-request-is-inval) about using [GetCallerIdentity ](https://docs.aws.amazon.com/STS/latest/APIReference/API_GetCallerIdentity.html) , I checked and when I use aws cli `sts get-caller-identity` indeed asking about my cognito credential throws a fuss..

#### Next
* Got to keep digging into my Cognito configuration. Tempted to simply try the "authenticated" pool. Just create an identity, see if that works. if so then perhaps thats a good enough proof of concept..


### 2020-09-29

#### back..
* Reading [this stack overflow question](https://stackoverflow.com/questions/36929336/how-to-call-aws-api-gateway-endpoint-with-cognito-id-configuration#36941672) again, per my [earlier notes](oh-wow-i-think-i-found-a-really-good-example)
* I want to try again but authenticated this time..
* reading a comment in there _"If you are using temporary credentials you must include the session token"_ , now I want to try that..

#### session in place of secret...
* I simply put the session_token in place of the secret. (Still got same `Unauthorized` though. )
```python
access_key, secret_key = 'xxxxxxx', "xxxxxxxxx"
session_token = 'IQoJb3JpZ2luX2VjEB4aCXVzLWVhc3QtMSJGMEQxxxxxx........CvHHVcnl8VNFmkWcBuATKqAcgPR7VLOgPu2eCUoswjnj3qQN0'
region = 'us-east-1'
print(url)
auth = aws_v4.GET_create_api_gateway_auth(url, request_dict, region, access_key, session_token)
print('full_url', full_url)
print('auth', auth)
r = requests.get(full_url, headers=auth)
r.status_code, r.json()


```

* Ah ok no that ^^ is wrong according to [doc](https://docs.aws.amazon.com/general/latest/gr/sigv4-add-signature-to-request.html)
* I know i'm probably reading this the second time already probably ...

> You can use temporary security credentials provided by the AWS Security Token Service (AWS STS) to sign a request. The process is the same as using long-term credentials, but requires an additional HTTP header or query string parameter for the security token. The name of the header or query string parameter is X-Amz-Security-Token, and the value is the session token (the string you received from AWS STS when you obtained temporary security credentials).

> When you add the X-Amz-Security-Token parameter to the query string, some services require that you include this parameter in the canonical (signed) request. For other services, you add this parameter at the end, after you calculate the signature. For details, see the API reference documentation for that service.

* Let me try to add this extra token somehow...

```python

access_key, secret_key = 'xxxxx', "xxxxxx"
# session_token = 'IQoJb3JpZ2luX2VjEB4aCXVzLWVhc3QtMSJGMEQCIFJrLe+xIf........CvHHVcnl8VNFmkWcBuATKqAcgPR7VLOgPu2eCUoswjnj3qQN0'
region = 'us-east-1'
print(url)
auth = aws_v4.GET_create_api_gateway_auth(url, request_dict, region, access_key, secret_key,
                                          session_token=session_token)
print('full_url', full_url)
print('auth', auth)
r = requests.get(full_url, headers=auth)
r.status_code, r.json()


```
* Dang still nothing

#### Summary
* Well.. i tried one of the recommendations for placing that session token ... into the canonical header
* Per that doc I referenced ^^ I can also try stuffing into query string or it says for some services it is meant to be included after calculating the signature. Cognito is a subset of STS per research so maybe searching explicitly for STS plus HTTP requests will help know how to do this ...



### 2020-09-30

#### that "Authenticated approach"
* I created a "User Pool". Wow thats intense. Now I have a "Pool Id"
* But I don't see a client id as would be needed in [this example](https://stackoverflow.com/questions/36929336/how-to-call-aws-api-gateway-endpoint-with-cognito-id-configuration#36941672) hmm so this requires more effort indeed


#### also this interesting ipython AWS auth documentation
* [here](https://github.com/MateusAmin/requests-aws-iam-auth/blob/master/requests_aws_iam_auth/api_gateway.py)
* these imports are available in botocore cool..
```python

from botocore.awsrequest import AWSRequest  # type: ignore
from botocore.session import Session  # type: ignore
from botocore.auth import SigV4Auth  # type: ignore
from requests.auth import AuthBase
from requests import PreparedRequest

```
* Hmmm... this example is interesting but it doesnt seem to explain how `x-amz-security-token` is handled. Says not to sign though .


#### Next
* That "Auth" approach seems intense, will put that one off for now,
* But since last time I had signed the `x-amz-security-token` header that I passed, next I would like to try the not signed variation, per the alternative mentioned in the [doc](https://docs.aws.amazon.com/general/latest/gr/sigv4-add-signature-to-request.html) and also in this [github repo example](https://github.com/MateusAmin/requests-aws-iam-auth/)


### 2020-10-02

#### Going to try to add the `x-amz-security-token` unsigned

```python
access_key, secret_key = 'xxxxx', "xxxx"
session_token = "IQoJb3JpZ2luX2xxxxxxJGMaf0Ou2obrtI1jVcNP+kSz3AU+Y26heeXY2qO+jQze00rmUH3jpo"
region = 'us-east-1'
print(url)
# so keeping this session_token=None
auth = aws_v4.GET_create_api_gateway_auth(url, request_dict, region, access_key, secret_key,
                                          session_token=None)
# but add it anyway...
auth['X-Amz-Security-Token'] = session_token
print('full_url', full_url)
print('auth', auth)
r = requests.get(full_url, headers=auth)
r.status_code, r.json()
```
* Damn still didnt work

```
(401,
 {'message': 'Unauthorized',
  'validation': '',
  'response_type': 'UNAUTHORIZED',
  'cognitoAuthenticationType': '',
  'path': '/default/myBikelearnSageLambda',
  'user-agent': 'python-requests/2.22.0',
  'caller': ''})
```

#### not sure what else is there left to try ...
* I am looking at my Authorizer, `CognitoUnAuthAuth` and I'm seeing the User Pool, `a20ce22xxxx-xxx-57d007e7` ,
* But these names are kind of confusing. Does that mean this is authenticated ? Am I setting that up to fail for UnAuth?

#### IAM?
* Hmm I changed over to IAM Authorization since I suspect "Cognito Authorizer" is strictly for "Authenticated" users.
* Now I am actually getting a different error, saying my signature is wrong.. this is promising...
* My `r.status_code` is actually a `403` not a `401`  also..

```python
In [99]: print(r.json()['message'])                                                                            
The request signature we calculated does not match the signature you provided. Check your AWS Secret Access Key and signing method. Consult the service documentation for details.

The Canonical String for this request should have been
'GET
/default/myBikelearnSageLambda
birth_year=&rider_gender=&rider_type=&start_station=&start_time=
host:rmuxqpksz2.execute-api.us-east-1.amazonaws.com
x-amz-date:20201002T143455Z
x-amz-security-token:IQoJb3JpZ2luX2VjEGcaCXVzLWVhc3QtMSJGMEQCIFqo9XllsBZX9ks5oUtzGRo5uDphLoatu9iCDlcIwZ4wAiAdfm07H62eip/yoY/04VFcpxcQqaX5n6gn3cpZeG1qoyqXBgiP//////////8BEAAaDDMyOTM0NTE3MzE2NiIMuzJ6uhwVQd3IZzKdKusF/fPivvLYatXz1mlFCSRWztrC2+4IiZX7mmA2NpWGYYfbzBn+myAL+tx05Q2oxr7AjOU38QnIAhNfG090m/lbo7qFrIbW9E9/NpQQLQ1689edbpV0KgZrB148lbEo44eWRKjvmTus+UPzsRj77zRJoWI/ZDOG20HPJew6YOnqknKkM/z4umsK90qMk/zicraRjzlLai9CKbwSam2j/i0p95deOw/vLLMZQHV5Gu3OztdAMX9vjpz2pTQPccW5xpCqjkV8uaLUCVxSTiklQ0Jl+3ZvA0wC/S3fZfQ6QJFiwsSkueD1EZxDf/4q2i936L/CurdMPxHuj8q2Yh/SLjMLWCMtkL/B2W6zXp80PzAnyPCpcF8vrL1JOrPjaExS/8SlK4JSDikQ81UeNiQ85both2+ErA4gwJQyWg6ukWyc6SqWChlkJseMUSKJaH9v0ZcvpeR08u65MnBuQ7sgf8P1igq7SUzb5NRhBYitqJan1pLDJlDwhz2UJ0dKVh818naWXKmrUnkntyXzxfRx0RTXW95p/GSFsLR/rsQul7nWdHY2TedRCu9rN7REVznZxFySrpjQczUIShoyXqzUxCYnezZETKNKpfGsFKDm8T1pIdLRn0UM4N9Tf+MSsTJgW3+RRo4Aus+P9h/BytPdfNXCD9QwHPmez9qUlo0YxbX57cR+ZjA/jtNE1oocd1To82Ug5RgiPrYJe1gYKli547Iw3goQVD/ay0EUnBa95OyN+7GeNo687/U/0H9l6a3UsZBzl9pgGuQ/2DbVDtsZ3nXrA+9G2GXwMogqxoO8nQ/CPDcE7CPz0orIvd2dViZ7wnf+ukjWcqGSO9pLIq1n0QUG4bI5c8dXfReOmIfkttJ++m6QacgTvAUYv86kY9RDmZmYVaQHAs/lklSKoNwhLAwVLBo4i4XPGA8QiShNlYrzWX0Pltefz2LjYpAHEDRli7BGSf7jx3NJJOyGqRoJdpN7JnttaI+ERspK9Sq5MILu3PsFOogCdfhTu/AwY2af4nlsZq5YEo5fbMoWPICqcn42Ko22K2mFBVpWMqRfu/AN2qNt2pwl/fJXK2Psa9vddZZn78/8C6OBS+ciKsrn+31TZiukfx+K23QnY0CRrUPEoZEbmECMhCs+0mujBFTPmP7RwTaMjrSVPznHD0awwGyAo2r9rRMcXdb9yWcCMU61ELfT1Qyl4+jA0GnTNV4Yv/uvotE9Hu4J1KeupgFmgZA6Mi3o7GmRu8CfOyHgdrZvQP0jxRpWLlVkJZ0j/RulmwkQ9I0+0YpA4fbLkBLBEMwzDBxplQJGMaf0Ou2obrtI1jVcNP+kSz3AU+Y26heeXY2qO+jQze00rmUH3jpo

host;x-amz-date;x-amz-security-token
e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855'

The String-to-Sign should have been
'AWS4-HMAC-SHA256
20201002T143455Z
20201002/us-east-1/execute-api/aws4_request
91e59f1e851dac8c3259bbfc1e12d1a35a800c8301e730155c7f4b12fe8ce31f'
```

* retry like above...
* Hmm for one thing... I had a bug where I was missing the `:` colon after `x-amz-security-token` in the Canonical String !!
* I retried and now getting...

```python
In [103]: print(r.json()['message'])                                                                           
The request signature we calculated does not match the signature you provided. Check your AWS Secret Access Key and signing method. Consult the service documentation for details.

The Canonical String for this request should have been
'GET
/default/myBikelearnSageLambda
birth_year=&rider_gender=&rider_type=&start_station=&start_time=
host:rmuxqpksz2.execute-api.us-east-1.amazonaws.com
x-amz-date:20201002T145056Z
x-amz-security-token:IQoJb3JpZ2luX2VjEGcaCXVzLWVhc3QtMSJGMEQCIFqo9XllsBZX9ks5oUtzGRo5uDphLoatu9iCDlcIwZ4wAiAdfm07H62eip/yoY/04VFcpxcQqaX5n6gn3cpZeG1qoyqXBgiP//////////8BEAAaDDMyOTM0NTE3MzE2NiIMuzJ6uhwVQd3IZzKdKusF/fPivvLYatXz1mlFCSRWztrC2+4IiZX7mmA2NpWGYYfbzBn+myAL+tx05Q2oxr7AjOU38QnIAhNfG090m/lbo7qFrIbW9E9/NpQQLQ1689edbpV0KgZrB148lbEo44eWRKjvmTus+UPzsRj77zRJoWI/ZDOG20HPJew6YOnqknKkM/z4umsK90qMk/zicraRjzlLai9CKbwSam2j/i0p95deOw/vLLMZQHV5Gu3OztdAMX9vjpz2pTQPccW5xpCqjkV8uaLUCVxSTiklQ0Jl+3ZvA0wC/S3fZfQ6QJFiwsSkueD1EZxDf/4q2i936L/CurdMPxHuj8q2Yh/SLjMLWCMtkL/B2W6zXp80PzAnyPCpcF8vrL1JOrPjaExS/8SlK4JSDikQ81UeNiQ85both2+ErA4gwJQyWg6ukWyc6SqWChlkJseMUSKJaH9v0ZcvpeR08u65MnBuQ7sgf8P1igq7SUzb5NRhBYitqJan1pLDJlDwhz2UJ0dKVh818naWXKmrUnkntyXzxfRx0RTXW95p/GSFsLR/rsQul7nWdHY2TedRCu9rN7REVznZxFySrpjQczUIShoyXqzUxCYnezZETKNKpfGsFKDm8T1pIdLRn0UM4N9Tf+MSsTJgW3+RRo4Aus+P9h/BytPdfNXCD9QwHPmez9qUlo0YxbX57cR+ZjA/jtNE1oocd1To82Ug5RgiPrYJe1gYKli547Iw3goQVD/ay0EUnBa95OyN+7GeNo687/U/0H9l6a3UsZBzl9pgGuQ/2DbVDtsZ3nXrA+9G2GXwMogqxoO8nQ/CPDcE7CPz0orIvd2dViZ7wnf+ukjWcqGSO9pLIq1n0QUG4bI5c8dXfReOmIfkttJ++m6QacgTvAUYv86kY9RDmZmYVaQHAs/lklSKoNwhLAwVLBo4i4XPGA8QiShNlYrzWX0Pltefz2LjYpAHEDRli7BGSf7jx3NJJOyGqRoJdpN7JnttaI+ERspK9Sq5MILu3PsFOogCdfhTu/AwY2af4nlsZq5YEo5fbMoWPICqcn42Ko22K2mFBVpWMqRfu/AN2qNt2pwl/fJXK2Psa9vddZZn78/8C6OBS+ciKsrn+31TZiukfx+K23QnY0CRrUPEoZEbmECMhCs+0mujBFTPmP7RwTaMjrSVPznHD0awwGyAo2r9rRMcXdb9yWcCMU61ELfT1Qyl4+jA0GnTNV4Yv/uvotE9Hu4J1KeupgFmgZA6Mi3o7GmRu8CfOyHgdrZvQP0jxRpWLlVkJZ0j/RulmwkQ9I0+0YpA4fbLkBLBEMwzDBxplQJGMaf0Ou2obrtI1jVcNP+kSz3AU+Y26heeXY2qO+jQze00rmUH3jpo

host;x-amz-date;x-amz-security-token
e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855'

The String-to-Sign should have been
'AWS4-HMAC-SHA256
20201002T145056Z
20201002/us-east-1/execute-api/aws4_request
b42ddcd7a1409fed7647a1d684d79d403e47fe2910957f2fb153a0e52c883e8b'
```
* Hmm i can't spot the difference. This all seems actually correct.
* I tried to capture and compare both but getting `True` indeed
```python
In [110]: mycanonical_string == shouldhavebeen_canonical_string                                                
Out[110]: True

In [111]: my_string_to_sign = '''AWS4-HMAC-SHA256
     ...: 20201002T145056Z
     ...: 20201002/us-east-1/execute-api/aws4_request
     ...: b42ddcd7a1409fed7647a1d684d79d403e47fe2910957f2fb153a0e52c883e8b'''                                  

In [112]: should_have_been_string_to_sign = '''AWS4-HMAC-SHA256
     ...: 20201002T145056Z
     ...: 20201002/us-east-1/execute-api/aws4_request
     ...: b42ddcd7a1409fed7647a1d684d79d403e47fe2910957f2fb153a0e52c883e8b'''                                  

In [113]: my_string_to_sign == should_have_been_string_to_sign                                                 
Out[113]: True
```

* maybe expired?

```python

access_key, secret_key = 'xxx', "xxxx"
session_token = "IQoJbxxxxxxxx0if4ipI1eIMgy67npeSUSLMCoHR46YIWG/+yBgCuVOB3vaK7KGysxSQ4cFoABBs8K9qcopDp"
region = 'us-east-1'
print(url)
# so keeping this session_token=None
auth, my_canonical_string, my_string_to_sign = aws_v4.GET_create_api_gateway_auth(url, request_dict, region, access_key, secret_key,
                                          session_token=None)
# but add it anyway...
# auth['X-Amz-Security-Token'] = session_token
print('full_url', full_url)
print('auth', auth)
r = requests.get(full_url, headers=auth)
r.status_code, r.json()

```

* oh my god that finally worked!! wow. so yea perhaps indeed it expires after a little bit of time i might indeed get a message that the signature is bad? Or maybe thats related to time getting mangled in there.


### 2020-10-04
#### Also on python side, tried without the session token
* Since I know now the "Cognito Auth" I had on the API Gateway side was wrong for UnAuth, I tried the python v4 request w/o the session token,
* But getting `Out[122]: (403, {'message': 'The security token included in the request is invalid.'})` so pretty sure now thats required for the temporary STS based authentication.

#### ok did a quick update in fetch_data.js
* quick update and wow now the UnAuth Auth works ! omg yes.

#### ran a quick lambda test
* This is what lambda is seeing in debug in lambda cloudwatch logs..
```
DEBUG,  {'params': {'path': {}, 'querystring': {'birth_year': '', 'rider_gender': '', 'rider_type': '', 'start_station': '', 'start_time': ''}, 'header': {'accept': 'application/json', 'accept-encoding': 'gzip, deflate, br', 'accept-language': 'en-US,en;q=0.9', 'dnt': '1', 'Host': 'xxxxx.execute-api.us-east-1.amazonaws.com', 'origin': 'https://bike-hop-predict.s3.amazonaws.com', 'referer': 'https://bike-hop-predict.s3.amazonaws.com/index.html?', 'sec-fetch-dest': 'empty', 'sec-fetch-mode': 'cors', 'sec-fetch-site': 'cross-site', 'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/85.0.4183.83 Safari/537.36',
```
* And since I know the origin I can actually adjust my CORS accordingly !

#### Next
* Now I just need to deploy lambda that reads the `querystring` input and I'll be set.


### 2020-10-07

#### ok update that code

```sh
# manually make sure git status is clean..
git log --pretty=oneline -n 1 > fresh/git_hash.txt
rm foo.zip # discard last one
zip   -r foo fresh -i \*.py \*.txt
```
* Ok uploaded and first try from browser gives an error darn.

<img src="2020-08-25-glue_files/Screen Shot 2020-10-07 at 10.33.30 AM.png" width="50%">

* Going to check logs. Looks like DEBUG sees my new record like this
```
DEBUG, new record {'starttime': '01/07/2013+00:00:00', 'start station name': 'E+47+St+&+2+Ave', 'usertype': 'Subscriber', 'birth year': '1999', 'gender': '1'}
```
* But my records should look like this
```python
record = {
     'starttime': '2013-07-01 00:00:00',
     'start station name': 'E 47 St & 2 Ave',
     'usertype': 'Customer',
     'birth year': '1999',
     'gender': 0}
```
* Basically just got the send the timestamp as YYYY-MM-DD HH:MM:SS i guess I forgot I changed all that. And undo the `+` plus marks.

<img src="2020-08-25-glue_files/Screen Shot 2020-10-07 at 11.04.11 AM.png" width="50%">

* ok yes! with commit `f58bc74` now actually working fully end to end.
* Got to just make sure I know what is good data to test it out.

#### Next
* I want to next create a bunch of test examples to test out the domain and look at different map outputs. Kinda exciting next part.
* Feels like theres some bug also and output appears to still be the same for two inputs I have tried.


### 2020-10-08

#### some quick local docker testing
* As per my [earlier notes](notes/2020-06-07-local-docker-notes.md)
```sh
. myblahlocal.sh # source my local place where I keep my laptop specific information.
my_local_data_directory=${MY_LOCAL_DATA_DIRECTORY}
docker run -p 8889:8889 -p 8080:8080 -i -t -v $(pwd):/opt/program       \
      -v ${my_local_data_directory}:/opt/data        \
      -v   ~/Downloads:/opt/downloads         \
      -v  $(pwd)/artifacts/2020-08-19T144654Z:/opt/ml   citibike-learn:latest

```
* In docker ... here I have a quick method to get a bunch of test scenarios I should be able to use from my browser.
```python
import pandas as pd
import fresh.utils as fu
import fresh.predict_utils as fpu
bundle = fpu.load_bundle_in_docker()

df = pd.read_csv('/opt/data/2013-07 - Citi Bike trip data.csv')

out = fpu.full_predict(bundle, record=dict(df.iloc[0]))

In [7]: out = fpu.full_predict(bundle, record=dict(df.iloc[0]))
   ...:                                                                                                        
['start_neighborhood', 'gender', 'time_of_day', 'usertype', 'weekday']
[['Midtown East' 0 4 'Customer' 1]]
  0%|                                                                                    | 0/1 [00:00<?, ?it/s]
[[0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0 1]]

In [8]: out                                                                                                    
Out[8]:
(array([[0.00260068, 0.00211338, 0.18238813, 0.04775023, 0.00407627,
         0.03426266, 0.01549505, 0.02768018, 0.00213743, 0.00634305,
         0.02986856, 0.02481377, 0.07334273, 0.07258937, 0.04883923,
         0.00380077, 0.00281027, 0.00450624, 0.03994255, 0.04935879,
         0.00830992, 0.0083217 , 0.00283933, 0.00307513, 0.00572311,
         0.00539479, 0.00300998, 0.0088579 , 0.00437763, 0.00306665,
         0.00585913, 0.00202413, 0.00434052, 0.00435104, 0.00632701,
         0.00504773, 0.00515511, 0.01245811, 0.00278124, 0.02105542,
         0.00562638, 0.01457816, 0.00257211, 0.01134078, 0.03223165,
         0.00336919, 0.00675962, 0.01909184, 0.00364397, 0.0023981 ,
         0.00664525, 0.0740085 , 0.00168374, 0.01895574]], dtype=float32),
 array([2]))

In [9]: df.iloc[0]                                                                                             
Out[9]:
tripduration                               634
starttime                  2013-07-01 00:00:00
stoptime                   2013-07-01 00:10:34
start station id                           164
start station name             E 47 St & 2 Ave
start station latitude                 40.7532
start station longitude               -73.9703
end station id                             504
end station name               1 Ave & E 15 St
end station latitude                   40.7322
end station longitude                 -73.9817
bikeid                                   16950
usertype                              Customer
birth year                                  \N
gender                                       0
Name: 0, dtype: object


```

```python
import numpy as np
sample = np.random.choice(range(df.shape[0]), size=1000, replace=False)

results = df.iloc[sample].apply(lambda x:
    fpu.full_predict(bundle, record=dict(x)),
    axis=1 # df.iloc[0]
  )

#
In [28]: Counter([x[1][0] for x in results])                                                                   
Out[28]: Counter({2: 1000})

In [31]: results[:5]                                                                                           
Out[31]:
# 183224    ([[0.0026006768, 0.002113385, 0.18238813, 0.04...
# 430787    ([[0.0026006768, 0.002113385, 0.18238813, 0.04...
# 381648    ([[0.0026006768, 0.002113385, 0.18238813, 0.04...
# 757405    ([[0.0026006768, 0.002113385, 0.18238813, 0.04...
# 431186    ([[0.0026006768, 0.002113385, 0.18238813, 0.04...
dtype: object

results.to_csv('/opt/downloads/2020-10-08-results.csv')

```
* Ok just looked at these random 1000 outputs. All the predictions here are exactly exactly the same.
* So something super weird is going on. Either that model is indeed fried, or theres a massive bug somewhere in the pipeline.

#### Next
* Find the (hopefully not in the model) bug in the pipe line or model which is pegging all the results of `full_predict` to be exactly the same.

### 2020-10-09

#### I already had debug prints in full predict
* So looking at those some of those, from yesterday, I see the `X` and the _preprocessed_ `X_transformed` arrays are not looking frozen at all.

```python
['start_neighborhood', 'gender', 'time_of_day', 'usertype', 'weekday']
[['Fort Greene' 2 2 'Subscriber' 0]]
  0%|                                                                                    | 0/1 [00:00<?, ?it/s]
[[0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 1.0 0.0 0.0 1 0]]
['start_neighborhood', 'gender', 'time_of_day', 'usertype', 'weekday']
[['Midtown West' 2 3 'Subscriber' 1]]
  0%|                                                                                    | 0/1 [00:00<?, ?it/s]
[[0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 1.0 0.0 1 1]]
['start_neighborhood', 'gender', 'time_of_day', 'usertype', 'weekday']
[['Clinton Hill' 1 3 'Subscriber' 1]]
  0%|                                                                                    | 0/1 [00:00<?, ?it/s]
[[0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0 1 1]]
['start_neighborhood', 'gender', 'time_of_day', 'usertype', 'weekday']
[['Midtown East' 1 4 'Subscriber' 1]]
  0%|                                                                                    | 0/1 [00:00<?, ?it/s]
[[0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
  0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 1.0 1 1]]
```
* Still stepping through an ipdb...
```python
ipdb.runcall(fpu.full_predict, bundle, record=dict(df.iloc[0]))

ipdb> p X_transformed.shape                                                                                    
(1, 85)
```
* Hmm can't spot anything weird here
* I wonder if the input order is somehow messed up. Or if the `85` input shape of my `X_transformed` is off somehow.
* Worst case scenario of course this model itself is somehow frozen.

#### Going to throw some manually created data at it just to see what happens hmm..

```python
import pandas as pd
import numpy as np
import xgboost as xgb

import fresh.utils as fu
import fresh.predict_utils as fpu
bundle = fpu.load_bundle_in_docker()
model = bundle['model_bundle']['bundle']['xgb_model']

# Capturing from earlier...
In [50]: results.iloc[0]                                                                                       
Out[50]:
(array([[0.00260068, 0.00211338, 0.18238813, 0.04775023, 0.00407627,
         0.03426266, 0.01549505, 0.02768018, 0.00213743, 0.00634305,
         0.02986856, 0.02481377, 0.07334273, 0.07258937, 0.04883923,
         0.00380077, 0.00281027, 0.00450624, 0.03994255, 0.04935879,
         0.00830992, 0.0083217 , 0.00283933, 0.00307513, 0.00572311,
         0.00539479, 0.00300998, 0.0088579 , 0.00437763, 0.00306665,
         0.00585913, 0.00202413, 0.00434052, 0.00435104, 0.00632701,
         0.00504773, 0.00515511, 0.01245811, 0.00278124, 0.02105542,
         0.00562638, 0.01457816, 0.00257211, 0.01134078, 0.03223165,
         0.00336919, 0.00675962, 0.01909184, 0.00364397, 0.0023981 ,
         0.00664525, 0.0740085 , 0.00168374, 0.01895574]], dtype=float32),
 array([2]))
frozen_prob_vec, frozen_arg_max = results.iloc[0]


np.array([[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
        0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
        0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
        0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0,
        0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
        0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0,
        0.0, 0.0, 0.0, 0.0, 1.0, 0, 1]],)

X1 = np.random.random(size=(1, 85))
model.predict(xgb.DMatrix(X1))

In [53]: X1                                                                                                    
Out[53]:
array([[0.66391013, 0.99864506, 0.69350251, 0.88719999, 0.14469238,
        0.37122814, 0.01913049, 0.57155392, 0.27280842, 0.61241182,
        0.72901457, 0.81904969, 0.68795549, 0.40358225, 0.76813721,
        0.30276028, 0.03913092, 0.78535682, 0.91529339, 0.71682487,
        0.01367609, 0.88521494, 0.45004401, 0.58287899, 0.21886144,
        0.53850454, 0.84298397, 0.81463873, 0.63851552, 0.35036151,
        0.06359997, 0.69765098, 0.25710927, 0.35467668, 0.05539965,
        0.10291735, 0.87837178, 0.36470324, 0.45305932, 0.78174721,
        0.35577204, 0.26187447, 0.29338407, 0.09584525, 0.83942943,
        0.58295799, 0.57238267, 0.20401032, 0.04527785, 0.68723466,
        0.56461105, 0.30996246, 0.9159496 , 0.48201374, 0.13833313,
        0.84263887, 0.96049939, 0.73290864, 0.06691187, 0.71942848,
        0.24744903, 0.91039479, 0.8428077 , 0.95673655, 0.53124254,
        0.36703251, 0.2267295 , 0.98289566, 0.86595976, 0.31206055,
        0.93004139, 0.7646387 , 0.26331289, 0.38078097, 0.5406475 ,
        0.99098728, 0.66207844, 0.44197275, 0.77417657, 0.3791533 ,
        0.55952619, 0.51686561, 0.83182124, 0.93380519, 0.41839925]])

In [54]: model.predict(xgb.DMatrix(X1))                                                                        
Out[54]:
array([[0.00260068, 0.00211338, 0.18238813, 0.04775023, 0.00407627,
        0.03426266, 0.01549505, 0.02768018, 0.00213743, 0.00634305,
        0.02986856, 0.02481377, 0.07334273, 0.07258937, 0.04883923,
        0.00380077, 0.00281027, 0.00450624, 0.03994255, 0.04935879,
        0.00830992, 0.0083217 , 0.00283933, 0.00307513, 0.00572311,
        0.00539479, 0.00300998, 0.0088579 , 0.00437763, 0.00306665,
        0.00585913, 0.00202413, 0.00434052, 0.00435104, 0.00632701,
        0.00504773, 0.00515511, 0.01245811, 0.00278124, 0.02105542,
        0.00562638, 0.01457816, 0.00257211, 0.01134078, 0.03223165,
        0.00336919, 0.00675962, 0.01909184, 0.00364397, 0.0023981 ,
        0.00664525, 0.0740085 , 0.00168374, 0.01895574]], dtype=float32)

In [55]: np.allclose( model.predict(xgb.DMatrix(X1)), frozen_prob_vec)                                         
Out[55]: True
```
* WOWW... this is wild. Completely random vector produces the same exact output.

* Wondering if this is a phenomenon of not doing a great job of saving or loading to/from cold storage. Maybe something got lost in the process.


#### Next
* hmm need better diagnostics
* Makes me want to write a pre-validation func that testifies the model does not produce completely same output for all the input domain ! dang.
* Then perhaps I can run that on the other models and see if this is the only one with that problem perhaps. (effectively if it has the best accuracy?)

* If that model is indeed bricked, would be handy to know what re-evaluation looks like on the test set again. If the test metrics are the same or not can be the difference between whether the COLD STORAGE bricked this model or if it was born bricked. hmm.

### 2020-10-11

#### Re-run validation
* I luckily stored what my test set was
* Let's see if the same accuracy comes up...
* Ok, running in my laptop docker container...
```
docker run -p 8889:8889 -p 8080:8080 -i -t -v $(pwd):/opt/program       \
       -v  ${my_local_data_directory}:/opt/data        \
       -v  ~/Downloads:/opt/downloads         \
       -v  $(pwd)/artifacts/2020-08-19T144654Z:/opt/ml   citibike-learn:latest
```
```python
import pandas as pd
import numpy as np
import xgboost as xgb

import fresh.utils as fu
import fresh.predict_utils as fpu
bundle = fpu.load_bundle_in_docker()
model = bundle['model_bundle']['bundle']['xgb_model']

In [65]: bundle['model_bundle']['bundle']                                                                      

Out[65]:
{'notebook': '2020-07-10-aws.ipynb',
 'xgb_model': <xgboost.core.Booster at 0x7fb209d6bd90>,
 'train': '/home/ec2-user/SageMaker/learn-citibike/artifacts/2020-07-08T143732Z/train.libsvm',
 'walltime': 1943.61303,
 'primary_dataset': '2013-07 - Citi Bike trip data.csv',
 'input_params': {'max_depth': 5,
  'learning_rate': 0.1,
  'objective': 'multi:softprob',
  'num_class': 54,
  'base_score': 0.5,
  'booster': 'gbtree',
  'colsample_bylevel': 1,
  'colsample_bynode': 1,
  'colsample_bytree': 1.0,
  'gamma': 0,
  'max_delta_step': 0,
  'min_child_weight': 1,
  'random_state': 0,
  'reg_alpha': 0,
  'reg_lambda': 1,
  'scale_pos_weight': 1,
  'seed': 42,
  'subsample': 0.1,
  'verbosity': 0},
 'num_round': 100,
 'validation_metrics': {'accuracy': 0.12171455130090014,
  'balanced_accuracy': 0.10451301995291779,
  'confusion': array([[415,  64,   4, ...,   0, 103,  69],
         [ 56, 541,   4, ...,   0, 130,  27],
         [ 23,  10, 136, ...,   0,  16, 130],
         ...,
         [  2,   0,   2, ...,   1,   3,  36],
         [151, 222,   3, ...,   0, 260,  35],
         [ 84,  25,  46, ...,   0,  29, 861]]),
  'logloss': 3.4335361255637977,
  'test': '/home/ec2-user/SageMaker/learn-citibike/artifacts/2020-07-08T143732Z/test.libsvm',
  'karea': 0.760827309330065}}

```
* So my test set here, per above , is listed as `'test': '/home/ec2-user/SageMaker/learn-citibike/artifacts/2020-07-08T143732Z/test.libsvm',`  but I have also stored this on S3.. and also locally actually
* I can use the techniques [like before](https://github.com/namoopsoo/learn-citibike/blob/2020-revisit/notes/2020-07-16-local.md#i-would-like-to-get-the-train-acc-too-to-better-understand-the-overunder-aka-the-overfittingunderfitting) for validating predictions.
```python
test_loc = (f'/opt/program/artifacts'
         '/2020-07-08T143732Z/'
         'test.libsvm')

dtest = xgb.DMatrix(f'{test_loc}?format=libsvm')
actuals = dtest.get_label()

# Run predict...
%%time
y_prob_vec = model.predict(dtest)
predictions = np.argmax(y_prob_vec, axis=1)
# CPU times: user 1min 9s, sys: 0 ns, total: 1min 9s
# Wall time: 17.6 s

# In [78]: y_prob_vec.shape                                                                                      
# Out[78]: (105427, 54)

# evaluate..
acc = accuracy_score(actuals, predictions)
# In [82]: acc                                                                                                   
# Out[82]: 0.12171455130090014

```
* Ok so that matches exactly  what is in `bundle['model_bundle']['bundle']['validation_metrics']['accuracy']`
* What about frozen predictions here?
```python
from collections import Counter
In [87]: print(dict(Counter(predictions)))                                                                     
{38: 599, 22: 7539, 7: 1630, 18: 3098, 32: 1235, 25: 5895, 15: 1916, 35: 2229, 34: 5138, 8: 9864, 46: 5658, 17: 1042, 10: 947, 33: 7171, 1: 3965, 16: 6314, 41: 331, 29: 4632, 44: 110, 37: 205, 28: 148, 23: 6065, 5: 2291, 12: 344, 52: 3337, 0: 4730, 27: 701, 53: 3041, 43: 1666, 49: 1091, 40: 59, 50: 979, 13: 1611, 3: 44, 11: 2165, 45: 769, 21: 873, 2: 491, 9: 1019, 48: 525, 42: 1109, 4: 160, 20: 400, 24: 453, 39: 70, 14: 686, 6: 280, 31: 249, 19: 231, 30: 210, 47: 68, 26: 24, 51: 20}

```
* OH WOW!!! Thank the lords these predictions are not frozen soooooo the only difference I can think of is that my `full_predict` func does not use `DMatrix` to read a  `libsvm` file , but instead `full_predict` loads a `xgb.DMatrix(X)` using `X` numpy array . So something really weird might be happening in the space of those two methodss???

##### Ok attempt to use libsvm file insstead of numpy directly..
* I haven't used it yet but [dump_svmlight_file](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.dump_svmlight_file.html#sklearn.datasets.dump_svmlight_file) appears to be the inverse of `load_svmlight_file` nice.

```python
from sklearn.datasets import dump_svmlight_file
# Dump numpy to libsvm...

blah_loc = '/opt/downloads/blah.libsvm'
X, yblah = np.random.random(size=(10,10)), np.ones(shape=(10,))
dump_svmlight_file(X, yblah, f=blah_loc)

```
* ....

```python

# So this produced the sameas that frrrooozen predit.. going to try libsvm on this first
X1 = np.random.random(size=(1, 85))
model.predict(xgb.DMatrix(X1))

# not this ... model.predict(xgb.DMatrix(X1))    
blah_loc = '/opt/downloads/blah.libsvm'
X, yblah = np.random.random(size=(1, 85)), np.ones(shape=(1,))
dump_svmlight_file(X, yblah, f=blah_loc)

dblah = xgb.DMatrix(f'{blah_loc}?format=libsvm')
blahactuals = dtest.get_label()

# Run predict...
blah_y_prob_vec = model.predict(dblah)

In [123]: frozen_prob_vec.shape                                                                                
Out[123]: (1, 54)

In [124]: blah_y_prob_vec.shape                                                                                
Out[124]: (1, 54)

In [125]: blah_y_prob_vec                                                                                      
Out[125]:
array([[0.00260068, 0.00211338, 0.18238813, 0.04775023, 0.00407627,
        0.03426266, 0.01549505, 0.02768018, 0.00213743, 0.00634305,
        0.02986856, 0.02481377, 0.07334273, 0.07258937, 0.04883923,
        0.00380077, 0.00281027, 0.00450624, 0.03994255, 0.04935879,
        0.00830992, 0.0083217 , 0.00283933, 0.00307513, 0.00572311,
        0.00539479, 0.00300998, 0.0088579 , 0.00437763, 0.00306665,
        0.00585913, 0.00202413, 0.00434052, 0.00435104, 0.00632701,
        0.00504773, 0.00515511, 0.01245811, 0.00278124, 0.02105542,
        0.00562638, 0.01457816, 0.00257211, 0.01134078, 0.03223165,
        0.00336919, 0.00675962, 0.01909184, 0.00364397, 0.0023981 ,
        0.00664525, 0.0740085 , 0.00168374, 0.01895574]], dtype=float32)

In [126]: frozen_prob_vec                                                                                      
Out[126]:
array([[0.00260068, 0.00211338, 0.18238813, 0.04775023, 0.00407627,
        0.03426266, 0.01549505, 0.02768018, 0.00213743, 0.00634305,
        0.02986856, 0.02481377, 0.07334273, 0.07258937, 0.04883923,
        0.00380077, 0.00281027, 0.00450624, 0.03994255, 0.04935879,
        0.00830992, 0.0083217 , 0.00283933, 0.00307513, 0.00572311,
        0.00539479, 0.00300998, 0.0088579 , 0.00437763, 0.00306665,
        0.00585913, 0.00202413, 0.00434052, 0.00435104, 0.00632701,
        0.00504773, 0.00515511, 0.01245811, 0.00278124, 0.02105542,
        0.00562638, 0.01457816, 0.00257211, 0.01134078, 0.03223165,
        0.00336919, 0.00675962, 0.01909184, 0.00364397, 0.0023981 ,
        0.00664525, 0.0740085 , 0.00168374, 0.01895574]], dtype=float32)

In [127]: dblah.num_col(), dblah.num_row()                                                                     
Out[127]: (85, 1)

```
* Dang what the heck??? So what is so special about `dtest` ??

```python

record = {
     'starttime': '2013-07-01 00:00:00',
     'start station name': 'E 47 St & 2 Ave',
     'usertype': 'Customer',
     'birth year': '1999',
     'gender': 0
     }
Xhmm = X_from_record(bundle, record=record)

hmmmm_loc = '/opt/downloads/hmmmm.libsvm'
yblah = np.ones(shape=(1,))
dump_svmlight_file(Xhmm, yblah, f=hmmmm_loc)

dblah = xgb.DMatrix(f'{hmmmm_loc}?format=libsvm')
# [20:37:49] 1x85 matrix with 4 entries loaded from /opt/downloads/hmmmm.libsvm?format=libsvm

```
* ===> ok wow per the below... this finally looks different..

```python                                                            
# Run predict...
hmmm_y_prob_vec = model.predict(dblah)

In [138]: hmmm_y_prob_vec                                                                                      
Out[138]:
array([[0.01845511, 0.0112169 , 0.00608919, 0.00358758, 0.02280447,
        0.00894809, 0.00416442, 0.01859882, 0.0227448 , 0.01681302,
        0.0115949 , 0.00805871, 0.00163983, 0.01053979, 0.00618187,
        0.01423946, 0.01279947, 0.01256619, 0.01246874, 0.00309547,
        0.02578371, 0.02672892, 0.01732285, 0.03873935, 0.00959205,
        0.04965306, 0.01366295, 0.02828944, 0.00437104, 0.02245426,
        0.00961021, 0.00906411, 0.03759988, 0.13236406, 0.04010247,
        0.05108095, 0.00328353, 0.0088856 , 0.01417809, 0.00381548,
        0.00600353, 0.01121624, 0.00846388, 0.02701668, 0.01104608,
        0.04947915, 0.01212523, 0.01051854, 0.00749311, 0.03515568,
        0.01406138, 0.00103403, 0.01931338, 0.01388424]], dtype=float32)

In [139]: # np.argmax                                                                                          

In [140]: np.argmax(hmmm_y_prob_vec, axis=1)                                                                   
Out[140]: array([33])
#
#
#
#### just to make sure that my blah label indeed doesnt matter?
hmmmm_loc = '/opt/downloads/hmmmm.libsvm'
yblah = np.ones(shape=(1,))
dump_svmlight_file(Xhmm, yblah*2, f=hmmmm_loc)

dblah = xgb.DMatrix(f'{hmmmm_loc}?format=libsvm')
# [20:37:49] 1x85 matrix with 4 entries loaded from /opt/downloads/hmmmm.libsvm?format=libsvm
model.predict(dblah)

[21:16:34] 1x85 matrix with 4 entries loaded from /opt/downloads/hmmmm.libsvm?format=libsvm
Out[144]:
array([[0.01845511, 0.0112169 , 0.00608919, 0.00358758, 0.02280447,
        0.00894809, 0.00416442, 0.01859882, 0.0227448 , 0.01681302,
        0.0115949 , 0.00805871, 0.00163983, 0.01053979, 0.00618187,
        0.01423946, 0.01279947, 0.01256619, 0.01246874, 0.00309547,
        0.02578371, 0.02672892, 0.01732285, 0.03873935, 0.00959205,
        0.04965306, 0.01366295, 0.02828944, 0.00437104, 0.02245426,
        0.00961021, 0.00906411, 0.03759988, 0.13236406, 0.04010247,
        0.05108095, 0.00328353, 0.0088856 , 0.01417809, 0.00381548,
        0.00600353, 0.01121624, 0.00846388, 0.02701668, 0.01104608,
        0.04947915, 0.01212523, 0.01051854, 0.00749311, 0.03515568,
        0.01406138, 0.00103403, 0.01931338, 0.01388424]], dtype=float32)

In [145]: hmmmm_loc                                                                                            
Out[145]: '/opt/downloads/hmmmm.libsvm'

In [146]: !cat /opt/downloads/hmmmm.libsvm                                                                     
2 46:1 75:1 82:1 84:1

```
* Ok cool yea I think it is required to have that label, but it is ignored for predict. Kind of hacky but ok.
* Very strange... so not just libsvm but specifically sparse libsvm made the difference. hmm.


### 2020-10-16

#### Change the display parameters of that static api map ...

* going to experiment, creating some artifact html pages
* But right away I can see the `center` which I have used `Brooklyn+Bridge,New+York,NY` as hard coded, should be changed.
* This is my experimentation capability right now:
```python
# env vars which need to be pre-defined
# GOOGLE_GEO_API_KEY
# GOOGLE_CLIENT_SECRET
# GOOGLE_MAP_TEMPDIR
import fresh.map as fm

locations = [{'latlng': '40.6924182926,-73.989494741'}]

fm.grab_final_thing(locations, debug=True)
```
* ok according to the [docs](https://developers.google.com/maps/documentation/maps-static/start#ImplicitPositioning) you can actually just pass markers and the `size` , without passing the `center` and `zoom` and the "viewport" will be calculated dynamically!
* Capturing some locations from the bundle I have ... (in the docker container)
```python
def subset(d, keys):
    return {k:v for (k,v) in d.items() if k in keys}

locations = [
    subset(dict(x), ['latlng', 'station_name'])
    for x in bundle['stations_bundle']['stationsdf'].iloc[:5].to_dict(orient='records')]
#
[{'station_name': 'Bank St & Hudson St', 'latlng': '40.73652889,-74.00618026'},
 {'station_name': 'E 59 St & Sutton Pl', 'latlng': '40.75849116,-73.95920622'},
 {'station_name': 'E 37 St & Lexington Ave', 'latlng': '40.748238,-73.978311'},
 {'station_name': '9 Ave & W 14 St', 'latlng': '40.7405826,-74.00550867'},
 {'station_name': 'Broadway & W 53 St', 'latlng': '40.76344058,-73.98268129'}]    
```
* And in my general python shell... replaying that...
```python
locations = [{'station_name': 'Bank St & Hudson St', 'latlng': '40.73652889,-74.00618026'},
           {'station_name': 'E 59 St & Sutton Pl', 'latlng': '40.75849116,-73.95920622'},
           {'station_name': 'E 37 St & Lexington Ave', 'latlng': '40.748238,-73.978311'},
           {'station_name': '9 Ave & W 14 St', 'latlng': '40.7405826,-74.00550867'},
           {'station_name': 'Broadway & W 53 St', 'latlng': '40.76344058,-73.98268129'}]
#
fm.grab_final_thing(locations, debug=True)
```

<img src="2020-08-25-glue_files/Screen Shot 2020-10-16 at 4.27.53 PM.png" width="50%">

* Ok wow that works perfectly. Going to update my lambda to use this.


### 2020-10-17

#### quick boto lambda deploy
```python

update_function_code(
    FunctionName=os.getenv('BIKELEARN_LAMBDA'),
    # ZipFile=b'bytes',
    S3Bucket=os.getenv('LAMBDA_S3_BUCKET'),
    S3Key=s3_loc,
    # S3ObjectVersion='string',
    Publish=True,
    DryRun=False,
    RevisionId=last_revision_id
)

# mini permission error
botocore.exceptions.ClientError: An error occurred (AccessDeniedException) when calling the UpdateFunctionCode operation: Your access has been denied by S3, please make sure your request credentials have permission to GetObject for xxxxartifacts/xxxxLambda/85ee3473e2013df6c23461171ce6a5ab94fab532/foo.zip. S3 Error Code: AccessDenied. S3 Error Message: Access Denied
```
* Interesting, so `UpdateFunctionCode` perhaps daisy chains permissions?


### 2020-10-18

#### make date just show the date/time now

```javascript
var d = new Date(2020, 10, 18);
formatDateString(d)

var today = new Date();
formatDateString(today);
```

#### make html dropdown
* in docker...
```python
import json
with open('/opt/downloads/stations.json', 'w') as fd:
    json.dump(stationsdf.station_name.tolist(), fd)  

import fresh.html_utils as fhu

with open('~/Users/Downloads/stations.json') as fd:
    stations = json.load(fd)

html = fhu.make_station_dropdown_html('startStation', stations)
with open('startStation.html', 'w') as fd:
    fd.write(html)



```

### 2020-10-19

#### crap what i change?
* I was not satisfied that lambda exceptions were coming back as `200` on api gateway so I started messing around with the API Gateway integration.
* But I did not really save it before I changed something. I think I deleted the Method Response `200` . I added it back again though still getting the result that lambda is clearly executing properly but final output on browser is now an error and the response is
```json
{"readyState":0,"status":0,"statusText":"error"}
```
which I have seen before, in the case that the browser was not happy .
* Ah indeed thats what the error says

<img src="2020-08-25-glue_files/Screen Shot 2020-10-19 at 12.47.07 PM.png" width="50%">

```
Access to XMLHttpRequest at 'https://xxxx.execute-api.us-east-1.amazonaws.com/default/myBikelearnSageLambda?birth_year=2000&rider_gender=1&rider_type=Subscriber&start_station=Bank%2BSt%2B%26%2BHudson%2BSt&start_time=2020-10-19%2B12%3A37%3A00' from origin 'https://bike-hop-predict.s3.amazonaws.com' has been blocked by CORS policy: No 'Access-Control-Allow-Origin' header is present on the requested resource.
12:45:37.310
```

* Indeed when I look at the response headers on my `GET` request, what I see is no `'Access-Control-Allow-Origin' header` only like this

```
content-length: 1269
content-type: application/json
date: Mon, 19 Oct 2020 16:45:37 GMT
status: 200
x-amz-apigw-id: UqtblHOYoAMFwOw=
x-amzn-requestid: 0b0ccfe3-723e-4952-8237-fb29c0838ebb
x-amzn-trace-id: Root=1-5f8dc2b0-57d9b2ff0391116f38136778;Sampled=0
```

* Ok ! going to try reapplying the CORS from API Gateway side. maye I messed it up some how.
<img src="2020-08-25-glue_files/Screen Shot 2020-10-19 at 12.55.42 PM.png" width="50%">
<img src="2020-08-25-glue_files/Screen Shot 2020-10-19 at 12.56.03 PM.png" width="50%">
* Oh wow thank the heavens that actually worked.
* Going to save the API Gateway snapshot of this just in case. Seriously need some infrastructure as code haha.
