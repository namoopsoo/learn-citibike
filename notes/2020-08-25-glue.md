

#### making the tarball from the joblib..

```
cd artifacts/2020-08-19T144654Z

ls
# => all_bundle_with_stationsdf.joblib

mkdir model

mv all_bundle_with_stationsdf.joblib model

tar -czf model.tar.gz model
# => creates model.tar.gz , which I can throw into a SageMaker model.

```

#### troubleshoot docker does not run serve command...
- is it not executable? Wrong work dir?

```
$ docker run -p 8889:8889 -p 8080:8080 -i -t -v $(pwd):/opt/program       \
      -v ${my_local_data_directory}:/opt/data        \
      -v   ~/Downloads:/opt/downloads         \
      -v  $(pwd)/artifacts/2020-08-19T144654Z:/opt/ml   citibike-learn:latest  serve

docker: Error response from daemon: OCI runtime create failed: container_linux.go:349: starting container process caused "exec: \"serve\": executable file not found in $PATH": unknown.



```

* Maybe some help [here](https://stackoverflow.com/questions/27158840/docker-executable-file-not-found-in-path) , or [here](https://docs.docker.com/engine/reference/builder/#/cmd)  , with the use of a `CMD` word in the `Dockerfile` .


### 2020-08-26

#### dockerfile
* ok i had just needed to add `/opt/server` to the `PATH` and that fixed it


#### for the probabily outputs from xgboost, got to map those to neighborhoods
* this is the next thing
* and put that mapping into `fresh/lambda.py`
* This information should be in the bundle too. along with the input header too.

#### 54
* `54` output probabilities.


### 2020-08-29

#### test entry code

```python
import fresh.lambda_entry as fl

fl.entry(None, None)

bundle = fl.fetch_bundle()
```

* hmm the bundle requires xgboost, which locally (except for Docker) I dont have and lambda also will not have
* making a slimmed bundle w/o the model...

```python
import fresh.predict_utils as fpu
import joblib
bundle = fpu.load_bundle_in_docker()
del bundle['model_bundle']['bundle']['xgb_model']

blahdir = '/opt/program/artifacts/2020-08-19T144654Z'

joblib.dump(bundle, f'{blahdir}/all_bundle_with_stationsdf_except_xgb.joblib')

```
* And then I saved that to my s3 location
* Try main entry func again w/ the no-xgb bundle

```python
import fresh.lambda_entry as fl
bundle = fl.fetch_bundle()
# fl.map_probabilities(bundle, prob_vec, k=5)
```

* hmm got a scikit learn error now

```
ModuleNotFoundError: No module named 'sklearn.preprocessing._label'
```
* not sure if it helps, but going to align my version ..


```
In [92]: sklearn.__version__                                                                                          
Out[92]: '0.20.2'

In [93]: !pip install -U scikit-learn==0.22.1
```
* oh wow... I tried `fetch_bundle` again after that and bingo!

* ok try also w/ map probabilities...

```python
import fresh.lambda_entry as fl
bundle = fl.fetch_bundle()
out = fl.entry(None, None)

fl.map_probabilities(bundle, prob_vec=out['result'][0], k=5)
```
* ok yay... very cool.

```python
In [8]: fl.map_probabilities(bundle, prob_vec=out['result'][0], k=5)                                                      
Out[8]:
[('Bedford-Stuyvesant', 0.18238812685012817),
 ('Vinegar Hill', 0.0740085020661354),
 ('Columbia Street Waterfront District', 0.07334273308515549),
 ('Downtown Brooklyn', 0.07258936762809753),
 ('Fulton Ferry District', 0.0493587926030159)]
```
* Now just need to add the Google Static Map API call in there. And complete.
* Ah I forgot got a few choices w/ what latlng to chose
```python
stationsdf = bundle['stations_bundle']['stationsdf']
df = fl.map_probabilities(bundle, prob_vec=out['result'][0], k=5)                                                      

In [24]: df.merge(stationsdf, on='neighborhood').iloc[:5][['station_name', 'latlng', 'neighborhood']]                     
Out[24]:
                  station_name                        latlng        neighborhood
0  Lexington Ave & Classon Ave      40.68676793,-73.95928168  Bedford-Stuyvesant
1    Franklin Ave & Myrtle Ave          40.694528,-73.958089  Bedford-Stuyvesant
2   Lefferts Pl & Franklin Ave   40.680342423,-73.9557689392  Bedford-Stuyvesant
3     Hancock St & Bedford Ave      40.68216564,-73.95399026  Bedford-Stuyvesant
4      Macon St & Nostrand Ave  40.6809833854,-73.9500479759  Bedford-Stuyvesant


```
* ..
```python
import fresh.lambda_entry as fl
out = fl.entry(None, None)

```

#### Summary
* Ok cool. i have a full end to end glue now, complete with locations on a static map img tag.

#### Next ...
* I want to just add the 'start' location too. Probably different color label too
* Then place the thing into a lambda
* And then the html side needs to TLC .


### 2020-08-30

#### quick lambda test
* can i even access file system on lambda?

```python
import os
def sage_entry(event, context):
    print(os.getcwd())
    print(os.listdir('.'))

```
* heres what i get

```
/var/task
['lambda_function.py']
```

* ok but when i tried to write ... Damn does not allow.
```python
with open('/var/task/temp.blah', 'w') as fd:
    fd.write('cool beans')
```

```
Response:
{
  "errorMessage": "[Errno 30] Read-only file system: '/var/task/temp.blah'",
  "errorType": "OSError",
  "stackTrace": [
    "  File \"/var/task/lambda_function.py\", line 14, in sage_entry\n    with open('/var/task/temp.blah', 'w') as fd:\n"
  ]
}
```
* So going to have to just embed the information I need in the code itself. Not s3. thats fine.

#### the html side...
* My original demo is [here](https://bike-hop-predict.s3.amazonaws.com/index.html)


### 2020-08-31

#### note
*  ok so since cannot write to file system, must change the entry function since cannot use joblib because it requires disk.
* I can still keep the extra info on s3, just use json or pickle instead since those dont need disk.


```python
In [1]: import joblib                                                           

In [2]: import fresh.lambda_entry as fle                                        

In [3]: bundle = fle.fetch_bundle()

In [6]: import pickle                                                           

In [7]: pkl = pickle.dumps(bundle)                                              

In [8]: import fresh.s3utils as fs3                                             


In [12]: loc = 'bikelearn/artifacts/2020-08-19T144654Z/all_bundle_with_stationsdf_except_xgb.pkl'                                                      

In [13]: fs3.write_s3_file(bucket_name, loc, pkl)                               

```

### 2020-09-02

#### update w that pkl..
* ok cool updated code w/ pkl instead of joblib/disk dependence and all good.

### 2020-09-03

#### Next
* test this code on lambda, along w/ docker update on sagemaker
* the lambda entry must also return the img html to the browser ajax call
* fast follow: the "Source station" should also be a special label in the static map diagram too!
* the API Gateway authentication : how to authenticate now?

#### api gateway authentication
* previously I was using the access keys/secrets as inputs to the actual html form. I guess I can still see if that works?
* that's a super bare bones mvp haha. But might as well see if it works.


#### zip
* uploaded the `foo.zip` created like this to lambda..
```
zip   -r foo fresh -i \*.py
```
* but ran into this on lambda darn..

```
Response:
{
  "errorMessage": "Unable to import module 'fresh.lambda_entry': No module named 'pandas'",
  "errorType": "Runtime.ImportModuleError"
}
```

#### tried another sagemaker model endpoint
* hmm but failed with this ..

```
Traceback (most recent call last):
  File "/opt/conda/lib/python3.7/site-packages/flask/app.py", line 2447, in wsgi_app
    response = self.full_dispatch_request()
  File "/opt/conda/lib/python3.7/site-packages/flask/app.py", line 1952, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/opt/conda/lib/python3.7/site-packages/flask/app.py", line 1821, in handle_user_exception
    reraise(exc_type, exc_value, tb)
  File "/opt/conda/lib/python3.7/site-packages/flask/_compat.py", line 39, in reraise
    raise value
  File "/opt/conda/lib/python3.7/site-packages/flask/app.py", line 1950, in full_dispatch_request
    rv = self.dispatch_request()
  File "/opt/conda/lib/python3.7/site-packages/flask/app.py", line 1936, in dispatch_request
    return self.view_functions[rule.endpoint](**req.view_args)
  File "/opt/server/predictor.py", line 82, in ping
    record = make_canned_record()

NameError: name 'make_canned_record' is not defined
```

#### Summary
* updated lambda entry code to return the map html
* tried another sagemaker docker go.
* zip + a lambda build go.

#### Next
* got to fix that sagemaker `make_canned_record` missing dependency
* pandas into lambda layer + retry
* try pipeline again.


### 2020-09-04

#### pandas layer
* Just out of convenience, I ran this in my running docker. ( Thanks to convenient refresher notes [here](https://medium.com/swlh/how-to-add-python-pandas-layer-to-aws-lambda-bab5ea7ced4f) )
```
mkdir python
pip install -t python pandas pytz
rm -r python/numpy*
```
* Not having `zip` in my docker, i ran the zip part on the mac host
```
zip -r python.zip python

# $ ls -lh python.zip
# 16M
```
* And I uploaded this to s3, and built a lambdas layer
* And the dependency was now good. but failed for joblib!.
* I commented out the joblib but then sklearn. Right also forgot about that.


#### summary
* Ok built pandas layer
* uncommented joblib dependency, but found sklearn dependency also needs to be met


#### NExt
* sklearn dependency needs to be layered up too!.
* And as from earlier, got to re-build the docker image w/ the `make_canned_record` fix.

### 2020-09-05

#### add other dependencies to layers...

```
mkdir python
pip install -t python pandas pytz
rm -r python/numpy*

# adding some more...
pip install -t python scikit-learn==0.22.1

```
*  ok ... made another layer for sklearn

```
zip -r python.zip python

# $ ls -lh python.zip
# 70M

rm -r python/scipy* python/numpy* python/pandas* python/pytz* python/dateutil*
rm -r python/six* python/python_dateutil*

# $ ls -lh python.zip
# 9.8M
```


#### zip lambda code again ...
* (because try except around a tqdm import)
* uploaded the `foo.zip` created like this to lambda..
```
zip   -r foo fresh -i \*.py
```

##### Dang also requests...
* separate layer for that ...

```
mkdir python
pip install -t python requests
```
*
```
zip -r python.zip python
# 904K
```

##### Access denied
* hmm need fix permission for s3...
```
"errorMessage": "An error occurred (AccessDenied) when calling the GetObject operation: Access Denied",
```

* Ah ok ... the reason was that (1) I was missing the GetObject IAM policy from my Lambda Role,
* (2) But then also I had an environmental variable ACCESS KEY I was defining in my `fresh/s3utils.py` code , which also did not have the permission
* So Removing the ACCESS KEY from my Lambda environmental variables and adding the permission to the Lambda Role freed up the lambda to use the permission through the IAM Role itself!

##### ok and rebuild the sagemaker docker ...
* ...  and got to repackage the model again think got to do that differently ..

```
cd artifacts/2020-08-19T144654Z

```

* Ok had to repackage the `model.tar.gz` without the `model` dir.
* and now `purple-bottleneck-epsilon` is In Service

#### Next
* Ok so try to hit sagemaker endpoint from the lambda then.


### 2020-09-07

#### Summary
* ok was able to hit sagemaker endpoint from the lambda after some tweaks.
* Also tested the `index.html` form i have on my s3 bucket, with some random data

#### next
* update the client javascript to embed the image from the response .

### 2020-09-08

#### to be easier, just perhaps a script that pushes my client code to s3
* hmm ok i have a deploys script thats deploying,
* but now the static website no longer serves instead now it is just making me download the index.html for some reason .
* weird.

#### Summary
* got a deploy script to s3 static (but needs tweaking)

#### Next
* Got to make the s3 deploy script not cause the s3 static hosting to break .


### 2020-09-09

#### two domain names..?
* This is the one that worked before I uploaded again  https://bike-hop-predict.s3.amazonaws.com/index.html
* And when I went into "Static website hosting" properties of my S3 bucket, I saw this new url I dont recall http://bike-hop-predict.s3-website-us-east-1.amazonaws.com
* But both prompt to just download the `index.html` file now
* and wow [this doc](https://docs.aws.amazon.com/AmazonS3/latest/dev/IndexDocumentSupport.html) has one more..
http://bike-hop-predict.s3-website.us-east-1.amazonaws.com/
* Hmm I also tried again manually uploading through the console, still not working.
* Per [here](https://stackoverflow.com/questions/25734480/website-hosted-on-s3-just-downloads-a-blank-file#25739950) I did check the `Content-type` and it was already `text/html` but I did just edit and save again. Still nothing.

##### ah uploading again
*  scrolling down, content-type must be selected in the beginning and cannot be changed after uploading
* so this time worked!

#### ok now trying to properly edit the html to insert the img
* so far just displaying the raw <img> html as a string literal
* tried `$('#' + output_id).text(JSON.stringify(response));`  that initially was bad because the `JSON.stringify` was escaping the quotation marks weird
* Then I tried without the `JSON.stringify` but still just raw string. except not escaped
* Then tried `document.getElementById(output_id_2).innerHTML=response['map_html'];`  . that worked except for the first try when I left the `"#"` prepended in the `getElementById`

```
Uncaught TypeError: Cannot set property 'innerHTML' of null
    at Object.success (fetch_data.js:408)
    at i (jquery-3.2.0.min.js:2)
    at Object.fireWith [as resolveWith] (jquery-3.2.0.min.js:2)
    at A (jquery-3.2.0.min.js:4)
    at XMLHttpRequest.<anonymous> (jquery-3.2.0.min.js:4)

```
* So yea now works!


#### Summary
* Yay figured out the weirdness around the content type .
* and updated the javascript to properly edit the inner html to insert the meticulously produced `<img>` tag!.


#### Next
* Should update that s3 deploy to actually use the `content-type` as `text/html` if I want to use that again.
* easier authentication for a true easy to use demo.
* and eventually just drop downs much easier to use


### 2020-09-10

#### hmm cognito?
* Ok cool per [docs](https://docs.aws.amazon.com/cognito/latest/developerguide/identity-pools.html#authenticated-and-unauthenticated-identities) I was able to create an "Unautenticated Identity Pool" for "Guests" who do not have to autenticate by definition.
* Wow that's exactly what I need. And this connects to an IAM role too. Quite nifty.
* Also this [starter javascript guide](https://docs.aws.amazon.com/sdk-for-javascript/v2/developer-guide/getting-started-browser.html) first helps with talking to cognito and then connects to Amazon Polly which converts text to speech . Haha.
* So per the steps, I attached `AmazonPollyFullAccess` to my new Unauthenticated Role.
* Ok wow the demo html worked right out of the box.

#### Summary
* Got an unauthenticated cognito identity pool created
* And tried out the identity pool with the Amazon Polly demo. Worked out of the box.

#### Next
* Use this unauthenticated identity pool with my API gateway.

### 2020-09-11

#### javascript plus cognito
* trying to decipher some of the docs like [this one](https://docs.aws.amazon.com/apigateway/latest/developerguide/how-to-generate-sdk-javascript.html)  .. There is something like `"lib/apiGatewayCore/apiGatewayClient.js"`
* The [sdk doc here](https://docs.aws.amazon.com/AWSJavaScriptSDK/latest/AWS/ApiGatewayV2.html) seems to describe managing the APIGateway not actually executing API . Umm ok.
* But reading [here](https://stackoverflow.com/questions/57680057/how-to-use-aws-cognito-to-authenticate-api-gateway) and [here](https://www.codeproject.com/Articles/5255224/Calling-API-Gateway-Cognito-from-JavaScript)  , I think the client makes a call first to get back a "Cognito-signed JWT (JSON Web Token)" and that can be used perhaps in the typical aws signing process, like what I currently use with `aws-sign-web.js`  
* Oh actually [this guide](https://github.com/mcasperson/AWSCognitoJavaScript) looks pretty detailed.
* But according to [here](https://aws-amplify.github.io/docs/) Amplify requires `$ npm install -g @aws-amplify/cli` which is a next level of intensity for sure.

#### Summary
* Created an Authorizer using Cognito.
* Researched how to actually use cognito on javascript. Found some bits and pieces of examples.

#### next
* maybe as a proof of concept, I should figure out how to make the Polly example I have spit out an Authorization token, and try using that  in a vanilla request to the API. Maybe that actually works? Maybe Cognito lets you avoid the whole AWS Signature v4 thing? 
