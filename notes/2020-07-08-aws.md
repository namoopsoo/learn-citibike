
using a new version of balancing that is giving me a better balancing per std

end result: compared with "2020-07-03-aws.md" , I am not really seeing much of a difference. 
the balanced test accuracy perhaps looks every so slightly better but probably not significantly.


```python
import pandas as pd
import xgboost as xgb
from xgboost import XGBClassifier
import datetime; import pytz
import matplotlib.pyplot as plt
# from scipy.special import softmax
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import train_test_split # (*arrays, **options)
import numpy as np
from sklearn.metrics import log_loss
from sklearn.preprocessing import OneHotEncoder, LabelEncoder

from joblib import dump, load
import joblib
import os
from sklearn.metrics import confusion_matrix, mean_squared_error
from sklearn.model_selection import KFold, train_test_split, GridSearchCV
from sklearn.metrics import accuracy_score, balanced_accuracy_score
import fresh.utils as fu

from importlib import reload
from collections import Counter
from tqdm.notebook import tqdm
import fresh.preproc.v1 as pv1
import fresh.preproc.v2 as pv2
import fresh.tests.utils as ftu
```


```python

reload(fu)
```




    <module 'fresh.utils' from '/home/ec2-user/SageMaker/learn-citibike/fresh/utils.py'>




```python
# Testing out a new array rebalancing ()
newarray = ftu.make_skewed_array(skew=[.1, .1, .3, .4, .1]) 

proportions = np.array(list(fu.get_proportions(newarray).values()))
print('original proportion std, ', np.std(proportions))
new_prop_v1 = fu.rebalance_proportions(proportions)
print('std after rebalance v1', np.std(new_prop_v1))
new_prop_v2 = fu.rebalance_proportions_v2(proportions)
print('std after rebalance v2', np.std(new_prop_v2))


```

    original proportion std,  0.13162160916809976
    std after rebalance v1 0.1000346111815388
    std after rebalance v2 0.03263032119830371



```python
# ok at least using standard deviation of the proportions, this new balancing, 
# looks better than the original...
```


```python
# localdir = '/opt/program'  # laptop docker 
localdir = '/home/ec2-user/SageMaker/learn-citibike'  # sagemaker
datadir = f'{localdir}/local_datas'

tripsdf = pd.read_csv(f'{datadir}/2013-07 - Citi Bike trip data.csv'
                     )#.sample(frac=0.017, random_state=42)
stationsdf = pd.read_csv(f'{localdir}/datas/stations/stations-2018-12-04-c.csv',
                        index_col=0)
```


```python
X, y, neighborhoods = fu.prepare_data(tripsdf, stationsdf)

```


```python
X.shape, y.shape, fu.get_proportions(y)

```




    ((843416, 5),
     (843416,),
     {'Stuyvesant Town': 0.0137654490785093,
      'Gramercy Park': 0.016522095857797337,
      'Theater District': 0.02566704923786127,
      'East Village': 0.016433171768142886,
      'Chelsea': 0.10993507355800697,
      'Union Square': 0.01358285828108549,
      'Rose Hill': 0.007547876729869957,
      'Midtown West': 0.0363011847060051,
      'Midtown East': 0.04896278941827046,
      'Murray Hill': 0.021488802678630712,
      'Midtown': 0.03108311912508181,
      'Ukrainian Village': 0.025094378100486592,
      'Nolita': 0.013509347700304476,
      'Garment District': 0.018445227503390973,
      'Lower East Side': 0.03171981560700769,
      'West Village': 0.04267526345243628,
      'Central Park': 0.006889838466427006,
      'Alphabet City': 0.022391085774991226,
      'Greenwich Village': 0.0476123289100515,
      'Kips Bay': 0.029481299856772933,
      "Hell's Kitchen": 0.044096863232378804,
      'Peter Cooper Village': 0.0034289128970757016,
      'Financial District': 0.04275707361491838,
      'NoHo': 0.00420433095886253,
      'NoMad': 0.00718506644407979,
      'Flatiron District': 0.019049911313041252,
      'Lincoln Square': 0.011050300207726673,
      'SoHo': 0.01590792681191725,
      'Fort Greene': 0.01977434623009286,
      'Tribeca': 0.046968518500953266,
      'Bowery': 0.01772197824086809,
      'Brooklyn Heights': 0.010232198582905708,
      'Two Bridges': 0.006070551187077314,
      'Park Slope': 0.002418735238601117,
      'Chinatown': 0.014954660570821517,
      'Sutton Place': 0.0010564181850948999,
      'Battery Park City': 0.0287284092310319,
      'Hudson Square': 0.01143445227503391,
      'Tudor City': 0.0014488698341032183,
      'Little Italy': 0.003407571115558633,
      'Lower Manhattan': 0.017927096474337694,
      'Korea Town': 0.004239900594724312,
      'Civic Center': 0.013253246322099652,
      'Downtown Brooklyn': 0.016035977501019663,
      'Bedford-Stuyvesant': 0.005347301924554431,
      'Boerum Hill': 0.0039980270708642,
      'Williamsburg': 0.014461428286871485,
      'Clinton Hill': 0.008885295038272928,
      'Meatpacking District': 0.009344143340889904,
      'Dumbo': 0.006646779288038168,
      'Brooklyn Navy Yard': 0.0030530604114695475,
      'Fulton Ferry District': 0.002557456818462064,
      'Vinegar Hill': 0.0009876502224287897,
      'Columbia Street Waterfront District': 0.0022574862226943763})




```python
X_balanced, y_balanced = fu.balance_dataset_v2(X, y, shrinkage=.5)
X_balanced.shape, y_balanced.shape, fu.get_proportions(y_balanced)
```




    ((421708, 5),
     (421708,),
     {'Financial District': 0.029684046781185084,
      'Peter Cooper Village': 0.006857825794151403,
      'Lower East Side': 0.027580695647225095,
      'Lower Manhattan': 0.02281199313268897,
      'Fulton Ferry District': 0.005114913636924128,
      'Korea Town': 0.00846557333510391,
      'Vinegar Hill': 0.0019753004448575793,
      'Sutton Place': 0.0021128363701897997,
      'Greenwich Village': 0.02974570081667884,
      'Gramercy Park': 0.021882439982167757,
      'Little Italy': 0.006815142231117266,
      'Boerum Hill': 0.007993682832670948,
      'NoMad': 0.013295929885133789,
      'Brooklyn Heights': 0.016841036926024643,
      'Nolita': 0.019985392736206094,
      'Fort Greene': 0.0237012340292335,
      'Stuyvesant Town': 0.02028654898650251,
      'Chelsea': 0.03309398920580117,
      'Midtown': 0.027538012084190957,
      'Bedford-Stuyvesant': 0.010495413888282889,
      'Downtown Brooklyn': 0.021974921035408386,
      "Hell's Kitchen": 0.029622392745691332,
      'Ukrainian Village': 0.02565519269257401,
      'Park Slope': 0.004837470477202234,
      'Tribeca': 0.0302175913191118,
      'Clinton Hill': 0.015389795782863973,
      'Murray Hill': 0.024476652091020328,
      'Garment District': 0.02306335189277889,
      'Civic Center': 0.019667637322507515,
      'West Village': 0.02920978496969467,
      'Columbia Street Waterfront District': 0.004514972445388753,
      'Chinatown': 0.020862777087463362,
      'NoHo': 0.008401547990552705,
      'Kips Bay': 0.027296138560330845,
      'Brooklyn Navy Yard': 0.006106120822939095,
      'Flatiron District': 0.023283883635121932,
      'SoHo': 0.021481688751458356,
      'Rose Hill': 0.013739364678877328,
      'Two Bridges': 0.01160755783622791,
      'Theater District': 0.025892323598319215,
      'Bowery': 0.022781166114942093,
      'Tudor City': 0.0028977396682064367,
      'East Village': 0.021993891507868003,
      'Midtown West': 0.028747379703491515,
      'Battery Park City': 0.02668434082350821,
      'Alphabet City': 0.025010196628947046,
      'Lincoln Square': 0.01789152683847591,
      'Williamsburg': 0.020798751742912156,
      'Midtown East': 0.030312443681409885,
      'Dumbo': 0.012347406262152959,
      'Central Park': 0.012807440219298662,
      'Union Square': 0.02002570499018278,
      'Meatpacking District': 0.015918597702675785,
      'Hudson Square': 0.018204539634059585})




```python
print('before', np.std(np.array(list(fu.get_proportions(y).values()))))
print('after', np.std(np.array(list(fu.get_proportions(y_balanced).values()))))


```

    before 0.01831356441060949
    after 0.008698420094844901



```python
fu.get_my_memory()
workdir = fu.make_work_dir(localdir); print(workdir)
fu.log(workdir, 'new workdir')
```

    /home/ec2-user/SageMaker/learn-citibike/artifacts/2020-07-08T143732Z



```python
# Free up some memory..
print(fu.get_my_memory())
del X
del y
del tripsdf
del stationsdf
print(fu.get_my_memory())
```

    {'pmem': '15.0', 'rss': '0.579 GiB'}
    {'pmem': '7.3', 'rss': '0.282 GiB'}



```python
%%time
X, y = X_balanced, y_balanced # rename for simplicity..

X_train, X_test, y_train, y_test = train_test_split(X, y)
proc_bundle, train_loc = pv2.preprocess(
        X_train, y_train, neighborhoods, workdir=workdir,
        dataset_name='train')
print(train_loc)
bundle_loc = f'{workdir}/proc_bundle.joblib'
joblib.dump({'notebook': '2020-07-03-aws.ipynb',
            'proc_bundle': proc_bundle,
            },
           f'{workdir}/proc_bundle.joblib')
print('Done ', bundle_loc)
test_loc = pv2.preprocess(
        X_test, y_test, neighborhoods, proc_bundle=proc_bundle,
        workdir=workdir,
        dataset_name='test')
print('Done ', test_loc)
```

    100%|██████████| 11/11 [00:10<00:00,  1.07it/s]
      0%|          | 0/11 [00:00<?, ?it/s]

    /home/ec2-user/SageMaker/learn-citibike/artifacts/2020-07-08T143732Z/train.libsvm
    Done  /home/ec2-user/SageMaker/learn-citibike/artifacts/2020-07-08T143732Z/proc_bundle.joblib


    100%|██████████| 11/11 [00:03<00:00,  3.17it/s]

    Done  /home/ec2-user/SageMaker/learn-citibike/artifacts/2020-07-08T143732Z/test.libsvm
    CPU times: user 15.7 s, sys: 629 ms, total: 16.3 s
    Wall time: 14.2 s


    



```python
# ok ... load w/o caching... 
train_loc = f'{workdir}/train.libsvm'
dtrain = xgb.DMatrix(
    f'{train_loc}?format=libsvm')
```

    [14:38:29] 316281x85 matrix with 1431544 entries loaded from /home/ec2-user/SageMaker/learn-citibike/artifacts/2020-07-08T143732Z/train.libsvm?format=libsvm



```python
# more cleanup..
print(fu.get_my_memory())
del X, y, X_train, X_test, y_train, y_test
print(fu.get_my_memory())
```

    {'pmem': '9.8', 'rss': '0.38 GiB'}
    {'pmem': '8.7', 'rss': '0.339 GiB'}


#### train


```python
%%time
# ok try the parameters from "2020-06-28-take2.ipynb"  again...

params = {'max_depth':3, 
          'learning_rate': .1, # 'eta':0.1   # alias
          'objective':'multi:softprob',   # mlogloss? 
          'num_class':  54 ,
          'base_score':0.5, 
          'booster':'gbtree', 
          'colsample_bylevel':1,
          'colsample_bynode':1, 
          'colsample_bytree':1, 
          'gamma':0,
          'max_delta_step':0, 
          'min_child_weight':1, #'missing':nan, 
          'random_state':0,
          'reg_alpha':0, 
          'reg_lambda':1,
          'scale_pos_weight':1, 
          'seed': 42,
          #'silent':None, 
          'subsample':1, 
          'verbosity': 2
          
          # from sklearn...
          # 'n_estimators':100, 'n_jobs':1,
         }

watchlist = [(dtrain, 'train'), 
             #(dtest, 'test')
            ]
num_round = 100
fu.log(workdir, 'Start xgb.train')
xgb_model = xgb.train(params, dtrain, num_round, watchlist)
```

    [14:38:59] INFO: src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3
    ...
    ...
    [14:43:16] INFO: src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3
    [14:43:16] INFO: src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3
    [99]	train-merror:0.875753
    CPU times: user 8min 28s, sys: 1.41 s, total: 8min 29s
    Wall time: 4min 18s


( Full train output log in [log](2020-07-08-aws_files/output.txt) )



```python
test_loc = f'{workdir}/test.libsvm'
dtest = xgb.DMatrix(f'{test_loc}?format=libsvm')
fu.log(workdir, f'Start predict()', f'mem, ({fu.get_my_memory()})')
y_prob_vec = xgb_model.predict(dtest)
predictions = np.argmax(y_prob_vec, axis=1)
fu.log(workdir, f'Done predict()', f'mem, ({fu.get_my_memory()})')
```

    [14:43:32] 105427x85 matrix with 476863 entries loaded from /home/ec2-user/SageMaker/learn-citibike/artifacts/2020-07-08T143732Z/test.libsvm?format=libsvm



```python
actuals = dtest.get_label()
correct = len([i for i, _ in enumerate(actuals)
          if actuals[i] == predictions[i]])
acc = correct/len(actuals)
print('test acc', acc)
print('test acc', accuracy_score(actuals, predictions))
print('test balanced acc', balanced_accuracy_score(actuals, predictions))
logloss = fu.big_logloss(actuals, y_prob=y_prob_vec, 
                         labels= list(range(54)))
fu.log(workdir, f'Done  done fu.big_logloss() logloss={logloss}',
              f'mem, ({fu.get_my_memory()})')
print('logloss', logloss)
```

    test acc 0.12198962315156459
    test acc 0.12198962315156459
    test balanced acc 0.1044572104146026
    logloss 3.4794945441534866

