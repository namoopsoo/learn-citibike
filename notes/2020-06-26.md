
### Notes
- I had tried building a new dataset in "2020-06-24" but kernel kept on exploding. 
- So here, first I tried iterating through chunks of preprocessing at a time. That still exploded the kernel
- But then [midway](#2020-06-27) I tried out a really cool numpy feature where you can save an array to a file in append mode. 
- And the preprocessing step (using encoders to build transformed data and saving that to disk) , on the `843,416` rows here, took about `39` seconds. 


```python
import pandas as pd
import xgboost as xgb
from xgboost import XGBClassifier
import datetime; import pytz
import matplotlib.pyplot as plt
from scipy.special import softmax
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import train_test_split # (*arrays, **options)
import numpy as np
from sklearn.metrics import log_loss
from sklearn.preprocessing import OneHotEncoder, LabelEncoder

from joblib import dump, load
import joblib
import os
from sklearn.metrics import confusion_matrix, mean_squared_error
from sklearn.model_selection import KFold, train_test_split, GridSearchCV
from sklearn.metrics import accuracy_score
import fresh.utils as fu

from importlib import reload
from collections import Counter
from tqdm.notebook import tqdm
import fresh.preproc.v1 as pv1
import fresh.preproc.v2 as pv2
```


```python
datadir = '/opt/data'
localdir = '/opt/program'


tripsdf = pd.read_csv(f'{datadir}/2013-07 - Citi Bike trip data.csv'
                     )#.sample(frac=0.017, random_state=42)
stationsdf = pd.read_csv(f'{localdir}/datas/stations/stations-2018-12-04-c.csv',
                        index_col=0)

```


```python

X, y, neighborhoods = fu.prepare_data(tripsdf, stationsdf)
# 
# future thinking here...
# ..disk approach => return the location of X, y on disk instead 
```


```python
workdir = fu.make_work_dir(); print(workdir)
fu.log(workdir, 'Starting')
```

    /opt/program/artifacts/2020-06-26T142154Z



```python
# place a small section of the pre-processed data into a target file..
x_outfile = f'{workdir}/x_transformed.csv'
y_outfile = f'{workdir}/y_enc.csv'

X_transformed, y_enc, proc_dict = pv2.preprocess(
        X[:1000], y[:1000], neighborhoods, labeled=True)
```

    100%|██████████| 10/10 [00:00<00:00, 359.14it/s]



```python
np.savetxt(x_outfile, X_transformed, delimiter=',')
```


```python
(X_transformed.shape, y_enc.shape, 
 np.hstack((np.resize(y_enc, (1000, 1)), X_transformed)).shape)
```




    ((1000, 85), (1000,), (1000, 86))




```python
both_outfile = f'{workdir}/minidata.csv'
yx_data = np.hstack((np.resize(y_enc, (1000, 1)), X_transformed))
np.savetxt(both_outfile, yx_data, delimiter=',', fmt='%u')
```

### 2020-06-27

#### trying a looped numpy append technique
* Read [here](https://stackoverflow.com/questions/27786868/python3-numpy-appending-to-a-file-using-numpy-savetxt#27980725) that you can pass a file description to `np.savetxt` to accomplish appending. 


```python
# just writing same data a few times first..
both_outfile = f'{workdir}/minidata.csv'
yx_data = np.hstack((np.resize(y_enc, (1000, 1)), X_transformed))
with open(both_outfile, 'ab') as fd:
    np.savetxt(fd, yx_data, delimiter=',', fmt='%u')
    np.savetxt(fd, yx_data, delimiter=',', fmt='%u')
    
```


```python
array = np.loadtxt(both_outfile, delimiter=',')
array.shape
```




    (3000, 86)




```python
# nice!!! that worked .
dataset_name = None#'train'
outfile = f'{workdir}/{dataset_name or "data"}.csv'
outfile
```




    '/opt/program/artifacts/2020-06-26T142154Z/data.csv'




```python
%%time
X_train, X_test, y_train, y_test = train_test_split(X, y)
proc_bundle, train_loc = pv2.preprocess(
        X_train, y_train, neighborhoods, workdir=workdir,
        dataset_name='train')
print(train_loc)
bundle_loc = f'{workdir}/proc_bundle.joblib'
joblib.dump({'notebook': '2020-06-26.ipynb',
            'proc_bundle': proc_bundle,
            },
           f'{workdir}/proc_bundle.joblib')
print('Done ', bundle_loc)
test_loc = pv2.preprocess(
        X_test, y_test, neighborhoods, proc_bundle=proc_bundle,
        workdir=workdir,
        dataset_name='test')
print('Done ', test_loc)
```

    100%|██████████| 11/11 [00:46<00:00,  4.25s/it]
      0%|          | 0/11 [00:00<?, ?it/s]

    /opt/program/artifacts/2020-06-26T142154Z/train.libsvm
    Done  /opt/program/artifacts/2020-06-26T142154Z/proc_bundle.joblib


    100%|██████████| 11/11 [00:15<00:00,  1.45s/it]

    Done  /opt/program/artifacts/2020-06-26T142154Z/test.libsvm
    CPU times: user 29.6 s, sys: 690 ms, total: 30.3 s
    Wall time: 1min 3s


    


Ok cool that appears to have worked 


```python
proc_bundle, outfile
```




    ({'enc': OneHotEncoder(categories=[['Alphabet City', 'Battery Park City',
                                 'Bedford-Stuyvesant', 'Bloomingdale', 'Boerum Hill',
                                 'Bowery', 'Broadway Triangle', 'Brooklyn Heights',
                                 'Brooklyn Navy Yard', 'Carnegie Hill',
                                 'Carroll Gardens', 'Central Park', 'Chelsea',
                                 'Chinatown', 'Civic Center', 'Clinton Hill',
                                 'Cobble Hill', 'Columbia Street Waterfront District',
                                 'Downtown Brooklyn', 'Dumbo', 'East Harlem',
                                 'East Village', 'East Williamsburg',
                                 'Financial District', 'Flatiron District',
                                 'Fort Greene', 'Fulton Ferry District',
                                 'Garment District', 'Governors Island', 'Gowanus', ...],
                                [0, 1, 2], [0, 1, 2, 3, 4]],
                    drop=None, dtype=<class 'numpy.float64'>, handle_unknown='error',
                    sparse=True),
      'usertype_le': LabelEncoder(),
      'le': LabelEncoder()},
     '/opt/program/artifacts/2020-06-26T142154Z/test.libsvm')




```python
!ls -lh '/opt/program/artifacts/2020-06-26T142154Z/train.csv'
```

    -rw-r--r-- 1 root root 139M Jun 27 18:38 /opt/program/artifacts/2020-06-26T142154Z/train.csv

#### looking at target class distribution

```python
# Check if class distribution for split was good...

records = [
    {k:v/x[1] for (k,v) in x[0]} for x in 
[
[[list(a.items()), sum(a.values())] 
                           for a in [dict(Counter(dd))]][0]    

 for dd in [y, y_train, y_test]
]
]

```


```python
# nice. randomness for the win... class distribution looking good here.
proportionsdf = pd.DataFrame.from_records(records).T
proportionsdf
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>0</th>
      <th>1</th>
      <th>2</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Stuyvesant Town</th>
      <td>0.013765</td>
      <td>0.013720</td>
      <td>0.013901</td>
    </tr>
    <tr>
      <th>Gramercy Park</th>
      <td>0.016522</td>
      <td>0.016575</td>
      <td>0.016362</td>
    </tr>
    <tr>
      <th>Theater District</th>
      <td>0.025667</td>
      <td>0.025719</td>
      <td>0.025511</td>
    </tr>
    <tr>
      <th>East Village</th>
      <td>0.016433</td>
      <td>0.016373</td>
      <td>0.016613</td>
    </tr>
    <tr>
      <th>Chelsea</th>
      <td>0.109935</td>
      <td>0.109766</td>
      <td>0.110441</td>
    </tr>
    <tr>
      <th>Union Square</th>
      <td>0.013583</td>
      <td>0.013524</td>
      <td>0.013758</td>
    </tr>
    <tr>
      <th>Rose Hill</th>
      <td>0.007548</td>
      <td>0.007501</td>
      <td>0.007688</td>
    </tr>
    <tr>
      <th>Midtown West</th>
      <td>0.036301</td>
      <td>0.036243</td>
      <td>0.036475</td>
    </tr>
    <tr>
      <th>Midtown East</th>
      <td>0.048963</td>
      <td>0.049088</td>
      <td>0.048588</td>
    </tr>
    <tr>
      <th>Murray Hill</th>
      <td>0.021489</td>
      <td>0.021377</td>
      <td>0.021826</td>
    </tr>
    <tr>
      <th>Midtown</th>
      <td>0.031083</td>
      <td>0.030941</td>
      <td>0.031510</td>
    </tr>
    <tr>
      <th>Ukrainian Village</th>
      <td>0.025094</td>
      <td>0.025041</td>
      <td>0.025254</td>
    </tr>
    <tr>
      <th>Nolita</th>
      <td>0.013509</td>
      <td>0.013528</td>
      <td>0.013455</td>
    </tr>
    <tr>
      <th>Garment District</th>
      <td>0.018445</td>
      <td>0.018613</td>
      <td>0.017941</td>
    </tr>
    <tr>
      <th>Lower East Side</th>
      <td>0.031720</td>
      <td>0.031839</td>
      <td>0.031363</td>
    </tr>
    <tr>
      <th>West Village</th>
      <td>0.042675</td>
      <td>0.042750</td>
      <td>0.042451</td>
    </tr>
    <tr>
      <th>Central Park</th>
      <td>0.006890</td>
      <td>0.006945</td>
      <td>0.006725</td>
    </tr>
    <tr>
      <th>Alphabet City</th>
      <td>0.022391</td>
      <td>0.022444</td>
      <td>0.022233</td>
    </tr>
    <tr>
      <th>Greenwich Village</th>
      <td>0.047612</td>
      <td>0.047666</td>
      <td>0.047450</td>
    </tr>
    <tr>
      <th>Kips Bay</th>
      <td>0.029481</td>
      <td>0.029564</td>
      <td>0.029233</td>
    </tr>
    <tr>
      <th>Hell's Kitchen</th>
      <td>0.044097</td>
      <td>0.043912</td>
      <td>0.044652</td>
    </tr>
    <tr>
      <th>Peter Cooper Village</th>
      <td>0.003429</td>
      <td>0.003489</td>
      <td>0.003249</td>
    </tr>
    <tr>
      <th>Financial District</th>
      <td>0.042757</td>
      <td>0.042914</td>
      <td>0.042285</td>
    </tr>
    <tr>
      <th>NoHo</th>
      <td>0.004204</td>
      <td>0.004224</td>
      <td>0.004145</td>
    </tr>
    <tr>
      <th>NoMad</th>
      <td>0.007185</td>
      <td>0.007191</td>
      <td>0.007166</td>
    </tr>
    <tr>
      <th>Flatiron District</th>
      <td>0.019050</td>
      <td>0.018974</td>
      <td>0.019279</td>
    </tr>
    <tr>
      <th>Lincoln Square</th>
      <td>0.011050</td>
      <td>0.011121</td>
      <td>0.010837</td>
    </tr>
    <tr>
      <th>SoHo</th>
      <td>0.015908</td>
      <td>0.015918</td>
      <td>0.015878</td>
    </tr>
    <tr>
      <th>Fort Greene</th>
      <td>0.019774</td>
      <td>0.019856</td>
      <td>0.019530</td>
    </tr>
    <tr>
      <th>Tribeca</th>
      <td>0.046969</td>
      <td>0.046846</td>
      <td>0.047336</td>
    </tr>
    <tr>
      <th>Bowery</th>
      <td>0.017722</td>
      <td>0.017837</td>
      <td>0.017377</td>
    </tr>
    <tr>
      <th>Brooklyn Heights</th>
      <td>0.010232</td>
      <td>0.010220</td>
      <td>0.010268</td>
    </tr>
    <tr>
      <th>Two Bridges</th>
      <td>0.006071</td>
      <td>0.006018</td>
      <td>0.006227</td>
    </tr>
    <tr>
      <th>Park Slope</th>
      <td>0.002419</td>
      <td>0.002449</td>
      <td>0.002329</td>
    </tr>
    <tr>
      <th>Chinatown</th>
      <td>0.014955</td>
      <td>0.014871</td>
      <td>0.015205</td>
    </tr>
    <tr>
      <th>Sutton Place</th>
      <td>0.001056</td>
      <td>0.001020</td>
      <td>0.001167</td>
    </tr>
    <tr>
      <th>Battery Park City</th>
      <td>0.028728</td>
      <td>0.028906</td>
      <td>0.028195</td>
    </tr>
    <tr>
      <th>Hudson Square</th>
      <td>0.011434</td>
      <td>0.011384</td>
      <td>0.011586</td>
    </tr>
    <tr>
      <th>Tudor City</th>
      <td>0.001449</td>
      <td>0.001459</td>
      <td>0.001418</td>
    </tr>
    <tr>
      <th>Little Italy</th>
      <td>0.003408</td>
      <td>0.003408</td>
      <td>0.003405</td>
    </tr>
    <tr>
      <th>Lower Manhattan</th>
      <td>0.017927</td>
      <td>0.017851</td>
      <td>0.018155</td>
    </tr>
    <tr>
      <th>Korea Town</th>
      <td>0.004240</td>
      <td>0.004249</td>
      <td>0.004211</td>
    </tr>
    <tr>
      <th>Civic Center</th>
      <td>0.013253</td>
      <td>0.013208</td>
      <td>0.013388</td>
    </tr>
    <tr>
      <th>Downtown Brooklyn</th>
      <td>0.016036</td>
      <td>0.016128</td>
      <td>0.015760</td>
    </tr>
    <tr>
      <th>Bedford-Stuyvesant</th>
      <td>0.005347</td>
      <td>0.005373</td>
      <td>0.005269</td>
    </tr>
    <tr>
      <th>Boerum Hill</th>
      <td>0.003998</td>
      <td>0.003979</td>
      <td>0.004055</td>
    </tr>
    <tr>
      <th>Williamsburg</th>
      <td>0.014461</td>
      <td>0.014259</td>
      <td>0.015067</td>
    </tr>
    <tr>
      <th>Clinton Hill</th>
      <td>0.008885</td>
      <td>0.008829</td>
      <td>0.009054</td>
    </tr>
    <tr>
      <th>Meatpacking District</th>
      <td>0.009344</td>
      <td>0.009414</td>
      <td>0.009134</td>
    </tr>
    <tr>
      <th>Dumbo</th>
      <td>0.006647</td>
      <td>0.006551</td>
      <td>0.006934</td>
    </tr>
    <tr>
      <th>Brooklyn Navy Yard</th>
      <td>0.003053</td>
      <td>0.003114</td>
      <td>0.002869</td>
    </tr>
    <tr>
      <th>Fulton Ferry District</th>
      <td>0.002557</td>
      <td>0.002575</td>
      <td>0.002504</td>
    </tr>
    <tr>
      <th>Vinegar Hill</th>
      <td>0.000988</td>
      <td>0.000998</td>
      <td>0.000958</td>
    </tr>
    <tr>
      <th>Columbia Street Waterfront District</th>
      <td>0.002257</td>
      <td>0.002234</td>
      <td>0.002329</td>
    </tr>
  </tbody>
</table>
</div>




```python
# quick test one more time, can I use a DMatrix on xgb.XGBClassifier ? 
# no not really... 
dmatrix = xgb.DMatrix(
    f'{both_outfile}?format=csv&label_column=0&delimiter=,')

```

    [15:28:46] 1000x85 matrix with 85000 entries loaded from /opt/program/artifacts/2020-06-26T142154Z/minidata.csv?format=csv&label_column=0&delimiter=,



```python
xgb_model = xgb.XGBClassifier(objective='multi:softprob')
xgb_model.fit(dmatrix,  verbose=True)
```


    ---------------------------------------------------------------------------

    TypeError                                 Traceback (most recent call last)

    <ipython-input-21-aee50f0fc1ac> in <module>
          1 xgb_model = xgb.XGBClassifier(objective='multi:softprob')
    ----> 2 xgb_model.fit(dmatrix,  verbose=True)
    

    TypeError: fit() missing 1 required positional argument: 'y'


##### thoughts on params to mess with..
num_round , make sure at least 100
gamma, 0
max_delta_step , 1
n_estimators , >100..
min_child_weight, 30
max_depth , 3,4,5,6...
colsample_bytree, 0.4..1.0 
subsample, 0.5..1.0


#### references
- [this](https://github.com/aws/sagemaker-xgboost-container/blob/master/src/sagemaker_xgboost_container/data_utils.py) is a handy reference around xgb utils


```python
os.getpid()
```




    1342


