{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "import datetime; import pytz\n",
    "import matplotlib as plt\n",
    "from scipy.special import softmax\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split # (*arrays, **options)\n",
    "import numpy as np\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "\n",
    "from joblib import dump, load\n",
    "import joblib\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, mean_squared_error\n",
    "from sklearn.model_selection import KFold, train_test_split, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This time, I am going to build the dataset balanced out to start with\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = '/opt/data'\n",
    "localdir = '/opt/program'\n",
    "tripsdf = pd.read_csv(f'{datadir}/2013-07 - Citi Bike trip data.csv')\n",
    "stationsdf = pd.read_csv(f'{localdir}/datas/stations/stations-2018-12-04-c.csv',\n",
    "                        index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(tripsdf, stationsdf):\n",
    "    \n",
    "    # Step 1, merge w/ stationsdf to get neighborhood data\n",
    "    mdf = tripsdf[['start station name', 'end station name', 'gender']\n",
    "            ].merge(stationsdf[['station_name', 'neighborhood']], \n",
    "                    left_on='start station name',\n",
    "                    right_on='station_name'\n",
    "                   ).rename(columns={'neighborhood': 'start_neighborhood'}\n",
    "                           ).merge(stationsdf[['station_name', 'neighborhood']],\n",
    "                                  left_on='end station name',\n",
    "                                   right_on='station_name'\n",
    "                                  ).rename(columns={'neighborhood': 'end_neighborhood'})\n",
    "    \n",
    "    neighborhoods = sorted(stationsdf.neighborhood.unique().tolist())\n",
    "    \n",
    "    X, y = (mdf[['start_neighborhood', 'gender']].values, \n",
    "            np.array(mdf['end_neighborhood'].tolist()))\n",
    "    return X, y\n",
    "    \n",
    "def preprocess(X, y, neighborhoods):\n",
    "    # Initially assuming labeled=True\n",
    "    labeled = True\n",
    "    genders = [0, 1, 2]\n",
    "\n",
    "    enc = OneHotEncoder(handle_unknown='error', \n",
    "                        categories=[neighborhoods, genders])\n",
    "    enc.fit(X)\n",
    "    X_transformed = enc.transform(X)\n",
    "    \n",
    "    le = LabelEncoder()\n",
    "    le.fit(neighborhoods)\n",
    "    \n",
    "    y_enc = le.transform(y)    \n",
    "    \n",
    "    return X_transformed, enc, le, y_enc\n",
    "    \n",
    "class FooFlassifier():\n",
    "    def __init__(self, stationsdf):\n",
    "        self.stationsdf = stationsdf\n",
    "        self.neighborhoods = sorted(stationsdf.neighborhood.unique().tolist())\n",
    "        self.workdir = make_work_dir()\n",
    "    def fit(self, X, y):\n",
    "        # preproc\n",
    "        (X_transformed,\n",
    "             self.one_hot_enc, self.le,\n",
    "             y_enc) = preprocess(X, y, self.neighborhoods)\n",
    "        joblib.dump({'le': self.le,\n",
    "                    'one_hot_enc': self.one_hot_enc},\n",
    "                   f'{self.workdir}/artifacts.joblib')\n",
    "        self.clf = XGBClassifier()\n",
    "        self.clf.fit(X_transformed, y_enc)\n",
    "        \n",
    "        dtrain = xgb.DMatrix(X_transformed, label=y_enc)\n",
    "        params = {'max_depth':2, 'eta':1, 'objective': 'multi:softprob'}\n",
    "      \n",
    "        \n",
    "        self.labels = list(range(len(self.le.classes_)))\n",
    "        \n",
    "#    def score(self, X, y_true):\n",
    "#        X_transformed = self.one_hot_enc.transform(X)\n",
    "#        y_true_enc = self.le.transform(y_true)\n",
    "        \n",
    "#        y_prob = self.clf.predict_proba(X_transformed)\n",
    "#        return log_loss(y_true_enc, y_prob, labels=self.labels)\n",
    "\n",
    "    def get_params(self, deep):\n",
    "        return {}\n",
    "    \n",
    "def make_work_dir():\n",
    "    ts = utc_ts()\n",
    "    workdir = f'/opt/program/artifacts/{ts}' \n",
    "    os.mkdir(workdir)\n",
    "    return workdir\n",
    "\n",
    "#X, y = mdf[['start_neighborhood', 'gender']].values, np.array(mdf['end_neighborhood'].tolist())\n",
    "\n",
    "#clf = FooFlassifier(stationsdf) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0   49   12 ...    0    0  143]\n",
      " [   0 1112   13 ...    0    0   39]\n",
      " [   0    1  283 ...    0    0  305]\n",
      " ...\n",
      " [   0    0    7 ...    0    0   73]\n",
      " [   0  567   27 ...    0    0   57]\n",
      " [   0   21  163 ...    0    0 2064]]\n",
      "[[ 193   64   14 ...    0    0  150]\n",
      " [  27 1167   16 ...    0    0   28]\n",
      " [   4    6  379 ...    0    0  236]\n",
      " ...\n",
      " [   0    0   17 ...    0    0   46]\n",
      " [  67  599   24 ...    0    0   78]\n",
      " [  19    9  196 ...    0    0 2017]]\n",
      "CPU times: user 19min 36s, sys: 2.99 s, total: 19min 39s\n",
      "Wall time: 19min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rng = np.random.RandomState(31337)\n",
    "X, y = prepare_data(tripsdf, stationsdf)\n",
    "neighborhoods = sorted(stationsdf.neighborhood.unique().tolist())\n",
    "\n",
    "\n",
    "kf = KFold(n_splits=2, shuffle=True, random_state=rng)\n",
    "for train_index, test_index in kf.split(X):\n",
    "    \n",
    "    # preproc\n",
    "    (X_transformed,\n",
    "         one_hot_enc, le,\n",
    "         y_enc) = preprocess(X[train_index], y[train_index], \n",
    "                             neighborhoods)\n",
    "    \n",
    "    xgb_model = xgb.XGBClassifier().fit(X_transformed, \n",
    "                                        y_enc)\n",
    "    #\n",
    "    X_test_transformed = one_hot_enc.transform(X[test_index])\n",
    "    y_true_enc = le.transform(y[test_index])\n",
    "    \n",
    "    predictions = xgb_model.predict(X_test_transformed)\n",
    "    actuals = y_true_enc\n",
    "    print(confusion_matrix(actuals, predictions))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/opt/program/artifacts/2020-06-11T041641Z/bundle.joblib']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump({'notebook': '2020-06-10-again',\n",
    "            'model': xgb_model,\n",
    "            'actuals': actuals,\n",
    "            'predictions': predictions,\n",
    "             'confusion_matrix': confusion_matrix(actuals, predictions),\n",
    "             'walltime_train': '19min 45s',\n",
    "             'preproc': {'le': le, 'one_hot_enc': one_hot_enc}\n",
    "            }, f'{workdir}/bundle.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2020-06-11T041623Z'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def utc_ts():\n",
    "    return datetime.datetime.utcnow(\n",
    "        ).replace(tzinfo=pytz.UTC).strftime('%Y-%m-%dT%H%M%SZ')\n",
    "utc_ts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "workdir = make_work_dir()\n",
    "pd.DataFrame.from_records(confusion_matrix(actuals, predictions),\n",
    "                          columns=range(54)).to_csv(f'{workdir}/confusion.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-16-6897dd5d4cdb>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-16-6897dd5d4cdb>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    X_trans <== one hot enc(X)\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def fit(X, y):\n",
    "    # do preproc...\n",
    "    X_trans <== one hot enc(X)\n",
    "    y_enc <== y\n",
    "\n",
    "dtrain = xgb.DMatrix(X_trans[:1000], label=y_enc[:1000])\n",
    "params = {}\n",
    "num_round = 2\n",
    "xgb.cv(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_round,\n",
    "    nfold=5,\n",
    "    metrics={'mlogloss', 'error'},\n",
    "    callbacks=[xgb.callback.print_evaluation(show_stdv=True)]\n",
    "    )\n",
    "model = FooFlassifier(stationsdf)\n",
    "ipdb.runcall(model.fit, X[:100, :], y[:100])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
