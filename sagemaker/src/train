#!/usr/bin/env python

# A sample training component that trains a simple scikit-learn decision tree model.
# This implementation works in File mode and makes no assumptions about the input file names.
# Input is specified as CSV with a data point in each row and the labels in the first column.

from __future__ import print_function

import os
import json
import cPickle
import sys
import traceback
import uuid

import pandas as pd

from sklearn import tree
import xgboost

from bikelearn.models import treefoo as bikemodel
from bikelearn import pipeline_data as pl
import utils as ut

# These are the paths to where SageMaker mounts interesting things in your container.





def train():
    train_fn = what_are_train_files()[-1]
    test_fn = what_are_test_files()[-1]
    print('DEBUG, train_fn, ' + train_fn)
    print('DEBUG, test_fn, ' + test_fn)

    stations_id, stations_df = ut.get_stations()

    hyperparameters = read_hyperparams()
    print('DEBUG, hyperparameters, {}'.format(hyperparameters))

    try:
        bundle = bikemodel.make_tree_foo({
                    'train_fn': train_fn,
                    'trainset': pd.read_csv(train_fn),
                    'testset': pd.read_csv(test_fn),
                    'test_fn': test_fn},
                {'stations_df': stations_df, 'fn': stations_id},
                hyperparameters)

        # TODO... do the test set too..
        print ('DEBUG, done baking bundle.')
    except Exception as e:
        print('DEBUG, oh crap exception, ' + str({'e': e.__class__.__name__, 'str': str(e)}))
        # Write out an error file. This will be returned as the failureReason in the
        # DescribeTrainingJob result.
        trc = traceback.format_exc()
        fn = 'failure.{}.log'.format(pl.make_timestamp())
        with open(os.path.join(ut.output_path, fn), 'w') as s:
            s.write('Exception during training: ' + str(e) + '\n' + trc)
        # Printing this causes the exception to be in the training job logs, as well.
        print('Exception during training: ' + str(e) + '\n' + trc, file=sys.stderr)
        # A non-zero exit code causes the training job to be marked as Failed.
        sys.exit(255)

    # save bundle ...
    save_model(bundle)


def what_are_train_files():
    return what_are_channel_files(ut.training_path)


def what_are_test_files():
    return what_are_channel_files(ut.testing_path)


def what_are_channel_files(channel_path):
    # Take the set of files and read them all into a single pandas dataframe
    print('DEBUG, channel_path, ' + channel_path)

    print('DEBUG, os.listdir(channel_path), ' + str(
        os.listdir(channel_path)))
    input_files = [
            os.path.join(channel_path, file)
            for file in
            filter(lambda x: x != 'support' and x.endswith('.csv'),
                os.listdir(channel_path))]

    print('DEBUG, input_files , ')
    print(str(input_files))

    if len(input_files) == 0:
        raise ValueError(('There are no files in {}.\n'
                    + 'This usually indicates that '
                    + 'the channel was incorrectly'
                    + ' specified,\n'
                    + 'the data specification in S3 '
                    + ' was incorrectly specified or '
                    + ' the role specified\n'
                    + 'does not have permission to '
                    + ' access the data.').format(
                            channel_path))

    return input_files

def read_hyperparams():
    with open(ut.param_path, 'r') as tc:
        hyperparameters = json.load(tc)
    return hyperparameters


def save_model(bundle):
    output_name = '{}.{}.pkl'.format(bundle['bundle_name'],
            bundle['timestamp'])
    print('DEBUG, save_model, ' + output_name)
    with open(
            os.path.join(ut.model_path, output_name), 'w') as out:
        cPickle.dump(bundle, out)

    with open(
            os.path.join(ut.model_path, 'bundle_meta.json'), 'w') as out:
        json.dump({'bundle_filename': output_name}, out)


if __name__ == '__main__':
    train()

    # A zero exit code causes the job to be marked a Succeeded.
    sys.exit(0)


