{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### redo w/ batch\n",
    "- would like to re-do the \"2020-06-20\" notebook but w/ the batching approach, to see if any deterioration!!?? \n",
    "- That is, the batching approach I had used [here](https://github.com/namoopsoo/learn-citibike/blob/2020-revisit/notes/2020-06-14.md#trying-out-that-model-save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "import datetime; import pytz\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.special import softmax\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split # (*arrays, **options)\n",
    "import numpy as np\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "\n",
    "from joblib import dump, load\n",
    "import joblib\n",
    "import os\n",
    "from sklearn.metrics import confusion_matrix, mean_squared_error\n",
    "from sklearn.model_selection import KFold, train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "import fresh.utils as fu\n",
    "\n",
    "from importlib import reload\n",
    "from collections import Counter\n",
    "from tqdm.notebook import tqdm\n",
    "import fresh.preproc.v1 as pv1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = '/opt/data'\n",
    "localdir = '/opt/program'\n",
    "\n",
    "\n",
    "tripsdf = pd.read_csv(f'{datadir}/2013-07 - Citi Bike trip data.csv'\n",
    "                     )#.sample(frac=0.017, random_state=42)\n",
    "stationsdf = pd.read_csv(f'{localdir}/datas/stations/stations-2018-12-04-c.csv',\n",
    "                        index_col=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, neighborhoods = fu.prepare_data(tripsdf, stationsdf)\n",
    "\n",
    "# ... actually doing this part jsut to get those labels... \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "# preproc\n",
    "(X_transformed,\n",
    "     one_hot_enc, le,\n",
    "     y_enc) = pv1.preprocess(X_train, y_train, # X[train_index]\n",
    "                         neighborhoods)\n",
    "labels = le.classes_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_train(model, X, y, workdir):\n",
    "\n",
    "    size = X.shape[0]\n",
    "\n",
    "    indices = np.random.choice(range(size), size=size, replace=False)\n",
    "    parts = fu.get_partitions(indices, slice_size=1000)\n",
    "\n",
    "    prev_model_loc = None\n",
    "    for i, part in enumerate(parts):\n",
    "        model.fit(X[part], y[part], xgb_model=prev_model_loc)\n",
    "        fu.log(workdir, f'[{i}] Done fit')\n",
    "\n",
    "        prev_model_loc = f'{workdir}/model.xg'\n",
    "        model.save_model(prev_model_loc)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "workdir = fu.make_work_dir(); print(workdir)\n",
    "fu.log(workdir, 'Starting')\n",
    "\n",
    "rng = np.random.RandomState(31337)\n",
    "\n",
    "kf = KFold(n_splits=2, shuffle=True, random_state=rng)\n",
    "for (i, (train_index, test_index)) in enumerate(kf.split(X)):    \n",
    "    # preproc\n",
    "    (X_transformed,\n",
    "         one_hot_enc, le,\n",
    "         y_enc) = pv1.preprocess(X[train_index], y[train_index], \n",
    "                             neighborhoods)\n",
    "    \n",
    "    xgb_model = xgb.XGBClassifier(objective='multi:softprob'\n",
    "                                 )# .fit(X_transformed, y_enc, verbose=True)\n",
    "    xgb_model = do_train(model, X_transformed, y_enc, workdir=workdir)\n",
    "    fu.log(workdir, f'[{i}] Done fit.')\n",
    "    \n",
    "    bundle_loc = f'{workdir}/bundle_{i}.joblib'\n",
    "    joblib.dump({'model': xgb_model}, bundle_loc)\n",
    "    #\n",
    "    X_test_transformed = one_hot_enc.transform(X[test_index])\n",
    "    actuals = le.transform(y[test_index]); len(actuals)\n",
    "    \n",
    "    predictions = xgb_model.predict(X_test_transformed)\n",
    "    confusion = confusion_matrix(actuals, predictions)\n",
    "    acc = accuracy_score(actuals, predictions)\n",
    "    \n",
    "    y_prob_vec = fu.predict_proba(X_test_transformed, bundle_loc=bundle_loc)\n",
    "    # xgb_model.predict_proba(X_test_transformed)\n",
    "    fu.log(workdir, f'[{i}] Done fu.predict_proba')\n",
    "    \n",
    "    \n",
    "    logloss = fu.big_logloss(actuals, y_prob_vec, list(range(len(labels))))\n",
    "    fu.log(workdir, f'[{i}] Done big_logloss, loss={logloss}.')\n",
    "                          \n",
    "    # save full now though\n",
    "    joblib.dump({'model': xgb_model,\n",
    "                'metrics': {'confusion': confusion,\n",
    "                           'validation_logloss': logloss,\n",
    "                           'validation_acc': acc}}, bundle_loc)\n",
    "    fu.log(workdir, f'[{i}] dumped bundle to {bundle_loc}')\n",
    "                             "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
