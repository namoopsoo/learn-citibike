{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### redo w/ batch\n",
    "- would like to re-do the \"2020-06-20\" notebook but w/ the batching approach, to see if any deterioration!!?? \n",
    "- That is, the batching approach I had used [here](https://github.com/namoopsoo/learn-citibike/blob/2020-revisit/notes/2020-06-14.md#trying-out-that-model-save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "import datetime; import pytz\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.special import softmax\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split # (*arrays, **options)\n",
    "import numpy as np\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "\n",
    "from joblib import dump, load\n",
    "import joblib\n",
    "import os\n",
    "from sklearn.metrics import confusion_matrix, mean_squared_error\n",
    "from sklearn.model_selection import KFold, train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "import fresh.utils as fu\n",
    "\n",
    "from importlib import reload\n",
    "from collections import Counter\n",
    "from tqdm.notebook import tqdm\n",
    "import fresh.preproc.v1 as pv1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = '/opt/data'\n",
    "localdir = '/opt/program'\n",
    "\n",
    "\n",
    "tripsdf = pd.read_csv(f'{datadir}/2013-07 - Citi Bike trip data.csv'\n",
    "                     )#.sample(frac=0.017, random_state=42)\n",
    "stationsdf = pd.read_csv(f'{localdir}/datas/stations/stations-2018-12-04-c.csv',\n",
    "                        index_col=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, neighborhoods = fu.prepare_data(tripsdf, stationsdf)\n",
    "\n",
    "# ... actually doing this part jsut to get those labels... \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "# preproc\n",
    "(X_transformed,\n",
    "     one_hot_enc, le,\n",
    "     y_enc) = pv1.preprocess(X_train, y_train, # X[train_index]\n",
    "                         neighborhoods)\n",
    "labels = le.classes_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_train(model, X, y, workdir):\n",
    "\n",
    "    size = X.shape[0]\n",
    "    while True:\n",
    "        indices = np.random.choice(range(size), size=size, replace=False)\n",
    "        parts = fu.get_partitions(indices, slice_size=10000)\n",
    "\n",
    "        if len(Counter(y_enc[parts[0]])) == 54:\n",
    "            break\n",
    "        print('..shuffling..')\n",
    "        \n",
    "    prev_model_loc = None\n",
    "    for i, part in enumerate(parts):\n",
    "        model.fit(X[part], y[part], xgb_model=prev_model_loc)\n",
    "        fu.log(workdir, f'({i}/{len(parts)}) Done fit', f'mem, ({fu.get_my_memory()})')\n",
    "\n",
    "        prev_model_loc = f'{workdir}/model.xg'\n",
    "        model.save_model(prev_model_loc)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mem, ({'pmem': '34.7', 'rss': '0.678 GiB'})\n"
     ]
    }
   ],
   "source": [
    "reload(fu);print(f'mem, ({fu.get_my_memory()})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/program/artifacts/2020-06-21T051742Z\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "workdir = fu.make_work_dir(); print(workdir)\n",
    "fu.log(workdir, 'Starting, ', f'mem, ({fu.get_my_memory()})')\n",
    "\n",
    "rng = np.random.RandomState(31337)\n",
    "\n",
    "kf = KFold(n_splits=2, shuffle=True, random_state=rng)\n",
    "for (i, (train_index, test_index)) in enumerate(kf.split(X)):    \n",
    "    # preproc\n",
    "    (X_transformed,\n",
    "         one_hot_enc, le,\n",
    "         y_enc) = pv1.preprocess(X[train_index], y[train_index], \n",
    "                             neighborhoods)\n",
    "    \n",
    "    xgb_model = xgb.XGBClassifier(objective='multi:softprob'\n",
    "                                 )# .fit(X_transformed, y_enc, verbose=True)\n",
    "    \n",
    "    xgb_model = do_train(xgb_model, X_transformed, y_enc, workdir=workdir)\n",
    "    fu.log(workdir, f'[{i}] Done fit.', f'mem, ({fu.get_my_memory()})')\n",
    "    \n",
    "    bundle_loc = f'{workdir}/bundle_{i}.joblib'\n",
    "    joblib.dump({'model': xgb_model}, bundle_loc)\n",
    "    #\n",
    "    X_test_transformed = one_hot_enc.transform(X[test_index])\n",
    "    actuals = le.transform(y[test_index]); len(actuals)\n",
    "    \n",
    "    predictions = xgb_model.predict(X_test_transformed)\n",
    "    confusion = confusion_matrix(actuals, predictions)\n",
    "    acc = accuracy_score(actuals, predictions)\n",
    "    fu.log(workdir, f'[{i}] Done predict, acc={acc}', \n",
    "                   f'mem, ({fu.get_my_memory()})')\n",
    "    \n",
    "    y_prob_vec = fu.predict_proba(X_test_transformed, bundle_loc=bundle_loc)\n",
    "    # xgb_model.predict_proba(X_test_transformed)\n",
    "    fu.log(workdir, f'[{i}] Done fu.predict_proba', f'mem, ({fu.get_my_memory()})')\n",
    "    \n",
    "    \n",
    "    logloss = fu.big_logloss(actuals, y_prob_vec, list(range(len(labels))))\n",
    "    fu.log(workdir, f'[{i}] Done big_logloss, loss={logloss}.', \n",
    "                   f'mem, ({fu.get_my_memory()})')\n",
    "                          \n",
    "    # save full now though\n",
    "    joblib.dump({'model': xgb_model,\n",
    "                 'notebook': '2020-06-20-batch-batch.ipynb',\n",
    "                'metrics': {'confusion': confusion,\n",
    "                           'validation_logloss': logloss,\n",
    "                           'validation_acc': acc},\n",
    "                'dataset': {'v': 'v1', 'desc': 'neighborhood+gender'},\n",
    "                'model': {'v': 'v1', 'desc': 'xgboost+defaults+onehot'}\n",
    "                }, bundle_loc)\n",
    "    fu.log(workdir, f'[{i}] dumped bundle to {bundle_loc}')\n",
    "                             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### truncated log\n",
    "\n",
    "```\n",
    "(pandars3) $ tail -f artifacts/2020-06-21T051742Z/work.log \n",
    "2020-06-21 05:17:42Z, Starting, , mem, ({'pmem': '34.7', 'rss': '0.678 GiB'})\n",
    "2020-06-21 05:17:53Z, (0/43) Done fit, mem, ({'pmem': '36.0', 'rss': '0.704 GiB'})\n",
    "2020-06-21 05:18:12Z, (1/43) Done fit, mem, ({'pmem': '36.0', 'rss': '0.704 GiB'})\n",
    "2020-06-21 05:18:45Z, (2/43) Done fit, mem, ({'pmem': '36.3', 'rss': '0.709 GiB'})\n",
    "2020-06-21 05:19:39Z, (3/43) Done fit, mem, ({'pmem': '36.7', 'rss': '0.717 GiB'})\n",
    "2020-06-21 05:21:04Z, (4/43) Done fit, mem, ({'pmem': '37.1', 'rss': '0.725 GiB'})\n",
    "2020-06-21 05:23:02Z, (5/43) Done fit, mem, ({'pmem': '37.5', 'rss': '0.733 GiB'})\n",
    "2020-06-21 05:25:38Z, (6/43) Done fit, mem, ({'pmem': '37.9', 'rss': '0.741 GiB'})\n",
    "2020-06-21 05:28:45Z, (7/43) Done fit, mem, ({'pmem': '38.3', 'rss': '0.749 GiB'})\n",
    "2020-06-21 05:32:24Z, (8/43) Done fit, mem, ({'pmem': '38.8', 'rss': '0.758 GiB'})\n",
    "2020-06-21 05:36:41Z, (9/43) Done fit, mem, ({'pmem': '39.3', 'rss': '0.768 GiB'})\n",
    "2020-06-21 05:41:28Z, (10/43) Done fit, mem, ({'pmem': '39.8', 'rss': '0.777 GiB'})\n",
    "2020-06-21 05:46:47Z, (11/43) Done fit, mem, ({'pmem': '40.2', 'rss': '0.787 GiB'})\n",
    "2020-06-21 05:52:35Z, (12/43) Done fit, mem, ({'pmem': '40.7', 'rss': '0.796 GiB'})\n",
    "2020-06-21 05:59:02Z, (13/43) Done fit, mem, ({'pmem': '41.3', 'rss': '0.807 GiB'})\n",
    "...\n",
    "...\n",
    "2020-06-21 15:24:59Z, (41/43) Done fit, mem, ({'pmem': '55.5', 'rss': '1.085 GiB'})\n",
    "2020-06-21 15:29:14Z, (42/43) Done fit, mem, ({'pmem': '56.0', 'rss': '1.094 GiB'})\n",
    "2020-06-21 15:29:23Z, [0] Done fit., mem, ({'pmem': '56.0', 'rss': '1.094 GiB'})\n",
    "```\n",
    "\n",
    "#### Trying to understand what happened here..\n",
    "- This notebook was meant to be a simple re-do of the [2020-06-20](https://github.com/namoopsoo/learn-citibike/blob/2020-revisit/notes/2020-06-20.md) notebook, except instead of running a `fit()` on all of the training data, `430k` rows, at once, to use the batching technique, `10k` at a time, \n",
    "- But this batching technique in the `do_train` func is not at all what happened. The first \"2020-06-20\" model fit took about `7 min` , but this fit here with `43` batches took from `05:17` to `11:23` , then `14:01` to `15:29` , maybe about `8 hours` . \n",
    "- The first \"2020-06-20\" model  per [here](https://github.com/namoopsoo/learn-citibike/blob/2020-revisit/notes/2020-06-20.md#log-dump) was about `2.9M` but this one, `105M` \n",
    "- This `43*2.9 = 124.7` so perhaps these `43` iterations are scaling the size roughly linearly.\n",
    "- But this time around I was tracking the memory of my notebook and I made a habit of killing any previous notebooks. So I feel confident the slowness is related to whatever is happening in this step..\n",
    "\n",
    "```\n",
    "model.fit(X[part], y[part], xgb_model=prev_model_loc)\n",
    "```\n",
    "\n",
    "- If the predict parts took `5min` in \"2020-06-20\" then here (I'm still waiting for it as I write this `55minutes` in ) I may need to wait several hours .\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial false start log..\n",
    "\n",
    "```\n",
    "model.xg  work.log  \n",
    "(pandars3) $ tail -f artifacts/2020-06-21T051408Z/work.log \n",
    "2020-06-21 05:14:08Z, Starting, , mem, ({'pmem': '30.9', 'rss': '0.603 GiB'})\n",
    "2020-06-21 05:14:12Z, (0/422) Done fit, mem, ({'pmem': '32.7', 'rss': '0.639 GiB'})\n",
    "2020-06-21 05:14:15Z, (1/422) Done fit, mem, ({'pmem': '32.7', 'rss': '0.64 GiB'})\n",
    "2020-06-21 05:14:19Z, (2/422) Done fit, mem, ({'pmem': '32.7', 'rss': '0.64 GiB'})\n",
    "2020-06-21 05:14:27Z, (3/422) Done fit, mem, ({'pmem': '32.7', 'rss': '0.64 GiB'})\n",
    "2020-06-21 05:14:38Z, (4/422) Done fit, mem, ({'pmem': '32.7', 'rss': '0.64 GiB'})\n",
    "2020-06-21 05:14:52Z, (5/422) Done fit, mem, ({'pmem': '32.7', 'rss': '0.64 GiB'})\n",
    "2020-06-21 05:15:09Z, (6/422) Done fit, mem, ({'pmem': '32.7', 'rss': '0.64 GiB'})\n",
    "2020-06-21 05:15:29Z, (7/422) Done fit, mem, ({'pmem': '33.1', 'rss': '0.646 GiB'})\n",
    "2020-06-21 05:15:52Z, (8/422) Done fit, mem, ({'pmem': '33.5', 'rss': '0.654 GiB'})\n",
    "2020-06-21 05:16:18Z, (9/422) Done fit, mem, ({'pmem': '33.9', 'rss': '0.662 GiB'})\n",
    "2020-06-21 05:16:47Z, (10/422) Done fit, mem, ({'pmem': '34.3', 'rss': '0.67 GiB'})\n",
    "```\n",
    "\n",
    "#### fuller log...\n",
    "\n",
    "```\n",
    "(pandars3) $ tail -f artifacts/2020-06-21T051742Z/work.log \n",
    "2020-06-21 05:17:42Z, Starting, , mem, ({'pmem': '34.7', 'rss': '0.678 GiB'})\n",
    "2020-06-21 05:17:53Z, (0/43) Done fit, mem, ({'pmem': '36.0', 'rss': '0.704 GiB'})\n",
    "2020-06-21 05:18:12Z, (1/43) Done fit, mem, ({'pmem': '36.0', 'rss': '0.704 GiB'})\n",
    "2020-06-21 05:18:45Z, (2/43) Done fit, mem, ({'pmem': '36.3', 'rss': '0.709 GiB'})\n",
    "2020-06-21 05:19:39Z, (3/43) Done fit, mem, ({'pmem': '36.7', 'rss': '0.717 GiB'})\n",
    "2020-06-21 05:21:04Z, (4/43) Done fit, mem, ({'pmem': '37.1', 'rss': '0.725 GiB'})\n",
    "2020-06-21 05:23:02Z, (5/43) Done fit, mem, ({'pmem': '37.5', 'rss': '0.733 GiB'})\n",
    "2020-06-21 05:25:38Z, (6/43) Done fit, mem, ({'pmem': '37.9', 'rss': '0.741 GiB'})\n",
    "2020-06-21 05:28:45Z, (7/43) Done fit, mem, ({'pmem': '38.3', 'rss': '0.749 GiB'})\n",
    "2020-06-21 05:32:24Z, (8/43) Done fit, mem, ({'pmem': '38.8', 'rss': '0.758 GiB'})\n",
    "2020-06-21 05:36:41Z, (9/43) Done fit, mem, ({'pmem': '39.3', 'rss': '0.768 GiB'})\n",
    "2020-06-21 05:41:28Z, (10/43) Done fit, mem, ({'pmem': '39.8', 'rss': '0.777 GiB'})\n",
    "2020-06-21 05:46:47Z, (11/43) Done fit, mem, ({'pmem': '40.2', 'rss': '0.787 GiB'})\n",
    "2020-06-21 05:52:35Z, (12/43) Done fit, mem, ({'pmem': '40.7', 'rss': '0.796 GiB'})\n",
    "2020-06-21 05:59:02Z, (13/43) Done fit, mem, ({'pmem': '41.3', 'rss': '0.807 GiB'})\n",
    "2020-06-21 06:05:56Z, (14/43) Done fit, mem, ({'pmem': '41.8', 'rss': '0.817 GiB'})\n",
    "2020-06-21 06:13:32Z, (15/43) Done fit, mem, ({'pmem': '42.3', 'rss': '0.826 GiB'})\n",
    "2020-06-21 06:21:35Z, (16/43) Done fit, mem, ({'pmem': '42.8', 'rss': '0.836 GiB'})\n",
    "2020-06-21 06:30:25Z, (17/43) Done fit, mem, ({'pmem': '43.3', 'rss': '0.846 GiB'})\n",
    "2020-06-21 06:39:32Z, (18/43) Done fit, mem, ({'pmem': '43.8', 'rss': '0.856 GiB'})\n",
    "2020-06-21 06:49:29Z, (19/43) Done fit, mem, ({'pmem': '44.3', 'rss': '0.866 GiB'})\n",
    "2020-06-21 06:59:44Z, (20/43) Done fit, mem, ({'pmem': '44.8', 'rss': '0.876 GiB'})\n",
    "2020-06-21 07:10:44Z, (21/43) Done fit, mem, ({'pmem': '45.4', 'rss': '0.887 GiB'})\n",
    "2020-06-21 07:22:05Z, (22/43) Done fit, mem, ({'pmem': '45.8', 'rss': '0.896 GiB'})\n",
    "2020-06-21 07:34:11Z, (23/43) Done fit, mem, ({'pmem': '46.3', 'rss': '0.905 GiB'})\n",
    "2020-06-21 07:46:42Z, (24/43) Done fit, mem, ({'pmem': '46.8', 'rss': '0.915 GiB'})\n",
    "2020-06-21 07:59:52Z, (25/43) Done fit, mem, ({'pmem': '47.5', 'rss': '0.929 GiB'})\n",
    "2020-06-21 08:13:32Z, (26/43) Done fit, mem, ({'pmem': '48.0', 'rss': '0.937 GiB'})\n",
    "2020-06-21 08:27:49Z, (27/43) Done fit, mem, ({'pmem': '48.4', 'rss': '0.946 GiB'})\n",
    "2020-06-21 08:42:41Z, (28/43) Done fit, mem, ({'pmem': '48.9', 'rss': '0.955 GiB'})\n",
    "2020-06-21 08:58:04Z, (29/43) Done fit, mem, ({'pmem': '49.4', 'rss': '0.965 GiB'})\n",
    "2020-06-21 09:14:08Z, (30/43) Done fit, mem, ({'pmem': '49.9', 'rss': '0.975 GiB'})\n",
    "2020-06-21 09:30:35Z, (31/43) Done fit, mem, ({'pmem': '50.4', 'rss': '0.985 GiB'})\n",
    "2020-06-21 09:47:50Z, (32/43) Done fit, mem, ({'pmem': '50.9', 'rss': '0.994 GiB'})\n",
    "2020-06-21 10:05:25Z, (33/43) Done fit, mem, ({'pmem': '51.5', 'rss': '1.006 GiB'})\n",
    "2020-06-21 10:24:07Z, (34/43) Done fit, mem, ({'pmem': '52.2', 'rss': '1.02 GiB'})\n",
    "2020-06-21 10:43:11Z, (35/43) Done fit, mem, ({'pmem': '52.7', 'rss': '1.029 GiB'})\n",
    "2020-06-21 11:03:10Z, (36/43) Done fit, mem, ({'pmem': '53.1', 'rss': '1.038 GiB'})\n",
    "2020-06-21 11:23:00Z, (37/43) Done fit, mem, ({'pmem': '53.6', 'rss': '1.048 GiB'})\n",
    "2020-06-21 14:19:14Z, (38/43) Done fit, mem, ({'pmem': '54.1', 'rss': '1.057 GiB'})\n",
    "2020-06-21 14:40:22Z, (39/43) Done fit, mem, ({'pmem': '54.6', 'rss': '1.066 GiB'})\n",
    "2020-06-21 15:02:32Z, (40/43) Done fit, mem, ({'pmem': '55.1', 'rss': '1.076 GiB'})\n",
    "2020-06-21 15:24:59Z, (41/43) Done fit, mem, ({'pmem': '55.5', 'rss': '1.085 GiB'})\n",
    "2020-06-21 15:29:14Z, (42/43) Done fit, mem, ({'pmem': '56.0', 'rss': '1.094 GiB'})\n",
    "2020-06-21 15:29:23Z, [0] Done fit., mem, ({'pmem': '56.0', 'rss': '1.094 GiB'})\n",
    "\n",
    "```\n",
    "\n",
    "#### size of first bundle on disk\n",
    "```\n",
    "(pandars3) $ ls -alrth artifacts/2020-06-21T051742Z\n",
    "total 459144\n",
    "drwxr-xr-x@ 41 michal  staff   1.3K Jun 21 01:17 ..\n",
    "-rw-r--r--@  1 michal  staff   105M Jun 21 11:29 model.xg\n",
    "-rw-r--r--@  1 michal  staff   3.7K Jun 21 11:29 work.log\n",
    "drwxr-xr-x@  5 michal  staff   160B Jun 21 11:29 .\n",
    "-rw-r--r--@  1 michal  staff   105M Jun 21 11:29 bundle_0.joblib\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
