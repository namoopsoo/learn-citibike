{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### this\n",
    "Try cache train data one more time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "import datetime; import pytz\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.special import softmax\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split # (*arrays, **options)\n",
    "import numpy as np\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "\n",
    "from joblib import dump, load\n",
    "import joblib\n",
    "import os\n",
    "from sklearn.metrics import confusion_matrix, mean_squared_error\n",
    "from sklearn.model_selection import KFold, train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "import fresh.utils as fu\n",
    "\n",
    "from importlib import reload\n",
    "from collections import Counter\n",
    "from tqdm.notebook import tqdm\n",
    "import fresh.preproc.v1 as pv1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = '/opt/data'\n",
    "localdir = '/opt/program'\n",
    "\n",
    "\n",
    "tripsdf = pd.read_csv(f'{datadir}/2013-07 - Citi Bike trip data.csv'\n",
    "                     )#.sample(frac=0.017, random_state=42)\n",
    "stationsdf = pd.read_csv(f'{localdir}/datas/stations/stations-2018-12-04-c.csv',\n",
    "                        index_col=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, neighborhoods = fu.prepare_data(tripsdf, stationsdf)\n",
    "\n",
    "# ... actually doing this part jsut to get those labels... \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "# preproc\n",
    "(X_transformed,\n",
    "     one_hot_enc, le,\n",
    "     y_enc) = pv1.preprocess(X_train, y_train, # X[train_index]\n",
    "                         neighborhoods)\n",
    "labels = le.classes_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mem, ({'pmem': '32.7', 'rss': '0.64 GiB'})\n"
     ]
    }
   ],
   "source": [
    "print(f'mem, ({fu.get_my_memory()})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dtrain(X, y, workdir, i):\n",
    "    \n",
    "    outpath = f'{workdir}/dtrain.txt'\n",
    "    fu.save_libsvm(X.toarray(), y, outpath)\n",
    "    fu.log(workdir, f'[{i}] Saved train data: {outpath}')\n",
    "    dtrain = xgb.DMatrix(f'{outpath}#dtrain.cache')\n",
    "    return dtrain\n",
    "\n",
    "def prepare_dtest(X, workdir, i):\n",
    "    outpath = f'{workdir}/dtest.txt'    \n",
    "    fu.save_libsvm(X, outpath=outpath)\n",
    "    fu.log(workdir, f'[{i}] Done saving to {outpath}')\n",
    "    dtest = xgb.DMatrix(f'{outpath}') # #dtest.cache\n",
    "    return dtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "workdir:  /opt/program/artifacts/2020-06-21T213257Z\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "workdir = fu.make_work_dir(); print('workdir: ', workdir)\n",
    "fu.log(workdir, 'Starting', f'mem, ({fu.get_my_memory()})')\n",
    "\n",
    "params = {'max_depth':3, \n",
    "          'learning_rate': .1, # 'eta':0.1   # alias\n",
    "          'objective':'multi:softprob',   # mlogloss? \n",
    "          'num_class': len(labels), # 54 \n",
    "          'base_score':0.5, \n",
    "          'booster':'gbtree', \n",
    "          'colsample_bylevel':1,\n",
    "          'colsample_bynode':1, \n",
    "          'colsample_bytree':1, \n",
    "          'gamma':0,\n",
    "          'max_delta_step':0, \n",
    "          'min_child_weight':1, #'missing':nan, \n",
    "          'random_state':0,\n",
    "          'reg_alpha':0, \n",
    "          'reg_lambda':1,\n",
    "          'scale_pos_weight':1, \n",
    "          'seed': 42,\n",
    "          #'silent':None, \n",
    "          'subsample':1, \n",
    "          'verbosity': 2\n",
    "          \n",
    "          # from sklearn...\n",
    "          # 'n_estimators':100, 'n_jobs':1,\n",
    "         }\n",
    "rng = np.random.RandomState(31337)\n",
    "\n",
    "kf = KFold(n_splits=2, shuffle=True, random_state=rng)\n",
    "for (i, (train_index, test_index)) in enumerate(kf.split(X)):    \n",
    "\n",
    "\n",
    "    # preprocess\n",
    "    (X_transformed, one_hot_enc, le,\n",
    "         y_enc) = pv1.preprocess(X[train_index], y[train_index], \n",
    "                             neighborhoods)\n",
    "    fu.log(workdir, f'[{i}] Done preprocessing', \n",
    "                   f'mem, ({fu.get_my_memory()})')\n",
    "    labels = le.classes_\n",
    "\n",
    "    dtrain = prepare_dtrain(X_transformed, y_enc, workdir, i)\n",
    "\n",
    "    watchlist = [(dtrain, 'train')]\n",
    "    num_round = 100\n",
    "\n",
    "    xgb_model = xgb.train(params, dtrain, num_round, watchlist)\n",
    "    fu.log(workdir, f'[{i}] Done xgb.train', \n",
    "                   f'mem, ({fu.get_my_memory()})')\n",
    "\n",
    "    # test..\n",
    "    X_test_transformed = one_hot_enc.transform(\n",
    "        X[test_index]).toarray()\n",
    "    actuals = le.transform(y[test_index])\n",
    "    fu.log(workdir, f'[{i}] Done transforming test data')\n",
    "    \n",
    "    dtest = prepare_dtest(X_test_transformed, workdir, i)\n",
    "    y_prob_vec = xgb_model.predict(dtest)\n",
    "    predictions = np.argmax(y_prob_vec, axis=1)\n",
    "\n",
    "    fu.log(workdir, f'[{i}] Done predict()',\n",
    "                   f'mem, ({fu.get_my_memory()})')\n",
    "    correct = len([i for i, _ in enumerate(actuals)\n",
    "              if actuals[i] == predictions[i]])\n",
    "    acc = correct/len(actuals)\n",
    "    fu.log(workdir, f'[{i}], acc={acc}')\n",
    "\n",
    "    bundle_loc = f'{workdir}/bundle_{i}.joblib'\n",
    "    logloss = fu.big_logloss(actuals, y_prob=y_prob_vec, \n",
    "                             labels= list(range(len(labels))))\n",
    "    fu.log(workdir, f'[{i}] Done  done fu.big_logloss() logloss={logloss}',\n",
    "                  f'mem, ({fu.get_my_memory()})')\n",
    "\n",
    "    joblib.dump({\n",
    "     'model': xgb_model,\n",
    "     'notebook': '2020-06-21.ipynb',\n",
    "     'num_round': num_round,\n",
    "     'metrics': {\n",
    "                 'accuracy': acc,   \n",
    "                 'validation_logloss': logloss,\n",
    "                 'confusion_matrix': confusion_matrix(\n",
    "                     actuals, predictions)\n",
    "                 },\n",
    "     'timestamp': fu.utc_ts(),\n",
    "     'input_params': params,\n",
    "    }, bundle_loc)\n",
    "    fu.log(workdir, f'[{i}] wrote bundle {bundle_loc}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### log dump of num_round=2 attempt\n",
    "* `Wall time: 2min 37s` ..\n",
    "```\n",
    "(pandars3) $ tail -f artifacts/2020-06-21T212459Z/work.log \n",
    "2020-06-21 21:24:59Z, Starting, mem, ({'pmem': '36.4', 'rss': '0.712 GiB'})\n",
    "2020-06-21 21:25:00Z, [0] Done preprocessing, mem, ({'pmem': '36.4', 'rss': '0.712 GiB'})\n",
    "2020-06-21 21:25:38Z, [0] Saved train data: /opt/program/artifacts/2020-06-21T212459Z/dtrain.txt\n",
    "2020-06-21 21:25:38Z, [0] Done xgb.train, mem, ({'pmem': '37.3', 'rss': '0.73 GiB'})\n",
    "2020-06-21 21:25:39Z, [0] Done transforming test data\n",
    "2020-06-21 21:26:15Z, [0] Done saving to /opt/program/artifacts/2020-06-21T212459Z/dtest.txt\n",
    "2020-06-21 21:26:16Z, [0] Done predict(), mem, ({'pmem': '59.7', 'rss': '1.166 GiB'})\n",
    "2020-06-21 21:26:17Z, [0], acc=0.02239938535669231\n",
    "2020-06-21 21:26:18Z, [0] Done  done fu.big_logloss() logloss=0.0, mem, ({'pmem': '60.1', 'rss': '1.175 GiB'})\n",
    "2020-06-21 21:26:19Z, [0] wrote bundle /opt/program/artifacts/2020-06-21T212459Z/bundle_0.joblib\n",
    "2020-06-21 21:26:20Z, [1] Done preprocessing, mem, ({'pmem': '60.9', 'rss': '1.189 GiB'})\n",
    "2020-06-21 21:26:57Z, [1] Saved train data: /opt/program/artifacts/2020-06-21T212459Z/dtrain.txt\n",
    "2020-06-21 21:26:57Z, [1] Done xgb.train, mem, ({'pmem': '62.0', 'rss': '1.211 GiB'})\n",
    "2020-06-21 21:26:58Z, [1] Done transforming test data\n",
    "2020-06-21 21:27:33Z, [1] Done saving to /opt/program/artifacts/2020-06-21T212459Z/dtest.txt\n",
    "2020-06-21 21:27:34Z, [1] Done predict(), mem, ({'pmem': '62.4', 'rss': '1.219 GiB'})\n",
    "2020-06-21 21:27:35Z, [1], acc=0.022382786193290143\n",
    "2020-06-21 21:27:36Z, [1] Done  done fu.big_logloss() logloss=0.0, mem, ({'pmem': '62.4', 'rss': '1.22 GiB'})\n",
    "2020-06-21 21:27:36Z, [1] wrote bundle /opt/program/artifacts/2020-06-21T212459Z/bundle_1.joblib\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.9889841079711914"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reran the logloss from above b/c i had my bug there from earlier..\n",
    "fu.big_logloss(actuals, y_prob=y_prob_vec, \n",
    "                             labels= list(range(len(labels))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
